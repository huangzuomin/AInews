---
title: 超级智能的路径之争：Meta研究员对OpenAI愿景的颠覆性质疑
date: 2025-06-20T20:10:04+08:00
draft: false
featured_image: "https://mmbiz.qpic.cn/mmbiz_png/UBYSOB6FniafhhkTibnFUzGnXHvnBmpMEozg7IrmSylOsK8FWAzCGulUX8ZNnFz0uN10ibP3Tj3KDZ9qxrZMvUDDg/640?wx_fmt=png&from=appmsg"
summary: OpenAI首席执行官Sam Altman认为构建超级智能是工程问题，但Meta AI研究员Jack Morris对此提出颠覆性质疑。Morris认为，当前依赖大语言模型（LLM）和强化学习（RL）的路径，受限于高质量训练数据的稀缺性及RL在可验证任务上的迁移能力不足，无法实现真正的通用超级智能。这场关于AI未来路径的辩论，揭示了行业在追求终极智能时面临的核心技术瓶颈和方法论分歧。
tags: 
  - 超级智能
  - OpenAI
  - Meta AI
  - Jack Morris
  - Sam Altman
  - 大语言模型
  - 强化学习
  - 人工智能发展
main_topics: 
  - 前沿模型与算法
  - AI Agent与自主系统
  - 产业生态与商业版图
---

> 科技巨头在追求超级智能的道路上分道扬镳：OpenAI首席执行官Sam Altman将其视为可解决的工程难题，而Meta AI研究员Jack Morris则认为，当前基于大语言模型（LLM）和强化学习（RL）的路径，因数据与迁移能力的核心局限，根本无法实现真正的超级智能。这一分歧揭示了AI前沿研究在方法论上的深刻挑战。

在人工智能领域，追求“超级智能”（Superintelligence）——一种能力超越人类的更高维AI——已成为诸多科技巨头的终极目标，并引发了一场全球性的军备竞赛。从OpenAI、Anthropic到Google DeepMind，再到Meta斥资数亿美元建立的“秘密超级智能实验室”[^1]，业界普遍弥漫着对这一宏伟愿景的乐观情绪。其中，OpenAI首席执行官Sam Altman更是断言，构建超级智能仅仅是一个“工程问题”，似乎暗示他们已掌握了可行的技术蓝图，只需投入时间和资源即可实现。

然而，这种乐观论调并非没有异议。Meta AI研究员Jack Morris在其题为“Superintelligence, from First Principles”的博客文章中，对OpenAI等公司当前大力推进的基于大语言模型（LLM）的强化学习（RL）路径提出了尖锐质疑。Morris的“谦卑预测”是：当前的LLM路径，即使不断扩展，也只会让模型在训练分布内的任务上变得更好，而无法进化成一个单一的、超越人类的通用超级智能模型[^2]。

### 超级智能之路：方法论的分歧

超级智能被定义为超越通用人工智能（AGI）的更高维度智能，其通用能力甚至能超越人类。围绕如何实现这一目标，AI界形成了两大主流学习范式：**监督学习（SL）**和**强化学习（RL）**。Sam Altman所指的“工程问题”，在Morris看来，恰恰在于构建大量适用于不同任务的RL环境，并训练LLM同时处理所有这些任务。Morris的核心观点在于，这种方法在根本上存在缺陷，无法通往超级智能。

Morris的分析建立在这样一个假设之上：如果超级智能能够实现，其基本构建模块将是神经网络，并通过反向传播算法和某种机器学习方法进行训练，其中Transformer架构因其在大型数据集上的流行性而被假定为基础。那么，关键问题便归结为：**我们采用何种学习算法，以及使用何种数据？**

### 数据与规模：监督学习的挑战

首先是数据问题。Morris强调，**文本数据是通向超级智能的最佳路径**。他指出，当前最优秀的系统，如ChatGPT，其成功很大程度上源于对互联网上庞大人类知识宝库的学习。他认为，由实际人类撰写的文本具有某种“内在价值”，这是纯粹的感官输入（如图像、视频、音频）无法比拟的，因为文本是人类思维过程的直接反映，具有极高的信息含量。

然而，依赖文本数据也带来了巨大的挑战——**“数据墙”或“token危机”**。大型AI实验室已投入巨大工程努力，从互联网的各个角落搜刮每一个有用的文本片段，甚至转录了数百万小时的YouTube视频，以供训练使用。OpenAI似乎已经转录了整个YouTube，而Reddit等高质量信息网站也被反复抓取。Morris指出，将模型规模扩展到超过1000亿参数已经很困难，同样，将数据规模扩大到20T tokens以上也面临严峻挑战。这些因素表明，在可预见的未来，单纯依靠监督学习的规模化将面临严峻瓶颈。

此外，尽管像Ilya Sutskever曾提出“next-token prediction”本质上是在学习压缩“（信息）宇宙”，认为这将无限趋近超级智能，但Morris对此表示怀疑。他指出，我们已经创建了在next-token prediction方面远超人类水平的系统，但这些系统仍无法展现人类级别的通用智能，例如，它们仍会凭空杜撰、无法完美遵循指令，这可能是因为模型在预测平均结果方面表现出色，却未能学习分布的“尾部”，即更复杂、更罕见的信息。

### 强化学习的局限：迁移能力的考验

如果单纯的监督学习无法通向超级智能，那么结合强化学习（RL）又如何呢？RL通过反馈而非仅仅依赖演示进行学习。虽然RL在“冷启动问题”上效率较低，需要SL进行预训练，但其核心在于模型通过尝试操作并获得奖励信号来迭代提升。

Morris探讨了两种RL范式：

1.  **来自人类验证者的RL（RLHF）：** 这种方法假设我们可以拥有无限数量的人类来标注数据，并提供奖励信号，引导模型生成更接近超级智能的文本。然而，Morris质疑：非超级智能的人类能否足够可靠地识别和验证超级智能的输出，从而为LLM提供有效的梯度信号，使其超越人类？他引用了“生成自然比验证更难”的原则，例如，你可以判断一部电影是否优秀，但并不意味着你能制作一部。
2.  **来自自动验证器的RL（RLVR）：** 近年来，这种方法备受关注，特别是在DeepMind的AlphaGo和OpenAI的o1模型中。AlphaGo Zero通过自我对弈数百万局，在围棋这种具有内在可验证性的任务上实现了“围棋霸主地位”——计算机程序可以清晰判断胜负。OpenAI的o1模型也通过可验证奖励强化学习（RLVR）在AIME（一套答案为整数的数学题）数据集上表现出色，能够随着思考时间的增加而产生更优的输出，这与AlphaGo在思考时间更长时表现更佳的特性类似。

这正是OpenAI等公司对超级智能路径的乐观来源：构建大量适用于不同任务的RL环境，并通过自动验证器来训练LLM。Altman所指的“工程问题”正是这种模式。

然而，Morris在此提出了最核心的质疑：**我们并不清楚RL在可验证任务上的迁移能力是否能够有效扩展到其他领域。** 训练模型解决数学问题是否能自然地教会它如何预订机票？或者，在可验证环境中提升编程能力，是否能使其成为更优秀的软件工程师？Morris认为，如果RL确实能够极好地迁移到其他领域，那我们现在应该已经知道。他的预测是，LLM将继续在训练分布内的任务上变得更好，从而产生在广泛任务上越来越有用的LLM，但它不会成为一个单一的、通用的超级智能模型[^2]。

这一深刻的分歧揭示了AI领域在追求终极智能过程中面临的根本性挑战。尽管科技巨头们投入了数十亿美元的资金和无数的工程努力，但通往超级智能的路径仍充满迷雾。Jack Morris的质疑并非仅仅是对某种技术路线的挑战，更是对整个行业在AI发展方向上的一种深刻反思：我们是否过度依赖于当前的技术范式，而忽视了智能本质的更深层次的突破？在数据和计算资源面临瓶颈、以及模型泛化能力遭遇天花板的背景下，真正的超级智能可能需要的是全新的理论突破，而非简单的工程堆叠。

## 引用
[^1]: [OpenAI路线遭质疑，Meta研究员：根本无法构建超级智能](https://36kr.com/p/3344734861214337)·36氪·学术头条（2025/06/20）·检索日期2025/06/20
[^2]: [Superintelligence, from First Principles](https://blog.jxmo.io/p/superintelligence-from-first-principles)·Jack Morris（2025/06）·检索日期2025/06/20
