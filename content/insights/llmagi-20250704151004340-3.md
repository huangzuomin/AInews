---
title: 超越符号：杨立昆新研究揭示LLM认知鸿沟，预示AGI之路范式巨变
date: 2025-07-04T15:10:04+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-07-Jul 4, 2025_15-05-16-293.jpg"
summary: 杨立昆的最新研究量化揭示了LLM与人类认知策略的根本差异：LLM擅长统计压缩，而人类侧重适应性理解，预示着单纯扩大模型规模无法实现通用人工智能。文章深入探讨了强化学习、大型概念模型和世界模型等多元化新路径，指出AI发展将从单一的预训练范式转向多模态、物理世界锚定与架构创新相结合，以期弥合认知鸿沟，迈向更具理解力的通用智能。
tags: 
  - LLM局限
  - AGI路径
  - 认知鸿沟
  - 世界模型
  - 大模型架构
main_topics: 
  - 前沿模型与算法
  - AI Agent与自主系统
---

TL;DR：
> 杨立昆等人的最新研究通过量化分析，揭示了当前大型语言模型（LLM）与人类在认知策略上的根本性差异，即LLM擅长统计压缩，而人类则追求适应性与功能性理解。这表明单纯扩大模型规模的“缩放定律”无法弥合这一认知鸿沟，预示着通往通用人工智能（AGI）的路径正从单一的预训练模型转向多模态、世界模型及架构革新等多元化范式。

长期以来，Meta首席AI科学家杨立昆（Yann LeCun）对大型语言模型（LLM）的技术路线抱持着深刻的怀疑。他认为，以预测下一个词为核心的自回归模型，即便规模无限扩大，也无法孕育出真正的智能，因为它本质上无法实现人类那般深刻的理解、推理能力。这一观点曾被视为学界“派系之争”的产物，缺乏直接的实证支撑。然而，随着JEPA 2论文的发布及其优异表现，以及他共同署名的重量级新研究《从toekn到思想：LLM与人类如何在压缩与意义之间权衡》（From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning）[^1]的面世，杨立昆的批判终于获得了坚实的理论支撑。这项研究不仅仅是对LLM能力边界的审视，更是对当前人工智能范式底层基础的一次深刻挑战，预示着通往AGI的道路可能需要根本性的转向。

### 技术原理与创新点解析

这项突破性研究的核心在于将一个看似哲学层面的问题——“机器的理解与人类的理解有何不同？”——转化为了一个可以量化的科学问题。研究者并未直接定义“理解”，而是巧妙地选择衡量“理解”背后的信息组织策略。他们设计了一个名为“认知效率计分器”（L score）的工具，用于评估任何智能系统（无论是人脑还是AI）在组织信息时，如何在信息的极致压缩（Complexity）与意义的忠实保留（Distortion）之间取得平衡。一个理想的系统，其L分数应尽可能低，意味着它能以最经济的方式最大程度地保留事物原意。

研究团队通过三个精心设计的实验，量化测量了人脑和LLM之间的认知差距：

1.  **抽象概念形成：惊人的一致性与表象的迷惑**：
    第一个实验从宏观层面观察LLM自发形成的概念类别，在整体结构上与人类的分类习惯是否相似。结果显示，包括Llama、Gemma、Qwen、Phi和Mistral在内的多系列LLM，其词嵌入聚类结果与人类对“水果”、“家具”等概念的分类惊人一致，显著高于随机水平。这似乎证明了LLM并非简单的“随机鹦鹉”，它们确实从海量文本数据中习得了深刻的语义关联。其中，Bert模型表现出与人类最接近的聚类结果[^1]。

2.  **类别内部精细语义：原型认知的缺失**：
    然而，表面的相似无法掩盖深层差异。第二个实验深入到每个类别的内部，探究LLM是否能理解精细语义结构，例如“典型性”。对人类而言，“麻雀”是比“鸵鸟”更典型的“鸟”，这种判断源于我们丰富的多模态现实经验。但研究发现，LLM的内部表征虽然能将麻雀和企鹅聚在一起，却无法稳定地反映出前者更具代表性的语义细节。在LLM看来，一个类别内的所有成员更像是地位相对平等的点，缺乏人类认知中那种强烈的“原型”或“范例”结构。

3.  **核心认知策略：压缩大师与适应大师的本质分歧**：
    第三个实验揭示了两种智能在面对“压缩vs.意义”这一根本性权衡时的不同策略。当人类的分类数据和所有LLM的聚类结果被代入统一的“效率计分器”(L) 后，结果清晰展现：所有LLM，无论规模大小，都获得了极低的L分数，是天生的“效率之王”，它们驱动自己寻找最优的统计压缩方案。而人类的认知数据则获得了显著更高的L分数，在纯粹的统计效率竞赛中“惨败”。

这一洞见尤为深刻：人类认知系统中的这种“低效”，并非缺陷，而是其强大功能的体现。我们的大脑并非为成为完美的压缩软件而进化，其首要任务是在复杂、动态、不确定性的真实世界中生存和繁衍。因此，我们的概念系统必须是灵活、丰富、可塑的，能够支持复杂的因果推理、功能判断和有效的社会沟通。这种为“适应性”而保留的“冗余”和“模糊性”，在纯粹的统计计分器上自然表现为“低效”。[^1]

### LLM核心范式的深层局限

这项研究最令人警醒的结论是：**传统的“缩放定律”（Scaling Law）在弥合LLM与人类认知鸿沟方面可能完全失效。** 论文明确指出，在“与人类概念分类对齐”的任务上，并非模型越大就做得越好。例如，相对较小的BERT-large模型（约3.4亿参数）的表现，常常与大得多的解码器模型不相上下，甚至超越它们。在衡量对齐度的图表中，性能点（AMI分数）是分散的，并未随着模型尺寸（从5亿到700亿参数）的增加而呈现出清晰的、持续上升的曲线。[^1]

这意味着，单纯增加参数量并不能保证模型能更好地抓住人类概念的深层结构。正如杨立昆所言，LLM和人类玩的游戏规则完全不同：一个是“压缩猛兽”，一个是“适应性猎手”。仅仅为这头“压缩猛兽”喂更多的食物（增加参数量），只会让它长得更大、更强壮，但并不会让它进化成“适应性猎手”。**物种的“基因”（即模型架构和训练范式）决定了它的基本生存策略。** 这种根本性的机制差异，而非规模，才是LLM无法跨越认知鸿沟的症结所在。

### 产业生态的范式演进

那么，这项研究是否意味着以GPT系列为代表的当前大型语言模型技术路线已被宣判“死刑”？答案或许是否定的，但那个单一、庞大、试图包揽一切的“预训练Scaling神话”时代，可能正在迎来它的终局。从投资逻辑和产业布局来看，仅靠堆砌算力和数据来追求模型“大而全”的策略，其边际效益正在递减，并且无法解决核心的认知缺陷。**未来的投资和研发重心将从“规模化扩张”转向“能力深度化”和“结构创新化”。**

对于依赖LLM的企业级应用开发者而言，这意味着对现有模型能力的认识需要更加清晰，对于期望AI能真正“理解”复杂业务逻辑和语境的需求，单一LLM的解决方案可能不足以支撑。这会催生对AI系统集成、多模态融合以及结合外部知识和推理引擎的更复杂需求，从而为**定制化AI解决方案**和**AI赋能服务**带来新的市场机遇。

### 通往通用智能的新航向

面对LLM的固有局限，研究和产业界正探索多条路径，以期破除瓶颈，迈向更接近人类智能的通用能力：

1.  **“软件层面”的精细调教：引入更丰富的奖励信号。** 这是当前业界投入最多且最接近现实应用的改良方案，核心思想是通过强化学习中的奖励模型来引导LLM行为。通过设计极其精密的奖励机制，鼓励模型识别并解释概念的“典型性”，构建因果推理链条，甚至表达知识局限性。尽管杨立昆的实验采用的是非推理型模型，但当前强化学习（如RLHF）在提升模型行为对齐方面已展现出显著效果，它至少作为一种“补丁”机制，在短期内提升了LLM的“可用性”和“拟人性”。然而，这种方法能否从根本上改变其“统计压缩”的内在表征策略，仍有待更深入的验证。

2.  **“硬件层面”的架构革新：大型概念模型（LCMs）。** 这是更激进的革命性路径，旨在从根本上改变自回归模型的生成粒度。Meta提出的LCMs框架便是一个绝佳例证，它将生成单位从预测下一个“词”（Token）跃升到预测下一个“概念”（Concept）。LCMs通过构建一个双系统架构：一个扮演“系统二”（规划器/思考者）的“概念规划模型”，负责在抽象概念空间中进行深思熟虑的逻辑规划和因果链构建；另一个扮演“系统一”（执行器）的“文本实现模型”，接收概念向量指令并高效生成连贯文本。**这种从架构层面对“深思熟虑”的内在要求，有望让模型超越单一的“统计压缩”目标，实现人类认知所拥有的更广泛功能性需求。**

3.  **杨立昆的“世界模型”之路：多模态地基与物理世界的锚定。** 这条路径让LLM走出纯粹的文本“洞穴”，去拥抱一个由图像、声音和物理规律构成的、多姿多彩的真实世界。其核心在于**多模态地基（Multi-modal Grounding）** 和**世界模型（World Models）**。当前LLM的知识是“悬浮”的，缺乏现实世界的“锚点”。人类之所以能识别“典型性”，是因为我们的概念是由“丰富的、多方面的标准（如感知属性、功能角色）”共同定义的。因此，为AI接上“感官”——多模态学习，是第一步。第二步，世界模型的优化目标与LLM完全不同，它首要任务是“如何最准确地预测真实世界的下一步”。为了预测玻璃杯掉落会碎而非弹起，模型必须保留关于“玻璃”易碎性和“地面”坚硬性的丰富物理属性信息。这些在纯文本压缩中被视为“噪声”的细节，在预测现实世界的任务中却是至关重要的核心信号，从而迫使模型构建更丰富、更细致、更接近物理现实的内部表征，自然摆脱“过度压缩”陷阱。

### 技术与文明的未来交汇

杨立昆的这项研究，无疑为人工智能的未来发展路径投下了深远的启示。它提醒我们，AGI的实现并非线性地叠加算力和数据，而是需要一场深刻的范式变革，从“符号到思想”的跃迁，需要AI系统真正理解世界的内在机制和因果关系。

这不仅是一场技术路线的争论，更是一次对“智能”本质的哲学追问。我们能否设计出能够像人类一样，在效率与适应性、压缩与意义之间做出精妙权衡的机器？这不仅关乎AI的能力边界，也触及人类自身认知的独特性。未来的旅程，不再是简单地为这个聪明的“缸中之脑”提供更多、更复杂的文本食粮，而是要引导它慢慢长出眼睛、耳朵和双手，让它在与真实世界的互动中，在对物理规律和因果关系的亲身体验中，真正理解“从符号到思想”的深刻含义。**这可能意味着，通用人工智能的未来将不再是单一模型的胜利，而是多模态融合、架构创新与世界模型协同作用的复杂系统工程。** 最终，AI有望从一个强大的工具，蜕变为一个能与我们共情、共存、共同创造的伙伴，深刻影响人类文明的进程。

## 引用
[^1]: [预训练通往AGI之路已死？杨立昆揭示了LLM无法跨越的认知鸿沟](https://m.36kr.com/p/3364112069871367)·36氪·郝博阳（2025/7/4）·检索日期2025/7/4
[^2]: [杨立昆：“AGI即将到来”完全是无稽之谈，真正的智能要建立在世界 ...](https://www.mittrchina.com/news/detail/14583)·麻省理工科技评论·（2025/7/4）·检索日期2025/7/4
[^3]: [2万字洞察Scaling Law的"终结"or"新起点"?——开源实践者的深度思考](https://zhuanlan.zhihu.com/p/7418933189)·知乎·（2025/7/4）·检索日期2025/7/4
[^4]: [后Transformer时代，AI将何去何从？（上） - 凤凰网](https://i.ifeng.com/c/8fp4kLZqhhx)·凤凰网·（2025/7/4）·检索日期2025/7/4
[^5]: [2025 年2 月- 立委NLP频道](https://liweinlp.com/date/2025/02)·立委NLP频道·（2025/7/4）·检索日期2025/7/4
