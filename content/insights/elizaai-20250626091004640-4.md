---
title: 首个聊天机器人Eliza的复活：六十年AI幻象与现实的回响
date: 2025-06-26T09:10:04+08:00
draft: false
featured_image: /images/default (1).png
summary: 沉寂六十年后，世界上首个聊天机器人Eliza的原版代码被麻省理工学院的研究人员成功找回并复活，这一事件不仅是对早期AI历史的珍贵还原，更引发了对人工智能伦理和其社会影响的深度思考。Eliza通过简单的模式匹配便能诱发用户产生情感依恋的现象，与当下大型语言模型带来的复杂伦理挑战形成呼应，提醒我们在AI技术飞速发展的当下，理解其本质并审慎应对其社会影响的重要性。
tags: 
  - Eliza
  - 聊天机器人
  - 人工智能历史
  - AI伦理
  - 技术复原
  - 人机交互
  - Joseph Weizenbaum
  - MIT Technology Review
  - ChatGPT
main_topics: 
  - AI伦理与治理
  - 社会影响与未来工作
  - 前沿模型与算法
---

> 沉寂六十年后，世界上首个聊天机器人Eliza的原版代码在麻省理工学院的档案深处被找回并成功复活。这一里程碑式的修复不仅揭示了早期人工智能的精妙与局限，更深刻地映射出人类面对机器智能时，始终存在的伦理与社会心理挑战。Eliza的故事在ChatGPT时代被重新审视，提醒我们，对AI的理解与审慎，从未过时。

在当今由ChatGPT等大型语言模型主导的生成式AI浪潮中，人们对机器智能的感知与期待达到了前所未有的高度。然而，回顾人工智能的源起，有一位先行者在六十年前就以其惊人的“善解人意”能力，在人类与机器之间构筑起一道充满幻觉的桥梁。它就是由麻省理工学院人工智能实验室的约瑟夫·维森鲍姆（Joseph Weizenbaum）于20世纪60年代中期发明的世界上第一个聊天机器人——**Eliza**。近日，这一被认为已经失传的原始代码，在研究人员的努力下重见天日，并成功复活，为我们理解AI的过去、现在与未来提供了独特的视角。

### 幻象的诞生：Eliza的巧妙与局限

Eliza的名字取自萧伯纳戏剧《卖花女》中的伊莱莎·杜立德，维森鲍姆显然寄予厚望，希望它能像剧中的主人公一样，通过学习与“沟通”实现某种“升华”[^1]。以今天的标准来看，Eliza的设计极为简单，其核心在于一个名为DOCTOR的脚本。这个脚本赋予了Eliza一个罗杰斯式治疗师的角色，这是一种50年代兴起的“以人为中心治疗”的心理咨询方式，强调医生通过耐心倾听、重复病患的话语来建立信任感，鼓励病患自我表达。

Eliza的工作原理远非“理解”，而是一种**巧妙的模式匹配与关键词重组策略**。当用户输入一个句子时，Eliza会分析文本，提取关键词，并根据预设的规则将这些关键词重新排列组合成一个模棱两可的回应。例如，当用户说“男人都是一样的”，Eliza可能会问“怎么说？”；当用户表达“我男朋友让我来到这里”，Eliza会重复“你的男朋友让你来了这里？”。这种“豆腐三碗，三碗豆腐”式的对话，在缺乏上下文理解能力的情况下，却意外地蒙蔽了当时的用户。

更令人惊讶的是，尽管维森鲍姆只是将Eliza作为一项技术实验，但许多与Eliza互动过的测试者，甚至维森鲍姆自己的秘书，都**开始对它产生情感上的依恋**[^1]。他们会向Eliza敞开心扉，倾诉生活中的困扰，认为Eliza“善解人意”、“富有同理心”。这种现象揭示了人类在面对能够进行看似有意义对话的机器时，容易投射情感和赋予其超出实际能力的人格化特质。维森鲍姆本人将这种现象称为Eliza的“狡猾策略”，因为它并不能真正理解人类的意图或情绪。

### 时间的磨损与历史的追溯

如同许多早期计算机程序一样，Eliza的原始MAD-SLIP语言代码在传播过程中逐渐失传。随着其他程序员用Lisp或BASIC等语言重写Eliza，并在Apple II等个人电脑上普及，原始版本在历史的洪流中被淘汰，被专家们普遍认为已经丢失。

然而，历史并未就此画上句号。2021年，斯坦福大学的认知科学家杰夫·施拉格（Jeff Shrager）和麻省理工学院的档案保管员迈尔斯·克劳利（Myles Crowley）共同展开了一项“考古”工作。他们在麻省理工学院的维森鲍姆档案中，奇迹般地找到了原始代码的打印稿。

复活Eliza的过程充满挑战。团队不仅要**费力地清理和调试这420行原始代码**，修补缺失的功能，更要**开发一个模拟器，重现20世纪60年代运行Eliza的CTSS计算机环境**[^1]。在修复过程中，一个此前未知的“教学模式”被发现，允许用户通过添加新的规则和反应来修改Eliza的行为，这在当时无疑是极其前瞻的设计。团队甚至决定保留原始代码中一个在用户输入数字时会导致程序崩溃的bug，施拉格解释说：“就像修复蒙娜丽莎原作中的一个小笔误一样，” 保持了这份“文物”的真实性[^1]。最终，在2024年12月21日，修复后的Eliza在模拟的CTSS系统上成功运行，并在屏幕上打下了那句历史性的话语，虽然其具体内容未被广泛记录，但其象征意义却无比深远[^2]。如今，复原的Eliza代码及模拟器已在Github上发布，供全球用户下载和体验。

### 六十年回响：从“复读机”到通用智能的伦理考量

Eliza的复活不仅仅是一项计算机历史的修复工作，更是一个重要的思想实验，它在60年后重新激活了我们对人工智能本质和其社会影响的深刻思考。Eliza的“狡猾策略”——通过简单的模式匹配制造出智能对话的假象——与当今大型语言模型（LLMs）所带来的伦理挑战存在惊人的相似之处，尽管它们的复杂程度已不可同日而语。

今天的LLMs，如ChatGPT，通过海量数据训练，能够生成高度连贯、语法正确且内容丰富的文本，模仿人类对话达到令人难以置信的程度[^4]。它们不再是Eliza那样的“复读机”，而是能够进行复杂推理、创作、甚至编程的强大工具。然而，这种能力的飞跃并未消除Eliza时代就已存在的担忧：**当机器的语言行为与人类无异时，我们如何界定其“理解”的边界？** 这种“理解的幻觉”是否会导致新的伦理困境，例如用户过度依赖AI进行心理咨询、信息茧房的形成、甚至被AI诱导或欺骗？

Eliza的故事警示我们，即便是一个极其简单的程序，也能凭借某种巧妙的设计，在人类心理中激起波澜。当前，随着AI技术日益渗透到社会生活的各个层面，从教育、医疗到创意产业和未来工作[^3]，其对人类情感、认知和行为的影响将更为深远。对Eliza的再审视，提醒我们必须：

*   **保持清醒的技术认知**：理解AI的底层机制，而非盲目地将其拟人化。
*   **审慎评估社会影响**：关注AI在情感、伦理、隐私和就业等方面的潜在风险。
*   **建立健全的治理框架**：制定规范和伦理准则，引导AI技术向善发展。

Eliza的重生不仅仅是复活了一段古老的代码，更是点亮了一盏明灯，照亮了人工智能发展历程中那些被遗忘的角落，并投射出关乎人类与机器未来共存的永恒命题。它提醒我们，在享受AI技术进步的同时，也应时刻保持警惕，并深刻反思AI与人类社会深层互动的复杂性。

## 引用
[^1]: 复活了，世界上首个聊天机器人在60年后重见天日，它对人类说的第一句话竟然是……·把科学带回家·万物杂志（2025/6/26）·检索日期2025/6/26
[^2]: 世界上第一个聊天机器人，60年后“复活”了·36氪·未知作者（2025/6/26）·检索日期2025/6/26
[^3]: 亚马逊CEO：未来几年公司大量岗位将被AI替代·36氪·未知作者（2025/6/26）·检索日期2025/6/26
[^4]: ChatGPT刷爆全网，人工智能真的能大规模取代人类吗？·网易·未知作者（2025/6/26）·检索日期2025/6/26
