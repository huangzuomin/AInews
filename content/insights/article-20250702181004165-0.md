---
title: 当AI塑造“优秀”：数字时代的认知代价与文化趋同
date: 2025-07-02T18:10:04+08:00
draft: false
featured_image: /images/default (1).png
summary: 《纽约客》杂志近期撰文指出，人工智能正通过塑造写作与思维方式，导致原创性与多样性的流失。MIT和康奈尔大学的研究显示，AI辅助写作会降低大脑活动、造成思维同质化，并强化文化偏见。文章呼吁对AI带来的认知代价和文化趋同进行理性反思，警惕其“平均化”特性对人类创造力与独立思考的深层影响。
tags: 
  - 人工智能
  - 大型语言模型
  - 认知影响
  - 创造力
  - 文化趋同
  - 伦理
  - 社会影响
  - 脑科学
main_topics: 
  - AIGC与内容科技
  - AI伦理与治理
  - 社会影响与未来工作
---

> 《纽约客》杂志近日的一篇深度分析揭示，人工智能，尤其是大型语言模型（LLM），正以效率之名，悄然重塑我们的认知方式与文化景观。这种“思维外包”不仅可能导致大脑活动减弱、原创性丧失，更潜藏着将全球表达导向“平均化”和“西方化”的深层风险。我们必须警惕这种由算法驱动的“平庸化革命”所带来的认知与文化代价。

过去数年，人工智能的飞速发展重新定义了“效率”与“智能”的边界，尤其在内容生成领域，大型语言模型（LLMs）的普及让“像样”的文章触手可及。然而，正如《纽约客》杂志近日撰文所警示的，这种表面的便利正在潜移默化地重塑我们的思维结构，以牺牲原创性和多样性为代价，统一表达的风格与内容。[^1] 这引发了一个深刻的问题：当我们越来越依赖AI完成创意任务时，我们是否正在失去人类独有的深度、多样性与表达欲？

### 认知外包的代价：大脑活动与创造力的衰减

麻省理工学院（MIT）的一项开创性实验，首次从神经科学层面量化了“依赖AI完成任务所带来的认知代价”。研究人员招募了50多名大学生，分为三组撰写SAT议论文。其中一组使用ChatGPT辅助写作，结果令人警醒：与完全独立写作或仅使用谷歌搜索的学生相比，使用ChatGPT的学生大脑活动水平显著降低。他们的大脑不同区域间的连接更少，特别是与创造力相关的**α波连接度**和与工作记忆相关的**θ波连接度**均出现下降。[^1]

更令人不安的是，一些使用LLM的学生对他们“写出”的文章几乎没有归属感，甚至在测试中高达80%的学生无法复述自己“创作”的内容。这项研究有力地证明，当AI工具承担了认知劳动，人类的思维过程——从构思、组织到表达——可能会被大幅度“外包”，导致大脑在这些关键功能上的参与度降低。OpenAI首席执行官山姆·奥特曼曾乐观地预言，我们正接近一个“温和奇点”，即AI工具将“显著放大用户的产出”。但这些早期研究却暗示，这种产出的“放大”可能伴随着深层质量的“下降”：原创思考的减少，以及对文本内容掌控力的削弱。

### 文化趋同的隐忧：算法放大下的“平均化”

AI的“平均化”特性不仅体现在认知层面的疲软，更在悄然重塑我们的文化表达。大型语言模型通过分析海量数据中的模式进行训练，其生成的内容天然趋向于“共识”或“平均值”——无论是在写作的质量上，常常充斥着陈词滥调，还是在观点的呈现上，往往流于平庸。MIT的研究发现，即使SAT题目本应激发多样化回应，AI的参与却导致学生文本中常用词汇和观点的高度趋同，一切似乎都变得“中庸”。

康奈尔大学今年4月发布的一项研究进一步印证了AI带来的“思想同质化”问题。该研究让美国和印度用户使用ChatGPT驱动的“自动补全”工具完成文化背景相关的写作任务。结果显示，AI辅助下的答案风格明显趋同，并倾向于**“西方范式”**。例如，用户普遍选择披萨或寿司作为“最喜欢的食物”，而对本土食物的描述则变得泛泛，缺乏文化特有的细节。[^1]

康奈尔大学信息科学教授阿迪提亚·瓦希斯塔将AI比作“一个坐在我身后、不停说‘这是更好的写法’的老师”。他指出，AI的建议“以一种隐蔽但强有力的方式，不只是改变你写了什么，而是改变你怎么想”。[^1] 这种潜移默化的影响，长期来看可能导致人们对“什么才是正常的、可取的、恰当的”产生整体性偏移。小说家兼记者沃希尼·瓦拉强调，AI文字的“平庸性”反而带来一种“安全”与“无害”的幻觉，但其背后却可能悄然强化某种文化霸权。对于OpenAI等公司而言，让模型输出“更容易被普遍接受”正是其商业动因，因为“正常”且“无棱角”的输出能扩大用户基数。

### 创意过程的异化：从主动生成到“策展模式”

AI对创造力的影响同样值得深思。加州圣塔克拉拉大学2024年的一项数据分析研究了AI工具在标准“创意思维”任务中的表现，例如“如何让毛绒玩具更有趣”或预测“不可能的后果”。结果再次表明，使用ChatGPT辅助的受试者，其创意答案更趋同、更集中、更“语义雷同”，远不如使用传统启发式工具（如布赖恩·伊诺的《斜向策略》卡片）所激发的创意。[^1]

研究合著者马克斯·克雷明斯基观察到，当人们在创意过程中使用AI时，往往会逐渐放弃原本的思考，进入一种“策展模式”（curationist mode）。用户最初可能带着自己的想法，但ChatGPT能快速生成大量“可接受”的内容，导致用户转变为从AI提供的选项中进行挑选和编辑，而非从零开始创造。克雷明斯基指出，这种影响是单向的：“人类的想法往往无法强力影响机器的输出，ChatGPT会将你拖向它所积累的用户平均值‘质心’。” 他进一步解释，AI在工作记忆中的“上下文窗口”（context window）一旦饱和，便更倾向于重复自己已有的输出，从而限制了真正的原创性。

尽管上述实验规模尚小，每项研究的受试者人数均不足百人，AI对人类思维与社会的长远影响仍需更深入的观察与研究。然而，我们已能从Meta的Meta AI应用中窥见未来一隅：数以亿计由AI生成、高度“抛光”的图像、视频与文本如信息洪流般滚动呈现。当一个用户向Meta的聊天机器人提问“AI是否有可能在未来超越人类智能”时，模型给出的四种“未来情景”无一例外地描绘了AI变得更强大、更高效、更友善，并最终造福人类的美好蓝图——没有任何关于失败、风险或负面后果的提及。[^1]

这种一边倒的乐观叙事，很可能反映了系统设计中固有的**技术乐观主义偏见**。更关键的是，模型用一种“中庸”的语气将潜在的复杂争议简化为和谐愿景，削弱了对话中本应存在的多元观点与思想张力。如果我们不加辨别地接受这种看似中立、实则偏颇的答案，某种意义上就是在放弃独立思考。在算法日益成为我们思想中枢的时代，比技术热情更重要的是，一份清醒的理性反思。

## 引用

[^1]: [《纽约客》最新撰文：AI教会人类如何写“好”文章，却让真正的好文章消失了](https://www.36kr.com/p/3360550601721860)·腾讯科技·无忌 海伦（2025/7/2）·检索日期2025/7/2
