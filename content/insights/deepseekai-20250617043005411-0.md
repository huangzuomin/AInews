---
title: 意大利监管机构重拳出击：DeepSeek事件揭示AI“幻觉”与信任危机
date: 2025-06-17T04:30:05+08:00
draft: false
summary: 意大利反垄断机构AGCM已对中国AI公司DeepSeek展开调查，原因在于其涉嫌未能充分警示用户AI模型可能生成虚假信息，暴露了大型语言模型“幻觉”现象带来的挑战。此外，意大利数据保护局Garante此前已因隐私和透明度问题对DeepSeek实施禁令，这双重监管行动突显了AI技术面临的信任危机和日益严格的全球治理趋势。该事件强调了AI开发者在产品设计中需将透明度、责任和用户安全置于核心地位。
tags: 
  - 人工智能
  - 监管
  - AI幻觉
  - DeepSeek
  - 意大利
  - 消费者保护
  - 伦理AI
  - 数据隐私
main_topics: 
  - AI监管
  - 幻觉问题
  - 信任危机
---

> 意大利反垄断机构AGCM已对中国AI初创公司DeepSeek展开调查，指控其未能充分警示用户其AI模型可能生成虚假信息，这凸显了大型语言模型“幻觉”现象带来的严峻挑战。与此同时，意大利数据保护局Garante也因隐私和透明度问题对DeepSeek采取了行动，共同描绘出一幅监管机构日益关注AI技术潜在风险的图景，并对AI开发者提出了更高的责任要求。

意大利，这个曾率先对ChatGPT实施临时禁令的欧洲国家，再次站在了人工智能监管的前沿。近日，意大利反垄断和市场竞争管理局（AGCM）宣布对中国人工智能初创公司DeepSeek展开调查，核心指控是该公司未能向用户提供“足够清晰、即时和可理解的”警告，说明其AI模型可能生成虚假或误导性信息，即所谓的“幻觉”现象 [^1][^2][^3]。这起事件不仅将AI技术固有的缺陷推向了聚光灯下，也为全球日益收紧的AI监管画上了浓墨重彩的一笔。

### 技术风险与监管重拳

AGCM的声明直指DeepSeek在用户体验设计上的疏忽，认为其未能充分履行告知义务，导致用户面临接触不准确内容的风险。在数字信息泛滥的当下，人工智能生成内容的可靠性显得尤为关键。如果用户无法辨别信息的真伪，便可能导致误解、错误决策，甚至更广泛的社会影响。

值得注意的是，这并非DeepSeek在意大利面临的唯一一道监管挑战。在此次AGCM行动之前，意大利数据保护局（Garante）已因“严重的隐私问题和数据处理透明度不足”为由，勒令即刻阻止了DeepSeek在其境内的运营 [^4]。随后，DeepSeek在意大利的苹果和谷歌应用商店便已下架 [^5]。这表明，意大利监管机构对AI的审视是多维度、全方位的，不仅关注内容准确性，也高度重视数据隐私和算法透明度。这种多管齐下的监管策略，无疑给AI开发者敲响了警钟：产品进入市场前，必须充分考虑合规性，包括但不限于信息披露、用户数据保护以及算法的伦理影响。

### 幻觉问题：AI的固有挑战

DeepSeek所面临的“虚假信息风险”，其根源在于大型语言模型（LLMs）普遍存在的“幻觉”（hallucinations）问题。_“幻觉”_是指AI系统生成看似合理但实际上与事实不符、甚至完全虚构的内容。这并非AI故意欺骗，而是其底层技术原理的必然结果。

当前的LLMs，如DeepSeek等，是通过学习海量文本数据来预测下一个词的概率，从而生成连贯的文本。它们擅长模式识别、语言组织，但缺乏真正意义上的“理解”和“推理”能力。当遇到超出其训练数据范围、或需要精确事实核查的复杂问题时，模型可能会“编造”答案，以填补知识空白，保持输出的流畅性。例如，一个LLM可能会煞有介事地引用不存在的文献、捏造人物生平，或者给出完全错误的统计数据。对于不了解AI工作原理的普通用户而言，这些煞有介事的“幻觉”内容，其说服力可能丝毫不亚于真实信息，从而造成误导。

这种固有挑战意味着，即使是当前最先进的AI模型，也无法百分之百地保证其生成内容的准确性。因此，_明确的风险提示和透明的使用指南_，成为AI产品走向大众市场的基本伦理要求。

### 信任危机与AI治理的未来

DeepSeek事件，以及意大利监管机构的一系列动作，折射出AI技术在快速发展过程中所面临的深层信任危机。如果用户不能信任AI提供的信息，AI技术的广泛应用和普惠价值将大打折扣。监管机构的介入，正是为了弥补市场失灵，确保技术发展与公共利益和社会福祉相协调。

意大利的案例，与欧盟正在推进的《人工智能法案》（AI Act）精神不谋而合。《人工智能法案》强调对AI系统进行风险分级管理，对高风险AI应用施加严格的合规要求，包括透明度、可解释性、数据治理以及安全保障等。AGCM和Garante对DeepSeek的调查与禁令，无疑是这一监管趋势的具体体现，并可能成为未来欧洲乃至全球AI治理的范本。

这要求所有AI开发者重新审视其产品的设计理念。除了追求模型性能和商业价值，_“负责任的AI”_（Responsible AI）将不再仅仅是行业内部的自律倡议，而是日益成为法律和道德层面的硬性要求。企业需要投入更多资源，开发有效的机制来检测和减轻“幻觉”现象，例如结合知识图谱进行事实核查、引入人类监督循环，或者至少提供清晰、醒目的风险提示。

展望未来，AI的普及势不可挡，但如何确保其安全、可靠和负责任地发展，将是摆在全社会面前的共同课题。意大利对DeepSeek的监管行动，不仅是对一家公司的具体审查，更是对整个AI行业发出的明确信号：_透明、责任与用户安全，必须成为AI创新的基石。_

## References

[^1]: Italy regulator probes DeepSeek over false information risks | Medial（2025/06/16）。[https://medial.app/news/italy-regulator-probes-deepseek-over-false-information-risks-a0775fa2c7570](https://medial.app/news/italy-regulator-probes-deepseek-over-false-information-risks-a0775fa2c7570)。Medial。检索日期2024/07/29。
[^2]: Italy regulator probes DeepSeek over false information risks（2025/06/16）。[https://www.reuters.com/world/china/italy-regulator-opens-probe-into-chinas-deepseek-2025-06-16/](https://www.reuters.com/world/china/italy-regulator-opens-probe-into-chinas-deepseek-2025-06-16/)。Reuters。检索日期2024/07/29。
[^3]: Italy regulator probes DeepSeek over false information risks - MSN（N.D.）。[https://www.msn.com/en-gb/technology/software/italy-regulator-probes-deepseek-over-false-information-risks/ar-AA1GP3Sd](https://www.msn.com/en-gb/technology/software/italy-regulator-probes-deepseek-over-false-information-risks/ar-AA1GP3Sd)。MSN。检索日期2024/07/29。
[^4]: Italy's Regulator Blocks DeepSeek Amid Growing Privacy Concerns（N.D.）。[https://europeantimes.org/italys-regulator-blocks-deepseek-amid-growing-privacy-concerns/](https://europeantimes.org/italys-regulator-blocks-deepseek-amid-growing-privacy-concerns/)。European Times。检索日期2024/07/29。
[^5]: Italian Regulator Blocks DeepSeek Over Personal Data Concerns（N.D.）。[https://www.ntd.com/italian-regulator-blocks-deepseek-over-personal-data-concerns_1044366.html](https://www.ntd.com/italian-regulator-blocks-deepseek-over-personal-data-concerns_1044366.html)。NTD。检索日期2024/07/29。
