---
title: 小红书的混合云突围：调度系统如何驾驭数字洪流与大模型时代
date: 2025-07-02T12:40:04+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-07-Jul 2, 2025_12-37-19-124.jpg"
summary: 小红书构建了一套独特的混合云联邦调度系统，通过统一K8S API、多层弹性调度和精细化应用编排，高效整合了公共云和自建数据中心资源。这套系统不仅成功应对了突发流量激增（如“TikTok难民潮”），还极大地优化了对GPU等异构算力的管理和利用，为搜索推荐及大模型推理等核心业务提供了稳定、经济的底层支撑，展现了企业在云时代对核心基础设施自主掌控的重要性。
tags: 
  - 混合云
  - 联邦调度
  - Kubernetes
  - 小红书
  - 弹性伸缩
  - 大语言模型
  - 资源管理
  - 云原生
  - GPU算力
main_topics: 
  - 企业级AI与数字化
  - AI与软件工程
  - 产业生态与商业版图
---

> 面对业务爆发式增长和“TikTok难民潮”带来的流量冲击，小红书通过自建一套先进的联邦调度系统，巧妙地融合了公共云与自有数据中心的资源，实现了成本效益与服务稳定性的双赢，并为大模型等前沿技术提供了高效的算力支撑。

在数字世界的潮汐中，企业的技术架构正经历一场深刻的演变。曾被誉为“长在云上”的小红书，如今也悄然迈入了自建与混合云并行的新阶段。这并非是对云原生复杂性的逃避，而是对效率、成本与核心技术自主掌控的深思熟虑。其核心在于一套独特的联邦调度系统，它不仅成功应对了突如其来的流量洪峰，更在人工智能，尤其是大语言模型（LLM）算力紧缺的时代，展现出其战略价值。

### 技术原理解析：在异构世界中构筑统一

小红书的混合云战略并非简单的资源叠加，而是一场关于“统一”与“屏蔽”的工程实践。在面对快速增长的业务需求、割裂的集群资源以及云上与云下网络异构的挑战时，其基础设施团队选择了一条与主流云厂商“标准答案”不同的道路：自主构建协调层，屏蔽异构环境差异，实现全链路技术栈的掌握。[^1]

这套方案的核心可以归结为三大支柱：

1.  **统一接入界面（Kubernetes API 兼容）**：为了让上层业务和平台能够无缝迁移或接入，小红书选择沿用并兼容了标准的Kubernetes API。这背后，是一个巧妙的路由层设计。它能根据资源请求的类型（如Workload、Pod、PVC等），将其精确路由至Karmada控制面或自研的ClusterGateway组件。ClusterGateway则模拟了ETCD的行为，能够ListWatch和支持Informers依赖的基础机制，从而确保了原生K8S客户端（如client-go和kubectl）的完全兼容性。这意味着，对于开发者而言，无论是私有云还是公有云资源，都如同一个**同质、统一的资源池**，极大减轻了运维负担和开发适配成本。

2.  **统一资源调度（多层联邦调度体系）**：调度是混合云效能提升的命脉。小红书构建了一个以“自建优先”为原则的多层联邦调度方案。在资源不足时，能够将工作负载或应用智能地拆分并分发到不同的集群中，优先使用成本更低的自建机房资源，当自建资源吃紧时，再弹性地将流量和计算任务溢出到公有云上。这种“预调度”能力，通过获取底层集群资源快照并模拟调度逻辑，实现了对未来资源分配的精准预测和优化，确保了在复杂的混合环境中，资源能够得到最有效的利用。

3.  **统一联邦应用编排（Fleet-Root机制）**：原生的联邦编排工具，如Karmada，在处理诸如`Deployment`的滚动更新时，往往会因简单的资源同步逻辑导致生产环境的不可用。小红书在Karmada之上构建的`Fleet-Root`机制，正是为了解决这一痛点。它在联邦层面精细化编排整个Rollout过程，确保无论是`MaxUnavailable`、`MaxSurge`还是`Partition`等参数，在联邦集群中的行为都与下发到单个集群**完全一致**。这种对编排语义的深度掌控，消除了使用联邦集群与单集群之间的体验差异，是保障业务稳定性的关键。

此外，为了进一步提升资源利用率，小红书还将HPA（Horizontal Pod Autoscaler，水平Pod自动伸缩器）的能力上移至联邦层面。这意味着，扩缩容决策不再局限于单个集群，而是可以在**全局视角**下进行，充分利用跨集群资源。对于CPU、内存等基础指标，也进行了聚合处理，从而有效减少了对管控面的压力。

### 应对挑战与实际应用：数字洪流与GPU算力困境

小红书的联邦调度系统并非纸上谈兵，它在多个关键业务场景中经受住了严峻考验：

*   **“TikTok难民潮”流量突增的承接**：今年1月，大量“TikTok难民”涌入小红书，导致流量激增，自建机房资源迅速告罄。传统应对方式，如紧急高价采购服务器（交付周期长，成本高）或调整全站流量策略（可能引发整条服务链扩容和成本激增），都面临巨大挑战。然而，凭借这套联邦调度体系，小红书能够将需要扩容的业务从自建机房**平滑分流**到云上ACK集群。流量高峰过后，业务可在服务粒度上定向缩容，动态释放云上资源，将成本和风险降至最低。这不仅守住了服务稳定性，也保障了自建资源的核心地位和成本可控性。[^1][^2]

*   **搜推数据引擎服务的联邦有状态编排**：小红书的搜索、广告、推荐（“搜广推”）业务是其核心，数据量巨大且对有状态编排需求强烈。传统的`StatefulSet`在联邦层面无法有效拆分。小红书为此自研了有状态编排工作负载，允许自定义编排索引，并在联邦层面精细化地汇报每个索引对应Pod的状态。这使得一个有状态服务可以高效地拆分到多个集群，例如，将一个服务按照索引范围拆分到不同的物理集群上，确保了数据一致性和高效发布。

*   **大模型（LLM）GPU推理的统一全局资源池弹性调度**：随着大模型时代的到来，GPU卡成为稀缺资源，且往往分散在几十个集群中，导致资源割裂严重。传统HPA在每个GPU集群开启会造成大量GPU空转（每个集群至少保留一个副本）。小红书将大模型推理业务纳入联邦架构后，业务方只需部署一次模型，联邦HPA便可根据全局需求进行弹性扩缩容。低峰期，一个模型可能只需一个推理实例，而非多个集群中的多个实例。这显著提升了GPU资源的整体利用率，避免了数以百计GPU卡的空转，对于降低AI算力成本、加速模型上线具有_至关重要的战略意义_。

### 深远影响与未来展望：基础设施的自主与创新

小红书的实践，为众多中大型互联网公司在混合云时代的基础设施演进提供了一个值得借鉴的范本。它表明，在与云厂商合作的同时，企业仍需在核心调度和编排能力上进行深度定制和自主掌控，才能真正驾驭复杂业务场景，实现成本与效率的平衡。这种自主性，在当前AI军备竞赛，尤其是在GPU等异构算力极度稀缺的背景下，显得尤为重要。

孙伟祥，小红书容器研发专家，指出未来的规划将主要聚焦于两大方向：一是覆盖更多场景，例如AI训练和Spark大数据场景；二是持续进行能力迭代。值得关注的是，Karmada社区也正推动将Volcano调度器从单集群扩展到联邦集群，这与小红书将调度决策上移、提升准确性和时效性的判断不谋而合。[^1]

小红书的故事不仅仅是关于技术细节的胜利，更是一个关于**工程文化与战略远见**的案例。它深刻揭示了在云原生时代，企业如何通过对核心基础设施的精细化运营和自主创新，将挑战转化为竞争优势，为应对不确定的数字未来，构建起坚韧而高效的数字底座。

## 引用

[^1]: 小红书混合云迎战 TikTok 难民：一套调度系统撬动云上云下·InfoQ·孙伟祥 (2024/6/9)·检索日期2024/6/15
[^2]: 小红书混合云迎战TikTok 难民：一套调度系统撬动云上云下·网易· (2024/6/9)·检索日期2024/6/15
