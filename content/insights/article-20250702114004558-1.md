---
title: 当AI教会我们“写好”文章，我们是否正在失去深度与原创性？
date: 2025-07-02T11:40:04+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-07-Jul 2, 2025_11-31-25-480.jpg"
summary: 《纽约客》近期报道揭示，AI正在以“效率”为名重塑人类思维与写作方式，可能导致原创性与批判性思维的丧失。麻省理工学院和康奈尔大学的研究显示，过度依赖AI会降低大脑活动、导致思想同质化，并可能强化文化霸权。文章呼吁对AI带来的“平庸化革命”进行理性反思，警惕技术乐观主义的潜在风险。
tags: 
  - 人工智能
  - 语言模型
  - 写作
  - 创造力
  - 认知科学
  - 文化影响
  - 伦理
  - 社会影响
  - 同质化
  - 平庸化
main_topics: 
  - AIGC与内容科技
  - AI伦理与治理
  - 社会影响与未来工作
---

> 人工智能正以“平均值”的逻辑重塑我们的表达与思维，一系列最新研究表明，过度依赖AI可能导致认知负荷降低、思想趋于同质，甚至强化文化霸权。我们需警惕效率之名下，原创性与批判性思维的消逝，并对AI的“温和奇点”保持审慎反思。

当今时代，大型语言模型（LLMs）正以惊人的速度渗透到人类的创造性劳动中，尤其是写作。从撰写电子邮件到完成学术论文，AI工具的普及似乎预示着一个高效产出的新纪元。然而，正如《纽约客》杂志最近深入探讨的那样，这种效率的表象之下，可能隐藏着对人类思维结构和文化多样性更深层次的侵蚀。以“效率”为名，我们可能正在牺牲原创性；以“智能”之名，我们可能正在统一表达的风格与内容，最终让真正具有突破性的思想难以诞生。

### 认知负荷的下降与思维的趋同

麻省理工学院（MIT）进行的一项开创性实验，首次从科学角度量化了过度依赖AI所带来的认知代价。研究人员召集了50多名学生，让他们使用不同工具（纯脑力、Google搜索、ChatGPT）撰写议论文，同时监测他们的大脑活动。结果令人警醒：使用ChatGPT的学生，其大脑活动水平显著低于其他组别。大脑成像显示，他们不同脑区之间的连接更少，与创造力相关的α波连接度下降，与工作记忆相关的θ波连接度也降低。更甚者，部分学生对自己“写出”的文章“完全没有归属感”，高达80%的学生甚至无法复述自己刚刚创作的内容[^1]。这项研究清晰地揭示了，当AI承担了大部分认知工作时，人类大脑的参与度随之减弱，这不仅影响了对内容的记忆与理解，更可能削弱核心的认知功能。

除了个体认知的退化，该研究还发现，使用大语言模型的学生所写文本中，常用词汇和观点呈现出惊人的高度趋同。例如，在“什么让我们真正快乐”的讨论中，AI辅助组更倾向于聚焦事业成功与个人成就；而在慈善行为的道德义务议题上，他们几乎全体持支持态度，与人工写作组中出现的批判性思考形成鲜明对比。这验证了大型语言模型“平均化”的技术特性：它们通过分析海量数据中的模式进行训练，其生成的答案天然倾向于“共识”，无论是写作质量（常常充满陈词滥调），还是观点内容（往往流于平庸）。正如MIT媒体实验室研究科学家娜塔莉娅·科斯米娜（Nataliya Kosmyna）所言：“我们正在面对的是：一切被平均化的状态，一切，无处不在，全部变得中庸。”[^1]

### 文化均质化的潜在风险

AI带来的同质化问题远不止于此，它甚至可能悄然强化某种文化霸权。康奈尔大学今年4月发布的一项研究，进一步印证了AI对思想多样性的影响。该实验分为美国和印度两组用户，让他们回答与文化背景相关的写作题，部分参与者使用由ChatGPT驱动的“自动补全”工具。结果显示，使用AI辅助写作的印度和美国用户的答案风格趋同，并明显向“西方范式”靠拢。例如，他们最常提及的“最喜欢的食物”是披萨，最常提到的节日是圣诞节。即使是描述本土文化特色，AI的辅助也倾向于将表达泛化，而非深入具体细节，例如将“鸡肉炒饭”简化为“风味浓郁、香料丰富”，而省略了豆蔻或柠檬泡菜等标志性食材的描绘[^1]。

理论上，用户可以选择拒绝AI的建议，但康奈尔大学信息科学教授阿迪提亚·瓦希斯塔（Aditya Vashistha）将AI比作“一个坐在我身后、不停说‘这是更好的写法’的老师”。他的同事摩尔·那尔曼（Mor Naaman）更是指出，AI的建议“以一种隐蔽但强有力的方式，不只是改变你写了什么，而是改变你怎么想”。这种潜移默化的影响，可能导致人们对“什么才是正常的、可取的、恰当的”产生整体性偏移。

小说家兼记者沃希尼·瓦拉（Vauhini Vara）深刻指出，AI文字的平庸性“反而带来一种‘安全’与‘无害’的幻觉”。而现实是，这种“安全”的表象正在悄然强化某种文化霸权。对OpenAI这类公司而言，让模型输出“更容易被普遍接受”正是其商业动因——输出越“正常”、越无棱角，付费订阅用户基数就越大。这种平均化不仅带来效率，也促成了规模经济。瓦拉认为：“当一切都一样时，效率才是最高的。”[^1]

### AI乐观主义的盲点与反思

OpenAI首席执行官山姆·奥特曼（Sam Altman）曾将我们当前所处的阶段描述为“温和奇点”（gentle singularity），认为人类正与机器融合，AI工具是传统“大脑系统”的改进，能“显著放大用户的产出”。然而，若早期研究可信，这种“产出放大”可能要以质量下降和认知代价为代价。

加州圣塔克拉拉大学2024年的另一项数据分析进一步挑战了AI“自动化创造力”的论断。研究者发现，当人们在创意过程中使用AI时，往往会逐渐放弃原本的思考。生成式AI公司Midjourney的马克斯·克雷明斯基（Max Kreminski）解释说，用户在与ChatGPT交互时，会从最初带着自身想法介入，逐渐转变为一种“策展模式”（curationist mode），即倾向于从AI生成的大批内容中进行筛选。这种影响是单向的：“人类的想法往往无法强力影响机器的输出，”克雷明斯基说，“ChatGPT会将你拖向它所积累的用户平均值‘质心’。”当模型的“上下文窗口”被AI自身生成的内容饱和后，原创性也会随之降低[^1]。

我们已经在Meta的Meta AI应用中看到了这种趋势的体现：由数亿陌生人制作的AI图像、视频与文本滚动呈现，它们几乎都具有一种“过度抛光”的光滑质感。更令人不安的是，当用户向Meta的聊天机器人提问“AI是否有可能在未来超越人类智能？”时，模型给出的四种“未来情景”全都描绘了一幅美好蓝图：AI将变得更强大、更高效、更友善，并最终对整个人类社会带来益处。这种一边倒的乐观叙事，不仅很可能反映了系统设计中的“技术乐观主义”偏见，更关键的是，它以一种“中庸”的语气将潜在的复杂争议简化为和谐愿景，削弱了对话中本该存在的多元观点与思想张力。

这些早期且规模尚小的实验，无疑为我们提供了宝贵的警示。AI对人类思维与社会的长远影响仍需更深入的观察与研究。然而，如果我们在面对AI生成的“安全”且“平均”的内容时，不加辨别地接受，某种意义上就是停止了独立思考。当我们选择将大脑“关闭”，任由AI的“平均值”逻辑重构我们的文化景观，那么真正多元、深刻、富含批判性的思想火花，或许将变得前所未有的稀缺。这场由AI引发的“平庸化革命”，远比我们最初所设想的仅仅是效率提升，值得我们比技术热情更多的理性反思。

## 引用
[^1]: 《纽约客》：AI教会人类如何写“好”文章，却让真正的好文章消失了 ·腾讯科技·无忌 海伦（2025/7/1）·检索日期2025/7/2
[^2]: 《纽约客》：AI教會人類如何寫「好」文章，卻讓真正的好文章消失了 ·DayDayNews（2025/7/1）·检索日期2025/7/2
[^3]: OpenAI首次停摆的背后 ·36氪（2025/7/1）·检索日期2025/7/2
[^4]: 文章_标签 ·网易出品（2025/7/1）·检索日期2025/7/2
[^5]: 特德·姜的论文：“为什么人工智能不会创作艺术” : r/printSF ·Reddit（未知日期）·检索日期2025/7/2
