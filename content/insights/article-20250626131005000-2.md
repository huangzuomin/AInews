---
title: 人工智能的“阅览室”：美国法院裁定AI模型可合法训练于已购书籍，重塑版权与创新的界限
date: 2025-06-26T13:10:05+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-06-Jun 26, 2025_13-02-05-914.jpg"
summary: 美国法院最新裁定，允许Anthropic等AI公司在未经作者同意的情况下，使用**合法购买**的已出版书籍训练其大型语言模型，援引“合理使用”原则，将其视为一种“转化性使用”。这一里程碑式的判决为AI模型的数据获取降低了版权风险，但同时强调了盗版内容使用的非法性，并引发了关于版权保护与技术创新之间平衡的深刻讨论。该判决在参考Google Books和GitHub Copilot等历史案例的基础上，可能对OpenAI和Meta等公司的类似版权诉讼产生影响，预示着未来围绕AI数据来源和知识产权的新一轮法律和伦理博弈。
tags: 
  - AI训练
  - 版权法
  - 合理使用
  - 转化性使用
  - Anthropic
  - 大型语言模型
  - 知识产权
  - 技术创新
  - 社会影响
  - 法律判决
main_topics: 
  - AI伦理与治理
  - 数据与开源生态
  - 产业生态与商业版图
---

> 美国法院最新裁定，允许Anthropic等AI公司在未经作者同意的情况下，使用**合法购买**的已出版书籍训练其大型语言模型，援引“合理使用”原则，将其视为一种“转化性使用”。这一里程碑式的判决为AI模型的数据获取降低了版权风险，但同时强调了盗版内容使用的非法性，并引发了关于版权保护与技术创新之间平衡的深刻讨论。

数字时代，版权与创新间的张力从未像现在这般尖锐。近日，美国法院的一项裁决如同一石激起千层浪，重新定义了人工智能在知识海洋中“阅读”和“学习”的边界。该判决允许大型语言模型（LLMs）开发者在未经作者明确许可的情况下，使用**合法购买**的已出版书籍进行模型训练。这一决定，对于快速发展的AI行业而言，无疑注入了一剂强心针，但同时也预示着一场关于知识产权未来形态的深刻变革。

### 裁决细节与“合理使用”的边界

此次判决源于三位作家在2024年8月对Anthropic（Claude模型背后的公司）发起的诉讼。核心争议点在于Anthropic未经创作者允许，使用了大量书籍来训练其AI模型。法院的裁决文书，深入剖析了美国版权法中的“合理使用”（Fair Use）原则，将其应用于AI训练的语境。

法院认定，AI训练属于一种“转化性使用”（Transformative Use）[^1]。这意味着，对原作品的新用途并未直接取代原作品的市场价值，反而创造了新的价值或功能，且有利于技术创新和公共利益。法庭认为，模型对书籍内容的摄取，并非为了复制原文以替代原作的销售，而是为了从中提取模式、语言结构、叙事风格等抽象特征，以生成全新的、非模仿性的内容。因此，这种内部的“阅读”和“理解”过程，被视为一种高度转化性的行为。

然而，裁决并非全盘绿灯。法院明确区分了数据来源的合法性。虽然允许使用合法采购书籍的扫描副本进行训练，但对于Anthropic此前从盗版网站（如LibGen和PiLiMi）获取并使用的数百万份书籍副本，法院裁定其**不构成合理使用，盗版行为本身涉及侵权**。这意味着，Anthropic在模型训练初期对盗版内容的依赖，仍需面临独立的审判和赔偿责任[^1]。这一区分至关重要，它为AI公司划定了清晰的红线：创新可以被鼓励，但前提是必须建立在合法合规的基础之上。

### 历史判例与行业震荡

Anthropic案并非孤例，它根植于美国司法系统长期以来在“技术创新vs.版权保护”拉锯战中的探索。在过去十年中，类似的版权纠纷曾多次将技术巨头推向风口浪尖：

*   **2015年Google Books案**：美国最高法院最终认定Google将数千万册图书扫描并数字化，提供部分片段浏览功能，属于“合理使用”[^2]。法院认为，Google Books将阅读转化为信息检索，并未直接替代原作市场，反而促进了学术研究和图书发现。这一判例为本次Anthropic案的“转化性使用”概念奠定了重要基础。
*   **2022年GitHub Copilot案**：作为一款AI编程助手，GitHub Copilot因训练使用了大量开源代码（包括带有“传染性”许可证的代码）而遭到指控。法院初步认定AI训练使用开源代码属于“转化性使用”，不构成直接侵权。尽管如此，此案促使GitHub推出了“代码来源检测”功能，旨在帮助用户识别生成代码与开源项目的关联性，并尊重原许可证要求[^3]。

这些案例的共同点在于，美国法院在权衡技术进步与知识产权时，往往倾向于支持那些能够带来广泛公共利益的“转化性”创新。本次Anthropic案的裁决，进一步巩固了这一司法倾向，使得AI公司在获取训练数据方面的版权风险大大降低，尤其是在合法获取内容的途径上。

这一判决预计将对目前悬而未决的**2023年OpenAI和Meta案件**产生深远影响[^4]。这两家公司同样面临作家和出版商的指控，称其使用盗版数据（如“影子图书馆”中的书籍）训练ChatGPT和Llama模型。Anthropic案明确区分合法与非法来源的判决，可能为OpenAI和Meta案件的审理提供重要的参照，即：模型训练的合法性并非绝对，而是取决于其所使用数据的来源是否合法。

### 版权与创新的未来张力

此次裁决引发了社会各界的激烈讨论。一方面，许多技术爱好者和AI开发者认为，这如同人类可以合法购买书籍进行阅读和学习一样，AI的“阅读”行为也应被视为理所当然。他们认为，这将极大推动AI技术的发展，并最终惠及整个社会。

另一方面，作家、艺术家等内容创作者则深感忧虑。他们质疑：AI的学习过程是否真的能与人类阅读一概而论？当AI模型能够“消化”海量受版权保护的作品后，其生成的内容又将如何影响原作品的市场？创作者的劳动成果和知识产权，又该如何在新范式下得到公平的保护和回报？

> “这是一个正确的决定，就像人类可以去图书馆或者读自己买的书一样自然。”一位网友的评论，反映了技术乐观派的普遍看法。而另一位网友则反问道：“AI可以和人类一概而论吗？创作者又该如何保护他们的知识？”[^1]

这种张力是AI时代不可避免的哲学与经济困境。法院的裁决，虽然在一定程度上为AI公司解除了束缚，但并未完全解决版权保护的深层问题。未来，我们可能需要看到更加精细化的法律框架，例如，建立合理的版税机制或内容使用许可平台，确保AI训练数据的合法性、透明度，并在经济上合理补偿创作者。

这场围绕AI“阅读权”的法律战役，仅仅是AI技术对社会、伦理、经济产生深层影响的一个缩影。随着AI能力边界的不断拓展，类似的法律和伦理挑战将层出不穷。如何在这场创新浪潮中，既能释放技术的巨大潜力，又能维护社会公平和知识产权的基石，将是人类社会需要持续探索的宏大课题。

## 引用
[^1]: AI“读书”合法了：美法院最新裁定，无需作者同意，已购书籍可用于训练AI·量子位·不圆 (2025/6/26)·检索日期2025/6/26
[^2]: AI“读书”合法了：美法院最新裁定，无需作者同意，已购书籍可用于训练AI·36氪 (2025/6/26)·检索日期2025/6/26
[^3]: 美法院最新裁定，无需作者同意，已购书籍可用于训练AI - 新浪财经·新浪财经 (2025/6/26)·检索日期2025/6/26
[^4]: AI“读书”合法了：美法院最新裁定，无需作者同意，已购书籍可用于训练AI·36氪 (2025/6/26)·检索日期2025/6/26
