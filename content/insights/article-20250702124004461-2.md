---
title: 当AI“记忆”成为侵权：科技巨头与知识产权的迷失边界
date: 2025-07-02T12:40:04+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-07-Jul 2, 2025_12-34-34-195.jpg"
summary: 一项斯坦福研究发现Meta的Llama等大型语言模型能“复刻”《哈利波特》等受版权保护书籍的90%内容，暴露了训练数据中普遍存在的版权问题。尽管Meta在随后的诉讼中因版权方未能证明市场损害而获胜，但AI行业普遍依赖含有盗版内容的Books3数据集的现实，以及Anthropic为规避侵权而销毁实体书的极端做法，凸显了AI技术发展与知识产权保护之间日益激化的伦理与法律矛盾。
tags: 
  - AI
  - 版权
  - 大型语言模型
  - 数据集
  - 法律诉讼
  - 伦理
  - 著作权
  - 生成式AI
  - Meta
  - Anthropic
main_topics: 
  - 数据与开源生态
  - AI伦理与治理
  - 产业生态与商业版图
---

> 大型语言模型对受版权保护内容的“记忆”能力，引发了史无前例的法律挑战和伦理困境。尽管Meta在与作家的诉讼中暂时获胜，但这场围绕数据所有权与“合理使用”的战役远未结束，甚至催生了焚毁实体书以规避侵权的荒谬之举，预示着AI时代知识产权保护的深层矛盾。

最近，一则关于Meta旗下大型语言模型Llama的发现，在AI界与知识产权领域激起轩然大波：一项来自斯坦福大学的研究揭示，Llama能够“复刻”超过90%的《哈利波特与魔法石》全文。这一惊人“记忆力”的背后，暴露了AI训练数据中版权侵犯的深层问题，并点燃了新一轮关于AI技术与现有法律框架之间冲突的争论。令人意想不到的是，尽管证据确凿，Meta竟在随后的版权诉讼中获得了胜利，这不禁让人反思，我们如何界定人工智能时代的知识财产边界？

### 技术原理与数据之殇

大型语言模型（LLMs）的强大能力，根植于其对海量文本数据的学习。研究人员通过简单的“古诗词默写”式提示——即提供书中的上半句，观察Llama能否一字不差地接出下半句——发现《哈利波特与魔法石》有高达91.14%的内容能被Llama原封不动地“背诵”出来[^1]。这并非Llama独有的现象，Pythia、Gemma、Phi等其他主流模型也不同程度地展现出这种对训练数据的“记忆”能力。这种现象不仅意味着模型掌握了语言模式，更深层次地表明，它在训练过程中对特定文本形成了近乎照搬的记忆副本。

问题的核心指向了名为Books3的数据集。这个包含近20万本txt格式书籍的数据集，因其丰富的文本内容而被广泛应用于各类大型语言模型的训练。然而，Books3的“丰富”背后，是大量未经授权、甚至盗版的书籍。尽管Books3在明面上已被下架，成为“不能说的秘密”[^1]，但其对早期及当前多数模型的深远影响却难以抹去。这揭示了一个核心矛盾：AI模型对高质量、大规模数据的贪婪需求，与现有版权保护体系的固有壁垒形成了直接冲突。科技公司在追求模型性能突破的同时，往往难以避免触及法律红线，而Books3这类“灰色地带”的数据集，便是这种困境的直接产物。

### 法律交锋与模糊地带

Llama的“记忆”事件迅速升级为法律诉讼。Meta被13位作家集体告上法庭，指控其未经授权使用受版权保护的作品进行模型训练，并能够原样输出，构成侵权。然而，出乎意料的是，Meta最终赢得了这场官司。这一判决的核心在于，版权方未能提供充分证据证明大模型的输出与原作品在市场上直接竞争，从而损害了他们的销量[^1]。

Meta的辩词援引了美国版权法的“合理使用”原则，声称AI对作品的复制和转化，创造出了“新作品”，与训练用的书籍有着根本性的不同。用人话讲，AI的输出是其学习理解后转述的产物，类似于人类阅读后写作，应被视为具有创造性的“新作品”。法官虽然承认使用盗版训练数据“不地道”，但在缺乏直接经济损害证明的情况下，驳回了作家的诉讼请求。

这并非个例，而是AI时代版权纠纷浪潮中的一朵浪花。从《纽约时报》起诉OpenAI训练集侵权，到Reddit起诉Claude，再到迪士尼和环球影业联合起诉Midjourney，以及作家团体与微软Megatron的官司[^1]——每一次诉讼都将AI技术推向了法律雷区。这些案件凸显了现有版权法在应对生成式AI独特运作方式时的滞后性与不确定性。AI的“学习”与“生成”过程是否等同于传统意义上的“复制”？模型输出的内容又该如何归类？这些根本性问题，尚待法律给出明确的答案。

### 伦理困境与未来路径

面对层出不穷的法律风险，科技公司正在探索各种“预防手段”。谷歌选择直接买断Reddit等网站的数据包，以确保数据的合法性。然而，有些公司的做法则令人咋舌，甚至引发了深刻的伦理争议。

以Claude背后的Anthropic公司为例。为了避免使用盗版数据集的法律风险，该公司斥资数百万美元购买了大量的实体图书。更令人震惊的是，为了迎合美国“首次销售原则”（First-Sale Doctrine）——即合法购买的实体书可在后续进行任何处理，包括扫描——Anthropic在将这些书籍扫描入库并用于模型训练后，立即将其销毁。这一举动，被视为Anthropic在法庭上的“制胜一击”，因为它理论上规避了版权问题。然而，为了避免侵权而“焚书”的行为，无疑触及了人类文明对于知识和文化的尊重底线。这让人不禁反思，为了技术发展和法律合规，我们是否正在付出过高的伦理代价？

> “争取权益是必要的，但在这场争端里，恐怕没有真正的赢家。”[^1]

当前的局面，是科技发展对数据质量的无限渴求，与传统知识产权保护体系之间的不可调和矛盾。从大模型开发者的角度看，技术迭代不等人，也没有时间等待漫长的授权谈判；他们能做的，或许只有尽量“规避”直接侵权，或寄希望于法律对“合理使用”的更宽泛解释。而对版权方而言，AI模型对作品的“吞噬”不仅损害了眼前利益，更可能在未来被盗版训练出的模型所取代，彻底颠覆现有的创作与回报模式。

这种深层次的结构性冲突，正在将我们引向一个荒谬的十字路口。Anthropic的“焚书”举动，是这一困境的极端体现。它揭示了在新的技术范式面前，旧有规则的捉襟见肘，以及各方在权衡利弊时所作出的艰难甚至令人不安的选择。如何在大模型所代表的科技进步与创作者的合法权益之间找到可持续的平衡点，避免对知识遗产造成不可逆的损害，将是未来几年亟需解决的全球性挑战。这需要法律、技术、伦理各界的深度对话与创新合作，而非仅仅是法庭上的针锋相对。

## 引用

[^1]: [复刻90%哈利波特，洗无可洗的Meta居然赢了？](https://m.36kr.com/p/3361239019718405)· 36氪 · 莫莫莫甜甜 (2025/7/2) · 检索日期2024/06/28
[^2]: [从开源大模型中提取（受版权保护的）书籍的记忆片段](https://arxiv.org/pdf/2505.12546)· arXiv · (2025/5/12) · 检索日期2024/06/28
[^3]: [Study: Meta’s Llama 3.1 can recall 42 percent of the first Harry Potter book](https://arstechnica.com/features/2025/06/study-metas-llama-3-1-can-recall-42-percent-of-the-first-harry-potter-book/) · Ars Technica · (2025/6) · 检索日期2024/06/28
[^4]: [The AI community needs to take copyright seriously](https://www.understandingai.org/p/the-ai-community-needs-to-take-copyright) · Understanding AI · Simon Willison (2025/5/17) · 检索日期2024/06/28
[^5]: [Books3](https://paperswithcode.com/dataset/books3) · Papers With Code · (未知) · 检索日期2024/06/28
