---
title: "超越参数堆叠：复旦邱锡鹏教授力推“情境智能”，探索通往AGI的下一幕"
date: 2025-06-16T08:30:04+08:00
draft: false
summary: "复旦大学邱锡鹏教授提出“Context Scaling”新范式，旨在让AI通过深度理解复杂、模糊的情境信息（情境智能），而非简单扩大参数或数据，来捕获人类的“暗知识”。这一路径被视为通往通用人工智能（AGI）的关键一步，它强调强交互性、具身性和拟人化三大支柱，并要求模型在固定参数下通过情境积累实现持续学习，以应对现有大模型在处理难以描述问题时的局限性。"
tags: 
  - "AI"
  - "通用人工智能"
  - "Context Scaling"
  - "邱锡鹏"
  - "大语言模型"
  - "情境智能"
  - "暗知识"
  - "深度学习"
main_topics: 
  - "通用人工智能发展"
  - "AI情境理解"
  - "大模型新范式"
---

> 在AI领域集体追问“扩展什么”的背景下，复旦大学邱锡鹏教授提出了“Context Scaling”新范式，旨在通过让AI深度理解复杂、模糊的情境信息，而非简单堆叠参数或数据，捕获人类智能中的“暗知识”，为实现真正的情境智能和通用人工智能（AGI）奠定基础。

2024年底，当OpenAI联合创始人Ilya Sutskever掷地有声地预言“我们所知的预训练时代即将终结”时，整个AI界为之震动，并迅速陷入一场关于“Scaling What”（究竟该扩展什么）的集体追问。面对大模型参数和数据规模化收益递减的现实，研究者们纷纷探索新的增长点：从推理时扩展（Test-Time Scaling）到强化学习的突破，从强化学习Self-play到Agent化路径，每一次尝试都指向可能的下一个跃迁。正是在这场前沿技术探讨中，来自复旦大学/上海创智学院的邱锡鹏教授，一位在自然语言处理及大语言模型领域深耕的学者，并曾主持开发了MOSS、FudanNLP等知名项目的领军人物[^1][^2]，提出了一种耐人寻味且更具深远意义的新路径——**Context Scaling**。

不同于传统关注“更大”的扩展路线，Context Scaling的核心在于追求“更深”：它聚焦于如何让人工智能真正理解并适应复杂、多变、模糊的情境。邱锡鹏教授将大模型的演进分为“AGI三幕”，并强调情境智能（Contextual Intelligence）将是迈向通用人工智能（AGI）的关键第三幕。

### 情境智能：超越上下文窗口的深度理解

在邱锡鹏教授的“AGI三幕”理论中，第一幕是模型规模化的胜利，通过海量数据和参数堆叠，实现了通用任务上的跃升。然而，随着数据量达到瓶颈和参数规模收益递减，单纯的加法已难以为继。第二幕则转向后训练优化，通过推理增强、知识具象化等手段，提升大模型解决复杂问题的决策能力。当这两幕发展到一定阶段，如何定义和理解“情境”（Context）便成为继续提升模型能力的核心挑战。当前大模型对任务或情境描述的局限性，导致它们难以处理那些模糊不清、无法用明确规则定义的复杂交互。

而这正是Context Scaling所要解决的问题，它旨在实现“情境智能”：让AI能够理解并适应足够丰富、真实、复杂、多变的情境信息，**从而在模糊不清的世界中作出合情合理的判断**。

邱锡鹏教授指出，这里的“Context”远非当前大模型简单的“上下文窗口”概念，它是一种多维、动态、跨模态的信息结构，可能包含时间、空间、参与者状态、目标意图，甚至是未明说的文化规则与人际默契。最关键的，是Context Scaling对**“暗知识”（Tacit Knowledge）**的捕获能力。所谓“暗知识”，指的是人类习得但难以清晰表述的隐性能力，例如：

*   **社交智能**：解读眼神、停顿、语调的变化。
*   **文化适应**：在不同文化背景中得体行事，理解未说出口的社会规则。
*   **情境判断**：区分同一句话语在不同情境下的不同含义（如“不要”可能表示拒绝，也可能是玩笑或反向请求）。
*   **动态适应**：在变化的环境中持续调整策略和理解。

正是这些难以言述的隐性知识，构成了人类智能的底色。若AI能通过深度情境理解捕获这些结构模糊、路径多变的信息，将实现真正意义上的智能突破。同时，这也是对AI安全发展的核心考量。当前大模型若仅遵循狭义目标（如“回形针悖论”），可能做出威胁人类社会的行为。Context Scaling通过让AI理解复杂的社会情境和隐含价值观，使其在没有明确禁令的情况下，也能基于对情境的深度理解，做出符合人类价值观的判断。

### 实现情境智能的三大技术支柱

邱锡鹏教授进一步阐述，Context Scaling之所以能成为一个独立的技术路径，源于其独特的三项能力支柱：

1.  **强交互性（Strong Interactivity）**：情境智能的本质在于“从交互中学习”。这不仅包括与环境的强化学习式交互，更要求AI能够进行深层次的多模态人机协作，如语言澄清、任务讨论、甚至情绪共鸣。它要求AI理解用户的情绪状态、文化背景和未说出口的期望，从而从持续互动中汲取信息，具备面对复杂情境的应变能力。
2.  **具身性（Embodiment）**：AI要能交互并理解所处世界，智能体必须具备“主体性”，即感知、行动、记忆与学习的能力。这并不意味着必须拥有现实物理世界的身体，虚拟环境中的持续任务代理或AR场景中的决策代理，都是这一理念的试验场。
3.  **拟人化（Anthropomorphizing）**：这是Context Scaling独有的特征——AI需要具备类人的情感共鸣和反馈能力。这并非简单的情感模拟，而是对人类偏好和行为模式的深度理解，包括理解和回应人类情绪、掌握复杂人际交往规则、懂得何时保持距离或表达关心，以及具备文化敏感性。

为了实现上述三点，Context Scaling要求模型具备**持续学习**的能力。不同于传统的持续学习，情境智能的持续学习更强调在模型参数相对固定的情况下，通过Context的积累和更新，实现能力的持续提升。这更像是人类的成长与发展，在先天基因确定的情况下，通过后天学习和不断适应新环境，根据具体情境调整行为策略。

### 挑战与前瞻：通往AGI的新范式

尽管前景广阔，Context Scaling的实现仍面临几大技术挑战：

*   **模型结构的突破**：现有Transformer架构在长上下文处理上的效率受限，要支持多模态、交互式、动态变化的情境输入，模型架构本身可能需要根本性重构。
*   **学习范式的转变**：需要从传统监督学习转向交互式、持续式的弱监督、多反馈学习，以及在新情境中快速适应的元学习能力。Context Scaling所需的训练目标与损失函数正在重塑AI学习的本质。
*   **复杂情境的定义与构建**：复杂情境难以靠人工构建，也无法通过真实世界逐一采集。大规模情境数据的生成，可能需要借助AI自身合成场景、任务、交互脚本的能力。

邱锡鹏教授强调，Context Scaling并非替代其他Scaling路线，而是对其构成补充与整合。例如，它能为推理时扩展（Test-Time Scaling）提供更丰富、高质量的上下文信息基础。与Agent路径相比，Context Scaling更多是对任务定义层的重新设想，强调智能体理解复杂情境的核心能力，这种能力可以通过各种Agent架构来实现，但其本身超越了具体的工具使用和任务执行。它也为强化学习提供了新的环境定义，不再是简单的状态-动作-奖励循环，而是包含丰富情境信息的复杂交互空间。

“在大模型时代，如果研究只是在已有路径上做微调，那将失去方向感。”邱锡鹏教授指出，“研究者需要去定义那些‘大家都意识到但没人清晰表达’的问题。” 在这场关于“Scaling What”的集体探索中，Context Scaling将推理增强、多模态融合、强化学习等看似分散的技术路径统一在“情境理解”这一核心目标之下。智能的本质，或许正是在面对复杂世界时那份模糊中的准确、不确定中的判断、冲突中的协调。从这个意义上讲，Context Scaling不仅是大模型发展的下一幕，更可能是通向通用人工智能（AGI）的关键一步。

## References
[^1]: 复旦大学邱锡鹏教授：解读大型语言模型的能力分析与应用（2023/3/2）。智源社区。检索日期2025/6/16。
[^2]: 邱锡鹏（未知）。Fudan University。检索日期2025/6/16。
[^3]: 邱锡鹏（未知）。xpqiu.github.io。检索日期2025/6/16。
[^4]: Acl'22 | 一文解读复旦黄萱菁、邱锡鹏等老师nlp实验室的12篇长文（2022/3/1）。知乎。检索日期2025/6/16。
[^5]: Focused Transformer: Contrastive Training for Context Scaling（2023/7/5）。arxiv.org。检索日期2025/6/16。
[^6]: 机器之心（未知）。复旦大学/上海创智学院邱锡鹏：Context Scaling，通往AGI的下一幕。微信公众号。检索日期2025/6/16。
