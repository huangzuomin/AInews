---
title: 游戏教父John Carmack：为何大型语言模型并非游戏智能的未来
date: 2025-07-02T13:34:03+08:00
draft: false
featured_image: "/newsimages/selected_image_YYYY-07-Jul 2, 2025_13-02-55-059.jpg"
summary: 游戏界传奇人物约翰·卡马克指出，大型语言模型（LLM）并非游戏或通用人工智能的未来，因其“无所不知却又无所学”的预训练模式难以适应高效的交互式学习。他正通过在Atari平台上的具身智能和强化学习研究，解决AI在数据效率、灾难性遗忘和物理世界交互等方面的核心挑战，旨在推动AI向更接近人类的智能迈进。
tags: 
  - John Carmack
  - LLM
  - 强化学习
  - 具身智能
  - Atari游戏
  - 灾难性遗忘
  - 迁移学习
  - AI Agent
  - 人工通用智能
main_topics: 
  - 前沿模型与算法
  - AI Agent与自主系统
  - 机器人与具身智能
---

> 游戏界传奇人物约翰·卡马克（John Carmack）对其在人工智能领域的最新研究提出见解，强调大型语言模型（LLM）并非游戏或通用人工智能的终极路径。他主张通过强化学习和具身智能的实践，解决AI在现实世界中面临的数据效率、灾难性遗忘和迁移学习等深层挑战。

在瞬息万变的AI领域，大型语言模型（LLM）无疑是近年来最受瞩目的技术突破，它们以前所未有的规模和能力重塑着人机交互的范式。然而，一位来自另一个前沿领域的巨擘——游戏界教父、Id Software、Armadillo Aerospace和Oculus的联合创始人约翰·卡马克（John Carmack）——却对LLM在未来游戏AI中的核心地位提出了质疑。他认为，虽然LLM成就斐然，但在构建真正具备交互式学习能力的智能体方面，其本质的“无所不知却又无所学”特性存在根本性局限，这与人类和动物通过“交互式体验流”学习的模式截然不同。[^1]

### Carmack的AI哲学：为何LLM不是游戏AI的终极答案

卡马克在过去三十年间，一直是科技前沿的探路者。从90年代初开创3D游戏引擎，推动GPU发展，到后来投身火箭科学，再到为现代虚拟现实奠定技术基石，他始终站在计算极限的边缘。如今，这位传奇工程师将目光转向人工智能，加入了Keen Technologies，并与强化学习之父理查德·萨顿（Richard Sutton）并肩工作。他坦言，尽管曾被OpenAI创始人招揽，但他选择了避开LLM领域，专注于更深层次的智能体学习问题。

卡马克的核心论点在于，LLM的预训练方式，即从海量“大杂烩”数据中学习，使其在知识广度上令人惊叹，但在特定环境下的**高效互动式学习**和**行为适应**方面却显得力不从心。他提出质疑：“你能要求LLM学习如何在它的训练集里从未见过的环境中有良好的表现吗？即使这种方法在理论上可行，但可能极其低效，将是一个重要的‘苦涩教训’。”[^1] 这揭示了符号智能与具身智能之间的鸿沟：LLM擅长理解和生成文本，却缺乏在动态、不确定环境中通过试错和反馈循环来构建世界模型的内在机制。

他回忆DeepMind在2013年利用图像输出学习Atari游戏的案例，虽然令人印象深刻，但其**数据效率**低下——模型需要连续玩游戏一个多月才能达到人类数小时的学习效果。这种效率差距，正是强化学习（RL）领域亟待解决的根本性问题，也是他选择专注于此的原因。

### 具身智能的真实挑战：Atari平台上的深层困境

卡马克将其研究重心放在Atari游戏上，并非因为问题已经解决，而是因为其中蕴藏着通往通用智能的诸多未解之谜。他指出，商业游戏提供了一个无偏见且多样化的测试平台，能够揭示AI算法在不同情境下的普适性和局限性。而他的团队更进一步，构建了一个**物理Atari 2600+系统**，让AI智能体通过摄像头观察真实屏幕、机械臂操作物理操纵杆来学习游戏。[^1]

这个看似“复古”的设置，实则旨在揭示现实世界对AI提出的严苛要求：

*   **速度与延迟**：现实世界不会像回合制游戏那样等待智能体响应。物理系统中的帧率、动作执行速度和不可避免的延迟，对算法的实时性和鲁棒性提出了挑战。许多现代高性能RL算法在遇到非即时反馈时会“崩溃”，因为它们假设了一种类似棋盘游戏的即时行动-效果行为。
*   **物理交互的复杂性**：从可靠地读取CRT显示器上的分数（出乎意料的难题）到伺服电机控制操纵杆的变异性，物理交互引入了模拟环境中难以捕捉的噪声和不确定性。
*   **稀疏奖励与内在好奇心**：大多数现实世界的任务奖励是稀疏的（例如，只有达成目标才有奖励），这与RL算法通常需要的密集奖励形成矛盾。卡马克探讨了如何通过内在奖励机制，模拟人类的“好奇心”，驱动智能体在缺乏外部奖励的情况下进行探索。

这些挑战使得训练AI玩物理游戏成为对“完全具身AI即将实现”这一论断的现实检验。他提出，如果一个跳舞的人形机器人连拿起操纵杆学习玩一款冷门电子游戏都做不到，那么谈论其具备通用智能还为时尚早。

### 迈向真正通用智能的崎岖之路

卡马克的研究不仅停留在游戏本身，更深入探讨了实现通用人工智能（AGI）所需的根本性突破。他关注的核心问题包括：

*   **串行多任务学习与灾难性遗忘**：当前AI系统可以并行学习多项任务，但若要求其像人类一样，在精通一项任务后学习另一项，再回到旧任务时仍能迅速恢复熟练度，这在现有在线学习模型中几乎不可能。神经网络存在强烈的“近期偏差”，极易发生“_灾难性遗忘_”，即学习新知识时遗忘旧知识。卡马克认为，这可能是深度学习中“可塑性丧失”的一种体现，类似于生物大脑的衰老过程——“老狗学不了新把戏”。
*   **迁移学习与泛化能力**：理想的智能体应在掌握数十款游戏后，能更有效地开始学习新游戏。然而，目前许多模型（如GATO）甚至出现“_负迁移学习_”现象，即并行学习其他游戏后，学习新游戏反而变得更困难。这凸显了AI在可塑性（学习新模式）与泛化（忽略细节）之间可能存在的内在冲突。
*   **函数近似的性能主导**：在强化学习中，作为“黑箱”的神经网络（函数近似器）其内部实现对性能起着决定性作用。卡马克深入探讨了CNN架构、激活函数、损失函数和优化器等底层组件的相互作用，以及它们如何影响AI从经验中泛化、平均并更新价值的能力。他指出，即使是像Adam这样“出奇地难以被击败”的优化器，也无法完全解决当今模型在复杂任务中表现出的根本性问题。

卡马克的洞察力在于，他没有被当下AI的表面成就所迷惑，而是直指其最深层次的结构性挑战。他所描绘的，是一条崎岖而充满未知的道路，但也是一条通往真正具备人类级学习、适应和通用智能的关键路径。他的研究，不仅是对游戏AI未来的探索，更是对整个AI领域，特别是具身智能和持续学习范式的深刻反思。

## 引用

[^1]: [Games and RL](https://docs.google.com/document/d/1-Fqc6R6FdngRlxe9gi49PRvU97R83O7ZTN_KFXo_jf0/)·John Carmack（2024/6/11）·检索日期2024/6/11
[^2]: [游戏教父John Carmack：LLM 不是游戏的未来](https://www.infoq.cn/article/1UBuM8APTi0TUgIdiiBg)·InfoQ·John Carmark（译者：明知山）（2025/6/11）·检索日期2024/6/11
[^3]: [游戏教父John Carmack：LLM 不是游戏的未来](https://www.xuexiaigc.com/aigcnews/%E6%B8%B8%E6%88%8F%E6%95%99%E7%88%B6-John-Carmack%EF%BC%9ALLM-%E4%B8%8D%E6%98%AF%E6%B8%B8%E6%88%8F%E7%9A%84%E6%9C%AA%E6%9D%A5/)·学习AIGC·（2024/6/11）·检索日期2024/6/11
[^4]: [游戏教父John Carmack：LLM 不是游戏的未来](https://cj.sina.com.cn/articles/view/1746173800/68147f6801901cng8?froms=ggmp)·新浪财经·InfoQ（2025/6/11）·检索日期2024/6/11
