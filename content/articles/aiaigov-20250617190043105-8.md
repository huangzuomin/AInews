---
title: 特朗普「全政府AI计划」意外泄密：AI.gov的宏伟蓝图、潜在风险与伦理困境
date: 2025-06-17T19:00:43+08:00
draft: false
summary: 特朗普政府代号“ai.gov”的“全政府AI计划”在GitHub上意外泄露，揭示了其在7月4日独立日前将AI聊天机器人、通用API和监控工具全面引入联邦政府的宏大目标。该计划旨在大幅提升政府效率和自动化，但引发了外界对敏感数据安全、与老旧系统集成的技术可行性、以及AI在公共服务中可能导致大规模裁员和算法偏见等深层伦理社会影响的严重担忧。
tags: 
  - 人工智能
  - 政府治理
  - 数据泄露
  - 伦理风险
  - 就业影响
  - 技术转型
  - 网络安全
  - 特朗普政府
main_topics: 
  - 政府AI化
  - 技术治理挑战
  - AI社会影响
---

> 特朗普政府一项雄心勃勃的“全政府AI计划”——ai.gov网站，在正式上线前意外通过GitHub泄露。该计划旨在通过引入AI聊天机器人、通用API和实时监控工具，大幅推动联邦政府运作自动化，但同时引发了关于数据安全、技术可行性以及对公共服务和劳动力影响的深刻质疑。

一场关于政府秘密项目的意外泄露，往往能迅速吸引公众的目光。然而，当这一项目是一项旨在将人工智能（AI）大规模嵌入联邦政府几乎每一个角落的宏伟技术计划时，其重要性以及随之而来的争议便会被无限放大。这正是特朗普政府“全政府AI计划”——_ai.gov_所遭遇的境况：该计划意外通过GitHub泄露，揭示了一个雄心勃勃的愿景，即最早在7月4日美国独立日之前，就实现大范围的公共服务自动化。这次提前曝光不仅揭开了关键战略转变的面纱，也立即凸显了这一宏大技术事业所固有的深刻挑战、伦理困境以及根本性的社会问题。

### 计划揭秘：一个雄心勃勃的蓝图

这项计划的核心人物是托马斯·谢德（Thomas Shedd），美国总务管理局（GSA）技术转型服务（TTS）小组的新任负责人。谢德曾是特斯拉的软件集成工程经理，并以与埃隆·马斯克的密切关系而闻名。自1月底上任以来，他便将AI置于其工作的首要位置。正如泄露的GitHub仓库所暗示的那样，他的愿景是**将GSA转变为一个类似科技初创公司的敏捷、技术驱动型实体**，并推行一项“全政府AI优先”战略。据称，其明确目标是**自动化目前由联邦雇员完成的大部分工作** [^1]。

这份现已被归档的_ai.gov_GitHub仓库——在媒体问询后迅速下线，但仍可供细心者查阅 [^2]——概述了一个多功能平台，旨在成为联邦政府各部门采用AI的中央枢纽。它包含三大核心组件：

*   **可操作聊天机器人（Actionable Chatbots）：** 这些对话式AI代理旨在执行特定操作，从而简化政府机构内部的互动和流程。
*   **“超级API”（Super API）：** 这可能是技术上最雄心勃勃的组件，该应用程序编程接口旨在建立政府系统与来自**OpenAI、谷歌、Anthropic**乃至**Meta的LLaMA**等领先AI模型之间的直接连接。API文档进一步表明，该计划将依赖**亚马逊网络服务（AWS）的Bedrock**来提供大部分这些模型，其中多数已获得FedRAMP认证——这是美国政府使用云服务的一项关键安全授权 [^3]。然而，文档也指出，另一个知名的AI模型提供商Cohere的模型似乎尚未获得这项关键认证。
*   **CONSOLE：** 一款“革命性的”监控工具，旨在实时监测各部门的AI使用情况，追踪员工偏爱哪些工具以及他们如何与AI系统互动 [^1]。

除了这些平台级工具，谢德的更广泛抱负，在404 Media获得的一段泄露会议录音中得以揭示，包括开发**AI编程助手**以帮助政府各部门编写代码，以及利用AI对**政府合同进行高级分析** [^1]。推动效率的背后，是近期关于AI可能取代国税局（IRS）、证券交易委员会（SEC）和退伍军人事务部（VA）等部门因大规模裁员而离职人员的报道 [^1]。这一趋势表明，AI正在从一种单纯的辅助工具，向公共服务领域人类劳动的直接替代品迈进，这无疑是一个深刻的转变。

### 技术实现与潜在风险

_ai.gov_项目本身通过GitHub泄露的方式，立即引发了人们对该届政府在网络安全和准备工作方面的质疑。尽管该代码库被迅速归档，但其公开暴露内部开发计划，即使是早期阶段的计划，也凸显了在处理大量敏感政府数据和公民信息时，安全协议可能存在的漏洞。正如一些批评者所指出的，如此随意地处理这样一个代码库，表明其安全意识与“全政府”AI计划所承担的巨大责任不符 [^1]。

尽管技术愿景宏伟，但其实现面临着巨大的挑战。联邦政府系统以其复杂性而闻名，往往依赖于数十年之久的老旧基础设施。将尖端AI模型（通常依赖于云服务）与这些分散且根深蒂固的系统进行整合，是一项艰巨的任务。专家甚至政府雇员都表达了深切的担忧。一位Reddit用户直言不讳地表示：“_他们连一个像样的网站都跑不顺，还想跳到AI整合，太吓人了！_” [^1]。通过AI生成的代码，**在关键政府操作中引入新的漏洞或缺陷**的风险是真实存在的。正如一位评论员讽刺地说，为“整个政府的所有软件编写AI代码？漏洞会比瑞士奶酪还多。” [^1]。

此外，这些AI系统所需摄取的数据量——涉及大量的机密政府信息和公民个人数据——带来了前所未有的安全和隐私噩梦。输入这些模型的数据的完整性以及其输出的可靠性变得至关重要。API文档中提及Cohere模型可能缺乏FedRAMP认证，尽管总体上依赖像Amazon Bedrock这样经过认证的供应商，但这表明在安全审查方面可能存在漏洞，或者激进的时间表可能超出了应有的尽职调查 [^3]。对于计划中的“模型排名”缺乏具体标准的说明，也引入了不透明性，可能会损害公众信任。

### 社会影响与伦理考量

除了技术障碍，特朗普政府的AI计划引发了更深层次的关于在公共部门大规模部署AI的**社会和伦理影响**的讨论。将“目前由联邦雇员完成的大部分工作”实现自动化的雄心，立即引起了人们对公务员队伍**广泛失业**的担忧。虽然支持者主张提高效率和节约成本，但批评者警告称，这可能导致公共劳动力萎缩，并改变政府就业的性质，带来巨大的人力成本。

更关键的是，AI在政府职能中的应用——从处理纳税申报到分析合同，并可能为关键政策决策提供信息——提出了复杂的伦理困境。AI系统，特别是大型语言模型，已知会表现出**其训练数据中固有的偏见**，如果不能仔细缓解，可能导致歧视性结果。当这些系统做出直接影响公民生活的决定时，公平、问责和透明的问题变得至关重要。当一个由AI驱动的合同分析工具基于有偏见的数据建议削减一项重要合同，或者一个自动化系统因算法错误而拒绝公民一项关键服务时，责任由谁承担？据报道，政府雇员自己也表示“非常糟糕”的反应，担心AI可能会无意中导致代码漏洞或建议“削减重要合同” [^1]。

该计划中对“AI”本身的定义也受到了审视。一位从事天气预测的专业人士指出，像国家海洋和大气管理局（NOAA）用于预测风暴的复杂算法，尽管在预报方面高度实用，但在这种宽泛、可能模糊的政府定义下，可能不被视为“AI”，因为它们“太实用了” [^1]。这凸显了一个根本性的矛盾：推动“AI”究竟是为了用先进、可靠的工具增强政府能力，还是如一些网友所担心的那样，是一项政治驱动的对现有自动化努力的重新包装，可能是一个“面子工程”？

部署AI以“实时监控”员工使用情况，也引发了对联邦劳动力内部**监视和隐私**的担忧，可能影响士气和信任。这种全面的转变可能会从根本上改变政府与被治理者之间的关系，算法越来越多地介入互动和决策，这可能侵蚀人类的监督和问责制。

_ai.gov_的提前泄露已将特朗普政府宏大的AI雄心推至公众视野，揭示了一项既大胆又可能充满问题的计划。在象征着自由和自治的独立日背景下，提议的上线日期为这项暗示着大规模自动化和可能减少政府人为干预的计划增添了一层讽刺意味。尽管提高效率和创新的前景诱人，但其深层的技术挑战、巨大的安全和隐私风险，以及围绕就业流失、算法偏见和问责制的深刻伦理问题不容忽视。_ai.gov_能否从一次GitHub泄露事件转变为一个功能完善、安全可靠且符合伦理的联邦治理支柱，仍有待观察。其潜在的7月4日上线，将不仅仅是一次技术发布，更是一个关键时刻，迫使美国对AI驱动的国家所带来的真实成本和收益进行全国性的反思。

## References
[^1]: 英智 (2025/6/17)。[特朗普「全政府AI计划」竟在GitHub泄密，或于7月4日「独立日」上线](https://mp.weixin.qq.com/s/m9sybyRZouy-IvsMirsFtA)。新智元。检索日期2025/6/17。
[^2]: 不可用作者 (2025/6/10)。[特朗普政府新 AI 计划「AI.gov」在 GitHub 上被泄露](https://www.oschina.net/news/354956/github-is-leaking-trumps-plans-to-accelerate-ai-across-gov)。OSCHINA。检索日期2025/6/17。
[^3]: 不可用作者 (2025/6/10)。[AI.govがGitHub流出で判明：トランプ政権、7月4日に政府全体AI化計画を始動](https://innovatopia.jp/ai/ai-news/57313/)。イノベトピア。检索日期2025/6/17。
