---
title: 当AI成为“外部大脑”：MIT研究揭示ChatGPT对人类认知的深层影响与“认知惯性”
date: 2025-06-20T20:10:04+08:00
draft: false
featured_image: "https://img.36krcdn.com/hsossms/20250620/v2_57ca3461ee9449178a8d5be94244015d@46958_oswg66239oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1"
summary: 麻省理工学院一项最新研究指出，过度使用ChatGPT等大型语言模型可能导致大脑活动水平下降，削弱记忆并引发“认知惯性”。这项结合脑电图与自然语言处理的实验发现，长期依赖AI会使大脑从主动生成信息转变为被动筛选信息，影响深度思考和创造力，提示人类需警惕AI对认知能力的潜在负面影响，并在工具使用与自主思考间寻求平衡。
tags: 
  - ChatGPT
  - 大脑认知
  - 认知惯性
  - 人工智能影响
  - MIT研究
  - 脑电图
  - 神经科学
  - AI伦理
  - 认知退化
  - 深度思考
main_topics: 
  - 前沿模型与算法
  - AI伦理与治理
  - 社会影响与未来工作
---

> 麻省理工学院一项突破性脑科学研究揭示，过度依赖大型语言模型（LLM）如ChatGPT，可能导致大脑活动水平显著降低，削弱记忆编码，并引发一种“认知惯性”。这不仅影响个体的深度思考与创造力，更提出了AI时代人类认知退化的潜在风险，呼吁我们在智能工具与自主思考之间寻求微妙的平衡。

随着生成式人工智能（AI）工具，特别是大型语言模型（LLM）如OpenAI的ChatGPT，日益融入我们的日常生活和专业工作，它们所带来的效率提升是显而易见的。然而，这种效率的另一面可能隐藏着对人类认知能力潜移默化的影响。近期，麻省理工学院（MIT）的一项开创性脑科学研究，首次通过严谨的数据分析，为这种担忧提供了神经科学层面的证据，引发了关于“AI时代认知退化”的深刻讨论[^1][^2]。

### 实验设计：量化工具辅助下的认知负荷

这项由MIT研究团队主导的实验，旨在系统性地评估LLM、传统搜索引擎与纯粹人脑思考在解决复杂任务时的认知差异。研究人员招募了54名大学生，并将其随机分为三个实验组，每组进行四轮任务：

*   **LLM组**：仅允许使用OpenAI的GPT-4o作为唯一信息来源来撰写论文。
*   **搜索引擎组**：可使用谷歌浏览器辅助，但明确禁止使用LLM生成内容。
*   **纯大脑组**：完全禁用任何在线工具，仅凭自身知识和思考完成写作。

在实验的前三轮，所有参与者都需在规定时间内（20分钟）完成SAT议论文的撰写。关键之处在于，研究团队在整个过程中运用了多模态数据收集技术：**脑电图（EEG）**实时记录大脑活动，以监测认知参与度和负荷；**自然语言处理（NLP）**分析产出文本的语言特征；同时，通过**访谈**深入了解参与者的主观体验，并结合**人类教师与AI评委**对论文质量进行评分。这种综合性的方法，使得研究能够从神经认知、语言和行为多个维度捕捉到AI辅助下的认知变化。

### 认知负荷与记忆编码的真相

实验结果揭示了显著的认知差异。在**大脑活动**方面：

*   **纯大脑组**的参与者表现出最强的脑电图神经连接，这表明他们在进行深度思考、记忆检索、规划和创造性思维时，需要调动更多的大脑资源，认知负荷也最高。
*   **LLM组**的神经连接则最为微弱，反映出自主思考的显著减少，大脑更多地处于一种被动的“筛选信息”状态。
*   **搜索引擎组**介于两者之间，由于需要自行整合外部信息，视觉皮层活动相对更多。

在**论文质量与记忆**方面，结果同样引人深思：

*   LLM组产出的论文结构更紧密规范，但内容同质化程度高，缺乏个性和原创性。
*   纯大脑组的论文则展现出更独特的个人风格，深度融入了个人经验和见解。
*   更令人担忧的是，研究发现过度依赖LLM的参与者，其对所写论文内容的**记忆编码较浅**。高达83.3%的LLM组参与者无法准确回忆或引用自己的论文内容，而纯大脑组只有11.1%出现类似问题。这暗示了使用AI生成内容可能损害即时记忆的编码深度。

实验的第四轮更进一步揭示了“认知惯性”的存在。研究团队将18名参与者进行分组互换，让原LLM组尝试纯大脑写作，原纯大脑组改用LLM。结果显示，原LLM组在不使用工具的情况下，其大脑神经连接依然弱于原纯大脑组，并持续表现出较差的引用能力，这表明对工具的依赖可能形成一种持久的认知习惯。相反，原纯大脑组在使用LLM时，大脑活动反而增强，他们能够更好地整合工具建议与自主思考，激活核心脑区，展现出更高的记忆召回能力。

### AI时代的“认知萎缩”风险与平衡之道

这项研究从神经认知、语言到行为层面，都指向了一个核心结论：使用AI写作工具，会显著降低大脑的认知参与度。长此以往，大脑可能因得不到充分锻炼而“退化”，陷入一种潜在的“认知萎缩”状态。

LLM提供了一种“便利陷阱”，它以降低神经连接和损伤即时记忆编码为代价，换取了表面上的高效率。这种模式导致了记忆衰退、创造力降低，并在脱离辅助后表现出持续性的认知缺陷。大脑的信息处理模式从**“主动生成信息”**转变为**“被动筛选信息”**，削弱了独立思考和问题解决能力。用论文作者的精辟比喻来说：

> 用AI写作就像给孩子计算器——关键不是禁止使用，而是教会他们何时该心算。

这意味着，AI并非思考的替代品，而是辅助工具。在学习和工作中，我们必须警惕过度依赖LLM的风险。研究团队建议，将AI主要用于语法检查、润色、初步资料搜集等辅助性任务，而非直接生成核心内容和结构。更重要的是，在AI辅助生成内容后，务必投入时间去理解、消化并融入自己的见解。

在AI智能飞速发展的今天，这项研究为我们敲响了警钟。它提醒我们，在享受技术便利的同时，更应审视其对人类心智可能产生的深层影响。如何智慧地驾驭AI，确保它赋能而非削弱人类的核心认知能力，将是未来教育、科技伦理乃至社会发展的关键议题。平衡好工具辅助与自主思考的关系，是我们在数字时代保持认知活力的核心挑战。

## 引用

[^1]: [ChatGPT用多了会变傻，MIT招募大学生做实验论证，用得越多人越笨](https://www.36kr.com/p/3344696933745284)·36氪·量子位 · 鹭羽（2025/6/20）·检索日期2025/6/20
[^2]: [ChatGPT用多了会变傻!MIT招募大学生做实验论证，用得越多人越笨](https://finance.sina.com.cn/tech/csj/2025-06-20/doc-infatmae6200279.shtml)·新浪科技（2025/6/20）·检索日期2025/6/20
[^3]: [ChatGPT for Cognitive Atrophy: A Neuroscience Study of LLM Use on Brain Activity and Memory](https://arxiv.org/abs/2506.08872)·arXiv（2025/6/20）·检索日期2025/6/20
