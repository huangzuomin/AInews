---
title: 揭示权力与利润的交织：OpenAI深陷信任危机
date: 2025-06-20T21:10:05+08:00
draft: false
featured_image: "https://np-newspic.dfcfw.com/download/D25143304313000626942_w900h420.jpg"
summary: 一份名为《OpenAI档案》的深度报告揭露了OpenAI从非营利研究机构向营利巨头的转变，并详细披露了CEO奥特曼在公司治理、安全承诺和个人利益冲突方面的诸多不当行为。报告质疑OpenAI背弃其“为人类谋福祉”的创立使命，将利润和增长置于安全与透明之上，这引发了对AI行业伦理、监管和未来发展方向的深刻担忧。
tags: 
  - OpenAI
  - 萨姆·奥特曼
  - AI伦理
  - 公司治理
  - 利益冲突
  - AI安全
  - 深度调查
  - 科技监督
main_topics: 
  - AI伦理与治理
  - 产业生态与商业版图
  - 投融资与市场洞察
---

> 一份深度调查报告《OpenAI档案》揭露了AI巨头OpenAI从追求“全人类福祉”的非营利机构，系统性地转向以利润为导向的商业实体，并详细记录了其领导层在公司治理、安全承诺和利益冲突方面的诸多不当行为，引发了对AI伦理与未来发展的深刻反思。

近期，由两大科技监督组织Midas Project和Tech Oversight Project联合发布的《OpenAI档案》报告，如同一颗重磅炸弹，将全球领先的AI研究机构OpenAI的内部运作“扒了个底朝天”[^1]。这份超过50页、逾万字的交互式报告，被誉为“迄今为止，针对OpenAI在公司治理实践、领导层诚信及组织文化方面，已记录在案的担忧的最全面汇编”[^1]。它不仅揭示了OpenAI从一个旨在造福人类的非营利研究实验室，如何一步步演变为一个以营利为核心的商业巨头，更将CEO萨姆·奥特曼（Sam Altman）一系列饱受争议的行为模式和盘托出。报告描绘的图景远不止一起简单的公司转型，而是一场关于AI时代核心价值观、权力结构以及人类未来走向的深刻警示。

### 使命的瓦解：从福祉到利润的系统性背离

《OpenAI档案》指出，OpenAI正在“系统性地、有预谋地拆除其创立时的核心道德与结构支柱”[^1]，其行为与公开声明存在严重矛盾，本质上是从“为人类谋福祉”到“为投资者谋利润”的根本性转变。这一转变的核心，在于其两大基石——“利润上限”（Capped-Profit）模式与非营利监督机制——的同步瓦解。

最初的“利润上限”旨在确保通用人工智能（AGI）创造的巨大财富能与全人类共享，防止财富过度集中。然而，报告揭示，这一承诺被逐步掏空：从表面上看似加强使命的利润倍数下调，到秘密引入“每年自动增长20%”这一使其在功能上形同虚设的条款，再到最终计划完全移除上限，标志着财富共享理念的彻底终结[^1]。与此同时，其监督机制也被巧妙地削弱。OpenAI从一个由非营利组织完全控制的实体，转型为特拉华州的公益公司（PBC）。法律义务从“使命优先”变成“平衡股东利益和公共利益”[^1]。然而，报告犀利地指出，历史上“没有股东成功起诉以保护公共利益的先例”[^1]，这使得公益承诺在法律实践中几乎无法执行，PBC的“公益”承诺在现实中可能沦为空壳，为追求利润最大化提供了巨大的法律掩护。

对于OpenAI管理层以“行业竞争激烈”为由放弃承诺的官方说辞，报告通过引用公司早期的《章程》和内部邮件，有力地驳斥了这一说法。报告证明，OpenAI在创立之初就已充分预料并准备应对激烈的行业竞争。因此，用竞争作为背弃承诺的理由，是一种站不住脚的“修正主义历史”[^1]。这背后真正的动机，恰恰是投资者和公司高层都相信其巨大的盈利潜力，因此移除上限才变得至关重要。

### CEO诚信：信任基础的 Erosion

报告进一步将矛头指向了OpenAI的掌舵者萨姆·奥特曼，指出他存在“长期、有据可查的言行不一、操纵信息和规避监督的行为模式，以及将个人利益置于组织责任之上”[^1]。报告列举了多个奥特曼在重大问题上公开撒谎或误导的实例：

*   在员工非贬低协议问题上，他公开声称不知情“剥夺离职员工股权”条款，但文件显示他明确授权了此条款[^1]。
*   在参议院宣誓作证时，他声称没有OpenAI股权，但后来承认曾通过基金间接持有[^1]。
*   长期向董事会隐瞒其个人拥有OpenAI创业基金的事实[^1]。

前董事会成员海伦·托纳（Helen Toner）更是直接指控奥特曼通过“隐瞒信息、歪曲事实、甚至直接撒谎”来阻碍董事会履职[^1]。报告还显示，这种行为模式贯穿其职业生涯：从Loopt时期因“欺骗性和混乱的”行为被员工试图解雇，到在Y Combinator期间因专注个人项目而玩忽职守最终被创始人保罗·格雷厄姆“请走”[^1]。最戏剧性的体现是，在被OpenAI董事会解雇后，他利用影响力反向操作，以“罢免开除他的董事会成员并安插自己盟友”作为回归条件，成功实现对监督体系的“反噬”[^1]。这种行为模式的揭露，对一家肩负着开发可能改变人类命运的强大AI系统的公司而言，无疑是对其信任基础的巨大侵蚀。

### 安全与利益：被牺牲的核心价值

报告揭示了OpenAI在安全和透明度方面存在的“系统性的言行不一”，其公开承诺与内部实践严重脱节[^1]。公司文化表现出一种“唯快不破”的倾向，为了追求商业利益和竞争优势，正在系统性地削弱、规避甚至惩罚内部的安全监督和异议。

一个令人震惊的例子是，OpenAI曾承诺将20%的计算资源投入“超级对齐”（Superalignment）安全团队，但据前负责人简·莱克（Jan Leike）透露，这笔资源从未被分配[^1]。在GPT-4o开发中，安全团队被要求在产品发布前“快速完成”测试，公司甚至在评估开始前就已计划好发布庆祝活动[^1]。更严重的是，公司被指控使用严苛的离职协议威胁离职员工，若批评公司将损失数百万美元股权。员工利奥波德·阿申布伦纳（Leopold Aschenbrenner）因向董事会提交国家安全风险备忘录而被解雇，公司明确告知解雇原因正是他“越级”报告安全问题[^1]。这些事件共同描绘出一幅令人不安的图景：在一个致力于开发通用人工智能的组织内部，安全担忧不仅被忽视，提出者甚至会遭到惩罚。此外，报告还指出，OpenAI在2023年发生黑客入侵、AI技术细节被盗的严重安全事件，但在长达一年时间里未向当局或公众报告[^1]。多名现任和前任员工指控公司存在“鲁莽和保密的文化”，将“利润和增长”置于安全使命之上[^1]。

而奥特曼庞大且相互交织的个人投资网络，更是将OpenAI的利益冲突风险推向极致。报告详尽揭示了这些投资与OpenAI的业务、技术和战略伙伴关系存在深刻且直接的利益冲突，从根本上挑战了OpenAI所宣称的“为全人类谋福祉”的使命[^1]。例如：

*   **Helion（核聚变能源）**：奥特曼既是Helion的董事长和主要投资者，又是OpenAI的CEO。他亲自主导了OpenAI从Helion购买大量能源的交易，报告质疑这笔交易是否主要为了保障他个人在Helion的巨额投资[^1]。
*   **Worldcoin（加密货币项目）**：奥特曼是Worldcoin的联合创始人。OpenAI与Worldcoin建立了官方合作关系（如提供免费GPT-4服务），引发人们质疑这究竟是平等的商业合作，还是奥特曼在利用OpenAI的资源和品牌，来扶持和推广他自己的另一个高风险项目[^1]。
*   **Humane（AI硬件）**：奥特曼是Humane的最大股东，而Humane的产品严重依赖OpenAI的模型。作为OpenAI的CEO，他有强烈的个人财务动因去确保Humane获得优惠条款或优先技术支持，这可能损害其他客户的利益和市场的公平性[^1]。

这些盘根错节的利益关系，严重侵蚀了奥特曼作为CEO的信托责任。他的决策究竟是为了OpenAI的使命，还是为了他个人的财富增长？报告最终描绘的图景是：奥特曼更像一个精明的资本操盘手，他巧妙地将OpenAI置于其个人商业帝国的中心，并利用其CEO的职位，系统性地将OpenAI的技术、资源和战略关系，转化为个人投资组合的增长动力[^1]。

《OpenAI档案》的发布，无疑给AI产业敲响了警钟。在一个技术快速迭代、能力日益强大的时代，如何确保AI的开发真正符合公共利益，如何建立透明、负责任的公司治理机制，以及如何防范个人野心与商业利益对崇高使命的侵蚀，已成为迫在眉睫的全球性挑战。这份报告不仅是对OpenAI的审视，更是对整个AI生态系统的一次深刻拷问：当技术巨头在无人监管的真空地带加速狂奔时，我们能否守住最初的承诺，确保AI的未来不偏离造福人类的初心？
<br>
## 引用
[^1]: [OpenAI被扒了个底朝天!](https://reportify.ai/news/1133486503226380288)·Reportify·(2025/6/20)·检索日期2025/6/20
