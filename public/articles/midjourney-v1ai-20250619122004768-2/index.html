<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Midjourney V1：从AI生图到“开放世界”视频模拟的跃迁与挑战 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="AI图像生成巨头Midjourney发布了其首款AI视频生成模型V1，支持用户将图像转化为最长20秒的逼真流畅视频，每月最低10美元起。此举标志着Midjourney向多媒体内容创作迈进的战略转型，尽管V1尚不支持音频或时间线编辑，但其在动作连贯性上的突破使其在激烈的AI视频竞争中占据一席之地，同时其构建“实时模拟开放世界”的宏大愿景也伴随着版权争议等潜在挑战。">
    <meta name="generator" content="Hugo 0.147.8">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/articles/midjourney-v1ai-20250619122004768-2/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/articles/midjourney-v1ai-20250619122004768-2/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="Midjourney V1：从AI生图到“开放世界”视频模拟的跃迁与挑战">
  <meta property="og:description" content="AI图像生成巨头Midjourney发布了其首款AI视频生成模型V1，支持用户将图像转化为最长20秒的逼真流畅视频，每月最低10美元起。此举标志着Midjourney向多媒体内容创作迈进的战略转型，尽管V1尚不支持音频或时间线编辑，但其在动作连贯性上的突破使其在激烈的AI视频竞争中占据一席之地，同时其构建“实时模拟开放世界”的宏大愿景也伴随着版权争议等潜在挑战。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-06-19T12:20:04+08:00">
    <meta property="article:modified_time" content="2025-06-19T12:20:04+08:00">
    <meta property="article:tag" content="Midjourney V1">
    <meta property="article:tag" content="AI视频生成">
    <meta property="article:tag" content="生成式AI">
    <meta property="article:tag" content="多媒体内容创作">
    <meta property="article:tag" content="开放世界模拟">
    <meta property="article:tag" content="人工智能伦理">

  <meta itemprop="name" content="Midjourney V1：从AI生图到“开放世界”视频模拟的跃迁与挑战">
  <meta itemprop="description" content="AI图像生成巨头Midjourney发布了其首款AI视频生成模型V1，支持用户将图像转化为最长20秒的逼真流畅视频，每月最低10美元起。此举标志着Midjourney向多媒体内容创作迈进的战略转型，尽管V1尚不支持音频或时间线编辑，但其在动作连贯性上的突破使其在激烈的AI视频竞争中占据一席之地，同时其构建“实时模拟开放世界”的宏大愿景也伴随着版权争议等潜在挑战。">
  <meta itemprop="datePublished" content="2025-06-19T12:20:04+08:00">
  <meta itemprop="dateModified" content="2025-06-19T12:20:04+08:00">
  <meta itemprop="wordCount" content="35">
  <meta itemprop="keywords" content="Midjourney V1,AI视频生成,生成式AI,多媒体内容创作,开放世界模拟,人工智能伦理,版权挑战,技术趋势,视频模型,AI应用">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Midjourney V1：从AI生图到“开放世界”视频模拟的跃迁与挑战">
  <meta name="twitter:description" content="AI图像生成巨头Midjourney发布了其首款AI视频生成模型V1，支持用户将图像转化为最长20秒的逼真流畅视频，每月最低10美元起。此举标志着Midjourney向多媒体内容创作迈进的战略转型，尽管V1尚不支持音频或时间线编辑，但其在动作连贯性上的突破使其在激烈的AI视频竞争中占据一席之地，同时其构建“实时模拟开放世界”的宏大愿景也伴随着版权争议等潜在挑战。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/images/default%20%2813%29.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        AI内参
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/articles/" title="">
              新闻
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/" title="">
              分类
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/tags/" title="">
              标签
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/authors/" title="">
              作者
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        
        
        
        
        
        
        
          7小时前
        
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">Midjourney V1：从AI生图到“开放世界”视频模拟的跃迁与挑战</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>AI图像生成巨头Midjourney正式发布其首款视频生成模型V1，标志着其业务从静态图像创作向动态多媒体内容生成的重大战略转型。V1支持用户通过图像生成最长20秒的流畅视频，以其在动作连贯性和视觉逼真度上的表现，迅速引起业界关注，同时也揭示了当前AI视频领域激烈竞争和未来“开放世界”模拟的宏大愿景。</p></blockquote>
<p>全球领先的AI图像生成平台Midjourney，近日迈出了其发展史上意义深远的一步，正式推出了备受期待的<strong>首款AI视频生成模型V1</strong>。这一发布不仅让Midjourney从“AI生图之王”的宝座延伸至动态内容领域，更预示着一场从单一媒介创作走向全多媒体内容生态的深刻变革。在生成式AI浪潮席卷全球的当下，Midjourney V1的登场，无疑为方兴未艾的AI视频赛道注入了新的活力，也对其长期以来秉持的“易用性”理念进行了全新的诠释。</p>
<h3 id="技术跃进从静态到动态的范式转变">技术跃进：从静态到动态的范式转变</h3>
<p>Midjourney V1的核心能力在于将用户上传的图像（无论是Midjourney自产还是外部导入）转化为动态视频。用户在Midjourney界面中选择“Animate Image”即可体验这项新功能，最长可生成<strong>20秒</strong>的视频内容。这并非简单的静态图像拉伸或模糊处理，而是实现了画面主体动作的<strong>连贯性与流畅度</strong>，甚至能够逼真地呈现凭空创造的怪物或科幻形象的运动，正如Perplexity AI设计师Phi Hoang在X上评价的那样：“它超出了我所有的预期。”<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>V1提供了“手动”和“自动”两种动作提示词生成选项，并引入了“高速运动”和“低速运动”的概念，以适应不同的创作需求。_低速运动_更适合相机基本静止、主体缓慢移动的场景，如人物眨眼或微风拂过；而_高速运动_则适用于所有物体（包括相机）都活跃起来的场景。这种灵活的运动控制机制，赋予了创作者更大的想象空间。值得注意的是，用户还可以选择对满意的视频片段进行延长，每次约4秒，总共可延展4次，直至达到20秒的上限。</p>
<p>尽管V1在动作连贯性上表现出色，但作为其首个视频模型，Midjourney V1仍有其局限性。目前，它<strong>无法生成对应音频</strong>，配乐需要用户后期手动添加；同时，尚<strong>不支持编辑时间线、场景转换或片段之间的连续性</strong>。这意味着，在生成复杂叙事性视频方面，用户仍需借助外部工具进行后期处理，或通过分段生成、拼接的方式来弥补。从技术层面看，这意味着模型目前更多专注于单镜头内的物理运动模拟，而非跨镜头或时间维度上的叙事逻辑理解。</p>
<h3 id="竞争格局与市场演变">竞争格局与市场演变</h3>
<p>Midjourney V1的发布，无疑是AI视频生成领域日益白热化竞争的最新注脚。在此之前，谷歌、字节跳动、MiniMax等巨头及一众新兴力量早已纷纷布局。例如，今年5月谷歌发布了能实现音画同步的Veo 3；6月字节跳动推出了豆包视频生成模型Seedance 1.0 pro；紧随其后，MiniMax更新了海螺02，旨在打破全球视频模型效果和成本纪录；快手也在去年6月推出了基于DiT架构的可灵AI，支持最长3分钟的“文生视频”和“图生视频”双模式<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。甚至微软的Bing团队也推出了由OpenAI Sora模型支持的Bing Video Creator，可生成5秒竖屏视频[^4]。</p>
<p>在与这些“老玩家”的比较中，Midjourney V1展现出其独特的优势与不足。有网友将V1与Runway的生成效果进行对比，发现V1在<strong>人物动作流畅度</strong>上表现更佳，有时甚至更具“大片感”，而Runway则在整体画面和谐度上略胜一筹，例如对背景中细微元素（如蝴蝶）的处理。与Veo 3相比，尽管有网友称V1的视觉效果“惊人”，但认为其在某些方面仍有差距。这些对比表明，当前的AI视频模型各有所长，尚未出现能够全面碾压所有维度的“终极解决方案”。</p>
<p>在商业模式上，Midjourney V1延续了其图像生成服务的订阅制。所有订阅者均可体验V1，会员起订费为<strong>10美元/月</strong>。视频生成采用“按次消耗额度”的机制，每个视频任务将消耗信用点数。Midjourney官方透露，视频制作的收费大约是图片制作的8倍，但“<strong>每秒的成本大致相当于生成一张静态图像</strong>”<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>，这意味着其在成本控制上做出了努力，以期降低用户尝试门槛。此外，Midjourney还在测试为每月60美元及更高订阅费的“专业版”会员开放“无限制轻松模式”，这或将进一步满足专业内容创作者的需求。</p>
<h3 id="走向开放世界的愿景与潜在挑战">走向“开放世界”的愿景与潜在挑战</h3>
<p>Midjourney将V1的发布视为其<strong>探索构建能够实时模拟开放世界模型的第一步</strong><sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这一宏大目标旨在创建一个AI系统，能够实时生成图像，并允许用户在3D空间中自由移动，环境和角色随之互动。简而言之，图像模型负责静态视觉，视频模型负责动态，3D模型实现空间移动，而实时模型则确保所有这些过程能够快速高效地完成。Midjourney计划在未来一年内分别构建并发布这些独立模型，最终逐步整合为一个统一的、能够实时模拟交互式虚拟世界的系统。</p>
<p>这一愿景的实现，将彻底颠覆我们对数字内容创作、游戏、虚拟现实乃至元宇宙的理解。如果AI能够实时、流畅、逼真地模拟一个可交互的开放世界，那么内容创作的门槛将大大降低，个性化、沉浸式的数字体验将变得触手可及。它不仅仅是生产视频片段，更是构建一个能够响应用户指令并自主演化的数字环境。这种能力将带来前所未有的创作自由，但也引发了关于<em>数字版权、内容真实性、算法偏见以及潜在滥用</em>等一系列深层伦理和社会问题。</p>
<p>其中最紧迫的挑战之一便是版权问题。目前，Midjourney正面临来自迪士尼和环球影业等全球娱乐巨头的严峻法律挑战，它们指控Midjourney未经授权使用受版权保护的角色来训练其模型，并继续允许用户生成衍生内容<sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这一指控不仅关系到Midjourney自身的未来发展，也触及了整个生成式AI行业的核心合法性问题：在模型训练阶段如何获取数据？生成内容如何界定版权归属？在追求技术前沿的同时，如何构建一个公平、负责任的生态系统，成为所有AI公司必须正视的课题。</p>
<p>Midjourney V1的亮相，无疑是AI视频生成技术发展道路上的一个重要里程碑。它展示了从图像到视频转换的巨大潜力，也清晰地勾勒出其构建“开放世界”的雄心。然而，在激动人心的技术进步背后，行业正面临着激烈的市场竞争、不断演进的用户需求以及日益复杂的法律和伦理挑战。作为“技术垫脚石”的V1，承载着Midjourney的愿景，也映射出通用人工智能未来图景中光明与阴影并存的复杂现实。</p>
<h2 id="references">References</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>智东西（2025/6/19）。<a href="https://m.36kr.com/p/3342792433285641">AI生图之王首发视频大模型，每月10刀，最长20秒，效果超逼真</a>。36氪。检索日期2025/6/19。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>AI工具集（未知）。<a href="https://ai-bot.cn/daily-ai-news/">每日AI资讯、热点、动态、融资、产品发布</a>。AI工具集。检索日期2025/6/19。&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/midjourney-v1/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Midjourney V1</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI视频生成</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E7%94%9F%E6%88%90%E5%BC%8Fai/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">生成式AI</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%A4%9A%E5%AA%92%E4%BD%93%E5%86%85%E5%AE%B9%E5%88%9B%E4%BD%9C/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">多媒体内容创作</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%BC%80%E6%94%BE%E4%B8%96%E7%95%8C%E6%A8%A1%E6%8B%9F/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">开放世界模拟</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">人工智能伦理</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E7%89%88%E6%9D%83%E6%8C%91%E6%88%98/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">版权挑战</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">技术趋势</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E8%A7%86%E9%A2%91%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">视频模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E5%BA%94%E7%94%A8/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI应用</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/articles/openaiai-20250618122004611-6/">OpenAI与美国军方：AI“战争化”的深层考量</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619112004610-4/">人工智能重塑教育的“不可能三角”：一场深远的变革及其潜在影响</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/mewmai-20250619112004625-6/">医学世界模型MeWM：AI如何让医生“预演”疾病，开启精准医疗新纪元</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619102004644-4/">高考志愿，大厂AI的隐形战役：流量、数据与未来治理的权衡</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/aithrive-capital-20250619082004285-0/">AI投资热潮：孙正义与Thrive Capital领跑，警惕市场分化与估值泡沫</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/openaiai-20250619072004332-0/">OpenAI的代理框架：将AI智能体从实验室推向企业前沿的战略举措</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619042004381-0/">AI编排层：驾驭提示词之乱，构建智能企业新秩序</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618222005660-0/">智能体浪潮：从“独角兽”涌现窥探自主AI的深层演进与未来挑战</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618212004488-1/">亚马逊的AI押注：一场加速劳动力重塑的预演</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618212004501-2/">斯坦福研究揭示硅谷AI投资错配：一场偏离用户需求的“资源漂移”</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618212004476-0/">自变量机器人：从“握锤”到“无我”，具身智能迈向统一架构的范式突破</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618202004760-5/">高考志愿争夺战：AI大模型与“名师”话语权的深度交锋</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/llmmit50-20250618172004590-1/">信息洪流中的LLM深度航标：MIT揭示掌握大模型精髓的50个关键洞察</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/gemini-25ai-20250618122004604-5/">揭秘Gemini 2.5家族：从轻量级“神经操作系统”到AI“智能体恐慌”的深层洞察</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/openai-20250618112004707-1/">OpenAI与微软权力对弈：国防合约背后的大模型自主之路</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
