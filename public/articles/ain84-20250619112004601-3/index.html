<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>突破视觉AI瓶颈：英伟达与港大如何革新注意力机制，实现√N计算与84倍加速 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="英伟达与香港大学联合发布广义空间传播网络（GSPN），一种新型视觉注意力机制，旨在克服Transformer在处理高分辨率图像时面临的计算二次方复杂度与空间结构丢失问题。GSPN通过引入“稳定性-上下文条件”，将计算复杂度显著降低至√N量级，并在图像生成任务中实现了高达84倍的加速，有望为下一代视觉AI模型奠定高效且空间感知的基石。">
    <meta name="generator" content="Hugo 0.147.8">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/articles/ain84-20250619112004601-3/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/articles/ain84-20250619112004601-3/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="突破视觉AI瓶颈：英伟达与港大如何革新注意力机制，实现√N计算与84倍加速">
  <meta property="og:description" content="英伟达与香港大学联合发布广义空间传播网络（GSPN），一种新型视觉注意力机制，旨在克服Transformer在处理高分辨率图像时面临的计算二次方复杂度与空间结构丢失问题。GSPN通过引入“稳定性-上下文条件”，将计算复杂度显著降低至√N量级，并在图像生成任务中实现了高达84倍的加速，有望为下一代视觉AI模型奠定高效且空间感知的基石。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-06-19T11:20:04+08:00">
    <meta property="article:modified_time" content="2025-06-19T11:20:04+08:00">
    <meta property="article:tag" content="人工智能">
    <meta property="article:tag" content="计算机视觉">
    <meta property="article:tag" content="注意力机制">
    <meta property="article:tag" content="Transformer">
    <meta property="article:tag" content="GSPN">
    <meta property="article:tag" content="图像生成">

  <meta itemprop="name" content="突破视觉AI瓶颈：英伟达与港大如何革新注意力机制，实现√N计算与84倍加速">
  <meta itemprop="description" content="英伟达与香港大学联合发布广义空间传播网络（GSPN），一种新型视觉注意力机制，旨在克服Transformer在处理高分辨率图像时面临的计算二次方复杂度与空间结构丢失问题。GSPN通过引入“稳定性-上下文条件”，将计算复杂度显著降低至√N量级，并在图像生成任务中实现了高达84倍的加速，有望为下一代视觉AI模型奠定高效且空间感知的基石。">
  <meta itemprop="datePublished" content="2025-06-19T11:20:04+08:00">
  <meta itemprop="dateModified" content="2025-06-19T11:20:04+08:00">
  <meta itemprop="wordCount" content="41">
  <meta itemprop="keywords" content="人工智能,计算机视觉,注意力机制,Transformer,GSPN,图像生成,英伟达,香港大学">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="突破视觉AI瓶颈：英伟达与港大如何革新注意力机制，实现√N计算与84倍加速">
  <meta name="twitter:description" content="英伟达与香港大学联合发布广义空间传播网络（GSPN），一种新型视觉注意力机制，旨在克服Transformer在处理高分辨率图像时面临的计算二次方复杂度与空间结构丢失问题。GSPN通过引入“稳定性-上下文条件”，将计算复杂度显著降低至√N量级，并在图像生成任务中实现了高达84倍的加速，有望为下一代视觉AI模型奠定高效且空间感知的基石。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/images/default%20%2815%29.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        AI内参
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/articles/" title="">
              新闻
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/" title="">
              分类
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/tags/" title="">
              标签
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/authors/" title="">
              作者
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        
        
        
        
        
        
        
          8小时前
        
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">突破视觉AI瓶颈：英伟达与港大如何革新注意力机制，实现√N计算与84倍加速</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>广义空间传播网络（GSPN）的问世，标志着视觉AI注意力机制的一次关键飞跃，它通过引入独特的稳定性-上下文条件，成功克服了传统Transformer在处理高分辨率图像时的计算二次方复杂度与空间结构丢失两大难题，以√N的计算效率和高达84倍的生成加速，为下一代视觉基础模型奠定了新的基石。</p></blockquote>
<p>近年来，Transformer架构及其核心的自注意力机制，无疑是推动自然语言处理和计算机视觉领域革命性进展的引擎。其强大的深度上下文建模能力，使得AI能够捕捉数据间极其复杂的依赖关系，从而在文本生成、图像识别等任务中展现出前所未有的表现。然而，当这一强大范式应用于视觉数据时，其固有的一些挑战也逐渐浮出水面，成为制约高分辨率图像处理和大规模视觉模型发展的瓶颈。</p>
<h3 id="突破transformer在视觉领域的固有困境">突破：Transformer在视觉领域的固有困境</h3>
<p>在视觉领域，Transformer面临的核心挑战主要体现在两个方面：首先是<strong>计算复杂度的二次方增长</strong>。随着图像分辨率的提高，像素数量N呈几何级数增长，而Transformer的注意力机制计算复杂度高达O(N²)，这意味着处理高分辨率图像时，计算资源和内存消耗将迅速变得天文数字般庞大，使得高效处理长上下文数据几乎不可能。其次，是<strong>对图像固有空间结构的忽视</strong>。Transformer通常将多维图像扁平化为一维标记序列进行处理，这无疑破坏了图像中至关重要的空间连贯性——像素间的相对位置、局部纹理和全局布局等信息，而这些信息对于依赖空间关系的视觉任务（如图像生成、目标检测等）是不可或缺的。</p>
<p>为解决效率问题，近期研究如线性注意力（Linear Attention）和状态空间模型（State Space Models，如Mamba）致力于将复杂度降低至线性（O(N)）。然而，这些方法在提升效率的同时，却往往未能有效保留并利用图像的关键二维空间结构信息，本质上仍停留在序列化处理的范畴。一些尝试将一维光栅扫描（raster scan）扩展至二维的线扫描方法（line scan），试图增强空间连贯性，但随即面临严峻的稳定性挑战：当标量权重演变为连接像素与前序邻居的矩阵权重时，传播过程中累积的矩阵乘法极易导致不稳定性——矩阵特征值过大引发指数增长，过小则导致信号迅速衰减，信息随之丢失。<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 在二维空间中同时实现稳定性和维持长距离上下文的有效传播，成为了一个亟待解决的难题。</p>
<h3 id="gspn的核心机制洞察与创新">GSPN的核心机制：洞察与创新</h3>
<p>正是为了克服上述挑战，来自英伟达（NVIDIA）、香港大学（The University of Hong Kong）和加州大学圣迭戈分校（UCSD）的研究人员联手提出了<strong>广义空间传播网络（Generalized Spatial Propagation Network, GSPN）</strong>。这是一种专为视觉任务优化设计的新型注意力机制，其核心优势在于能够<strong>直接操作空间连贯的图像数据</strong>，通过高效的线扫描方法建立像素间的密集连接。<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>GSPN成功的关键在于其引入的<strong>稳定性-上下文条件（Stability-Context Condition）</strong>。这一创新性的数学条件，通过确保传播矩阵为“行随机矩阵”（即元素非负且每行元素之和为1），从而在数学上保证了二维序列传播过程的<strong>稳定性和有效长距离上下文传播</strong>。<sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 行随机矩阵的特性意味着其乘积仍为行随机矩阵，这为模型提供了强大的稳定性保障，避免了梯度爆炸或消失的问题。通过满足这一条件，GSPN能够将具有N个元素的图像的计算复杂度显著降低至令人瞩目的**√N量级**。这意味着，相比于传统的O(N²)复杂度，GSPN在处理高分辨率图像时能够实现巨大的计算效率提升。</p>
<p>具体实现上，GSPN的传播层通过逐行或逐列的顺序处理进行，隐藏层依据前一行的隐藏状态和当前输入计算得出。为了提高参数效率，研究人员选择让每个像素连接前一行的三个相邻像素（三邻居连接）。同时，GSPN提供了两种变体：<strong>全局GSPN</strong>捕捉整个序列的长距离依赖，而<strong>局部GSPN</strong>则通过将空间维度划分为非重叠组来限制传播序列长度，进一步提高效率。最终，通过<strong>四方向集成</strong>（从左到右、右到左、上到下、下到上）确保了所有像素间的密集连接，形成了一个全方位的上下文感知网络。为了保证行随机性，研究人员对每个传播方向的矩阵元素应用Sigmoid函数并进行归一化。<sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>在工程实现层面，GSPN的线性传播层通过<strong>定制化的CUDA内核</strong>得以高效实现。该内核采用了<strong>并行化结构</strong>，在批量、通道以及与传播方向正交的行/列上实现全并行化，有效减少了内核循环长度，确保了高效且可扩展的线性传播能力。GSPN被设计为一个通用的序列传播模块，可以无缝集成到各种视觉任务的神经网络中，研究团队还针对判别任务和生成任务设计了不同的GSPN块。<sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<h3 id="效率与性能的实证">效率与性能的实证</h3>
<p>GSPN的实际表现令人印象深刻。在ImageNet-1K分类任务中，GSPN在参数数量相当的情况下，<strong>显著优于现有序列模型</strong>，展现了其在从小型到基础配置模型规模上的一致性能提升和卓越可扩展性。<sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>在类条件图像生成任务中，GSPN-XL/2在ImageNet 256×256的基准测试中创造了新的最先进性能（SOTA）。值得注意的是，GSPN-L/2仅使用了先前模型65.6%的参数，却获得了更优的FID和IS分数，而GSPN-B/2在收敛时，仅用DiT-XL/2 20.3%的参数就实现了极具竞争力的性能，这充分验证了GSPN在效率和可扩展性方面的巨大优势。<sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>或许最引人注目的是其在<strong>文本到图像生成</strong>领域的表现。研究人员将GSPN模块直接集成到广受欢迎的Stable Diffusion架构中，替换了原有的自注意力层。结果显示，GSPN由于其归一化权重满足稳定性-上下文条件，无需额外归一化即可适应任意分辨率。在不使用任何预训练权重的情况下，GSPN在相同的训练轮数内达到了与基线模型相当的性能。更令人惊叹的是，在单块A100 GPU上生成<strong>16K×8K分辨率的超高分辨率图像时，GSPN相比于基于softmax注意力的SD-XL实现了约84倍的惊人加速</strong>。<sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 这一数字不仅代表了计算效率的飞跃，更意味着高分辨率图像生成将变得前所未有的可行和高效。</p>
<h3 id="超越像素更深远的影响与未来展望">超越像素：更深远的影响与未来展望</h3>
<p>GSPN的问世，远不止是技术参数上的优化，它更深远的影响体现在多个层面。首先，<strong>计算效率的显著提升</strong>将直接转化为更低的能源消耗和碳足迹，这对于日益增长的AI模型规模和训练成本而言，无疑是可持续发展的福音。其次，高达84倍的加速，意味着曾经因计算瓶颈而难以普及的<strong>高分辨率视觉AI应用将成为现实</strong>。从精细的工业检测、医学影像分析，到电影级别的视觉内容创作、元宇宙中的高保真数字世界构建，GSPN都有望成为赋能这些创新的核心技术。它降低了开发和部署大规模视觉模型的门槛，让更多研究者和企业能够探索前沿应用。</p>
<p>此外，GSPN对图像<strong>空间结构的固有保留</strong>，也为AI对视觉世界的理解开辟了新路径。它摆脱了将二维信息强行序列化的弊端，使得模型能够更自然、更准确地感知和推理空间关系，这对于需要精确空间定位和上下文理解的任务（如自动驾驶中的环境感知、机器人操控等）具有里程碑式的意义。</p>
<p>当然，如同任何新兴技术，GSPN的长期影响仍需时间来验证。但其在保持卓越空间保真度的同时，实现极高计算效率的能力，使其有潜力成为继Transformer之后，推动下一代视觉理解和生成基础结构发展的关键力量。英伟达与香港大学的这项合作研究，不仅解决了当前视觉AI领域的一个核心难题，更指明了未来高效、智能、具备强空间感知能力的视觉基础模型的演进方向。我们可以预见，GSPN及其衍生技术，将在未来的AI生态中扮演越来越重要的角色，塑造我们与数字世界的交互方式，以及机器对真实世界的认知能力。</p>
<h2 id="references">References</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>LRST（2025/6/19）。<a href="https://mp.weixin.qq.com/s/sRWVPluSQHehKWsMFEJVqQ">√N并行+84倍计算加速，英伟达港大全新图像注意力：空间结构都保留</a>。新智元。检索日期2025/6/19。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">人工智能</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">计算机视觉</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">注意力机制</a>
   </li>
  
   <li class="list di">
     <a href="/tags/transformer/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Transformer</a>
   </li>
  
   <li class="list di">
     <a href="/tags/gspn/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">GSPN</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">图像生成</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E8%8B%B1%E4%BC%9F%E8%BE%BE/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">英伟达</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E9%A6%99%E6%B8%AF%E5%A4%A7%E5%AD%A6/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">香港大学</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/articles/article-20250618202004724-1/">破解AI心智之谜：深入探究其推理机制、幻觉与欺骗的深层逻辑</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/-transformer-20250618202004715-0/">超越 Transformer：具身智能能否摆脱“水土不服”的困境？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/llmmit50-20250618172004590-1/">信息洪流中的LLM深度航标：MIT揭示掌握大模型精髓的50个关键洞察</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/aiceo-20250619112004584-1/">AI浪潮席卷硅谷：亚马逊CEO的警告与职场重塑的残酷现实</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619112004610-4/">人工智能重塑教育的“不可能三角”：一场深远的变革及其潜在影响</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/agi-20250619112004591-2/">马斯克每月豪掷十亿美元，押注AGI能否再次改写科技格局？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619102004636-3/">AI浪潮席卷中国教育：技术赋能还是焦虑陷阱？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/geo-20250619102004605-0/">当算法成为导购：生成式搜索引擎优化（GEO）如何重塑数字广告的伦理边界</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/aimetaopenai-20250619102004625-2/">揭秘硅谷AI人才争夺战：Meta豪掷亿美元未能撼动OpenAI核心壁垒</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619102004615-1/">硅谷巨头押注十年监管真空：AI未来之路的权力博弈</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/sam-altmanai-20250619092004629-1/">Sam Altman：AI不仅接管想象力，更重塑现实与未来</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250619092004615-0/">中国机器人产业：摩根士丹利预测下的全球霸权与人形浪潮</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/aicloudmatrix384-20250619082004293-1/">华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/aiopenaimeta-20250619082004301-2/">百万美元年薪背后的AI人才争夺战：OpenAI与Meta的深层博弈</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/1ai-20250619072004342-1/">巨头逐鹿：1亿美元签字费背后，AI人才争夺战的深层逻辑</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
