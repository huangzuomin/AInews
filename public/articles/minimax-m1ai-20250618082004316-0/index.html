<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。">
    <meta name="generator" content="Hugo 0.147.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/articles/minimax-m1ai-20250618082004316-0/">
    

    <meta property="og:url" content="http://localhost:1313/articles/minimax-m1ai-20250618082004316-0/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界">
  <meta property="og:description" content="MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-06-18T08:20:04+08:00">
    <meta property="article:modified_time" content="2025-06-18T08:20:04+08:00">
    <meta property="article:tag" content="MiniMax">
    <meta property="article:tag" content="AI模型">
    <meta property="article:tag" content="推理模型">
    <meta property="article:tag" content="M1">
    <meta property="article:tag" content="MoE">
    <meta property="article:tag" content="混合注意力">

  <meta itemprop="name" content="MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界">
  <meta itemprop="description" content="MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。">
  <meta itemprop="datePublished" content="2025-06-18T08:20:04+08:00">
  <meta itemprop="dateModified" content="2025-06-18T08:20:04+08:00">
  <meta itemprop="wordCount" content="51">
  <meta itemprop="keywords" content="MiniMax,AI模型,推理模型,M1,MoE,混合注意力,闪电注意力,CISPO,强化学习,人工智能">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界">
  <meta name="twitter:description" content="MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://localhost:1313/images/default%20%286%29.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        AI内参
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/articles/" title="">
              新闻
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/" title="">
              分类
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/tags/" title="">
              标签
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/authors/" title="">
              作者
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        
        
        
        
        
        
        
          23小时前
        
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>MiniMax发布其自研的MiniMax-M1模型，这是一款全球首个开源、大规模实现混合注意力的推理模型，凭借独特的MoE架构、闪电注意力机制和创新的CISPO强化学习算法，在长上下文理解和智能体工具使用方面展现出顶尖性能与极致性价比，再次印证了MiniMax作为一家深度“模型驱动”的AI公司的战略选择。</p></blockquote>
<p>在当下全球大模型技术突破普遍趋于平缓之际，中国AI独角兽MiniMax却再次以一次大胆的底层技术革新，证明了其在基础模型领域持续激进探索的决心。日前，MiniMax正式推出了其酝酿已久的自研文本推理模型MiniMax-M1，将其定位为“金字塔尖的文本推理模型”，并强调其是<strong>全球首个开源、大规模实现混合注意力的推理模型</strong>。这一发布不仅标志着MiniMax在推理模型领域的重大突破，更折射出其在模型架构和算法层面坚持“非共识”路线的深层战略考量。</p>
<h3 id="技术架构的激进探索">技术架构的激进探索</h3>
<p>M1的登场并非孤立事件，它延续了MiniMax在底层架构上持续的激进创新。早在五个月前，MiniMax就已将MoE（Mixture of Experts，混合专家）架构和_Lightning Attention_（闪电注意力）引入其基础模型MiniMax-01系列。如今，M1作为MiniMax-01系列的进一步深化，将这些前沿理念推向了新的高度。</p>
<p>M1的核心技术亮点在于其对Transformer架构中注意力机制的“大改”。与市面上主流模型依赖标准Softmax Attention不同，M1大胆采用了<strong>混合注意力机制Lightning Attention</strong>。这种独特的注意力层设计旨在<strong>解放传统Softmax Attention在计算资源消耗方面的局限性</strong>，显著提高推理效率，并天然有利于强化学习的高效扩展<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。模型总参数达到4560亿，原生支持100万token的上下文长度输入，并拥有目前所有模型中最长的80ktoken输出长度，这在很大程度上得益于其底层架构的创新。</p>
<p>然而，探索混合架构和大规模强化学习的“无人区”并非坦途。MiniMax团队发现，传统的PPO/GRPO等强化学习算法在混合架构中会严重损害训练性能，尤其是在处理对稳定熵和促进可扩展RL至关重要的低概率_token_（如“however”、“wait”）时，这些_token_的梯度贡献容易被裁剪，阻碍了长链式思考（CoT）推理行为的促进。为解决这一难题，M1在算法层面提出了全新的强化学习算法<strong>CISPO</strong>。这项创新算法旨在<strong>明确避免丢弃任何_token_，同时将熵维持在合理范围以确保稳定探索</strong>。在Zero-RL设置下，CISPO在数学推理数据集上的表现显著优于字节跳动的DAPO和DeepSeek的GRPO算法，展现出更高的训练效率，仅需DAPO 50%的步数即可达到同等性能<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<p>这种“双线创新”——底层架构的线性注意力机制引入，以及算法层围绕CISPO形成的高效RL框架——最终使得M1的强化学习训练变得异常高效，进而带来了训练成本的大幅下降。根据MiniMax发布的技术报告，在生成10万Token长度时，M1的计算量仅为Deepseek R1的25%。更令人瞩目的是，M1的完整强化学习训练仅需<strong>512张H800 GPU在3周内完成</strong>，按照当前GPU租赁价格估算，<strong>成本仅为53.47万美元</strong>。这种极致的性能与性价比，无疑为大模型的商业化落地提供了新的想象空间。</p>
<h3 id="性能飞跃与应用潜力">性能飞跃与应用潜力</h3>
<p>M1在多项评测基准上的表现令人瞩目。在长上下文能力评测基准OpenAI-MRCR (128k/1M) 和LongBench-v2中，M1的表现远超包括DeepSeek-R1-0528和Qwen3-235B在内的所有开源模型。甚至与闭源模型相比，M1也超越了OpenAI o3和Claude 4 Opus，仅小幅落后于SOTA（<em>State-of-the-Art</em>）的Gemini 2.5 Pro<sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这表明M1在处理复杂、冗长信息方面的能力已跻身全球顶尖行列。</p>
<p>除了长上下文能力的强势，M1在**智能体工具使用（Agentic Tool Use）**维度上的能力上限更让人期待。从评测基准TAU-Bench (airline) 的表现来看，M1已是市面上在Agentic Tool Use方面能力最强的模型<sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这一能力对于构建更强大、更自主的AI智能体至关重要。</p>
<p>MiniMax也通过一系列Demo展示了M1在实际应用中的潜力。例如，M1可以根据一句自然语言指令<strong>生成一个复杂的迷宫游戏，并逐步可视化A*算法的求解过程</strong>，甚至能帮你<strong>从零到一搭建一个能够测试打字速度的网页</strong>，或<strong>创建一个可拖拽的便签墙</strong>。这些Demo都指向通用智能体中产品化_feature_的巨大可能性，而长上下文理解和智能体工具使用正是M1模型的强势所在。</p>
<h3 id="战略选择与行业启示">战略选择与行业启示</h3>
<p>M1的出现，是MiniMax从传统稠密模型与Transformer架构，转向MoE与线性注意力机制这一战略选择的最新成果。MiniMax在2023年夏天已投入公司80%的算力与研发资源转向MoE，并在Mistral 8✖️7B发布一个月后，上线了国内首个MoE大模型abab 6。其后，MiniMax-Text-01在今年1月成为<strong>第一个依赖线性注意力机制大规模部署的模型</strong>，验证了这种“非共识”架构的可行性<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。M1本质上又是基于MiniMax-Text-01的一次**_scale up_和架构创新**，通过7.5万亿_token_的定向增强预训练，大幅提升了模型在STEM（科学/技术/工程/数学）、编程代码与复杂推理等核心领域的能力。</p>
<p>MiniMax此前凭借其原生AI应用“星野”和“Talkie”在商业化上的优异表现，被外界赋予了“产品驱动”的标签<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>。然而，M1的发布以及MiniMax在模型底层架构层面持续的激进探索，有力地印证了MiniMax终究是一家“模型驱动”的AI公司。这种对基础技术路线的坚持，尤其是在行业普遍倾向于跟随主流架构时，选择“非共识”路径的勇气，使其得以在性能、效率和成本之间找到新的平衡点，并可能为整个AI领域带来新的范式。</p>
<p>值得注意的是，MiniMax官方宣布M1系列模型同时也拉开了为期五天的“MiniMaxWeek”序幕，预示着未来几天将围绕文本、语音和视觉等多模态模型公布更多技术进展。这表明MiniMax正系统性地将其底层架构创新扩展到更广泛的AI能力领域。在竞争日益激烈的AI大模型赛道，MiniMax的M1模型以其独特的技术路线和卓越的性能，不仅巩固了自身的技术身位，也为业界提供了一个关于<strong>如何在模型性能、训练效率和成本效益之间取得突破性进展</strong>的案例研究。这早该成为一种共识：在产品繁荣的表象之下，深耕模型底层、敢于挑战主流的技术实力，才是决定一家AI公司能否持续引领未来的关键。</p>
<h2 id="references">References</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>甘德（2025/6/17）。<a href="https://m.36kr.com/p/3340568175557127">MiniMax-M1 登场，MiniMax 再次证明自己是一家模型驱动的 AI 公司</a>。36氪。检索日期2025/6/18。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>（2025/1/16）。<a href="https://news.qq.com/rain/a/20250116A04BIZ00">突破Transformer架构，MiniMax 01首次开源，海外开发者再一次被中国模型震惊了</a>。腾讯新闻。检索日期2025/6/18。&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>（无日期）。<a href="https://www.minimaxi.com/news/minimaxm1">新闻动态 - MiniMax</a>。MiniMax官方网站。检索日期2025/6/18。&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/minimax/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">MiniMax</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">推理模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/m1/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">M1</a>
   </li>
  
   <li class="list di">
     <a href="/tags/moe/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">MoE</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%B7%B7%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">混合注意力</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E9%97%AA%E7%94%B5%E6%B3%A8%E6%84%8F%E5%8A%9B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">闪电注意力</a>
   </li>
  
   <li class="list di">
     <a href="/tags/cispo/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">CISPO</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">强化学习</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">人工智能</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/articles/minimax-m1ai-20250617202000424-10/">MiniMax M1：解构中国AI“六小虎”的首个开源推理模型，重塑长上下文交互的边界</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250617193006116-1/">游戏之智：小模型如何通过像素世界解锁通用推理能力</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/airichard-sutton-20250617003004877-3/">AI的未来之路：Richard Sutton预言“经验时代”的到来</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/openai65ioai-20250618082004323-1/">OpenAI豪掷65亿美元收购io：AI硬件的黎明，抑或又一个起点？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618082004330-2/">全球AI人才流动的悖论：中国人才基石的挑战与机遇</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618082004337-3/">面部识别技术：急速扩张下的监管真空与伦理困境</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/apiopenaigpt-45-20250618062004417-1/">API接口更迭引发开发者“阵痛”：OpenAI为何急于淘汰曾“最强大”的GPT-4.5？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/gemini-25aiopenai-20250618062004410-0/">谷歌Gemini 2.5：以“思考”模型重塑企业AI赛道，剑指OpenAI主导地位</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/metaai-20250618042004400-0/">Meta重金押注AI：一场关于数据、权力与“超级智能”的豪赌</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/metaai-20250618012004426-1/">Meta巨资押注AI：一场豪赌，还是市场重塑的序曲？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250618002005001-0/">任正非的“无心之言”：华为长局中的中国AI芯未来</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250617232005871-4/">情报领域的AI新前沿：中国情报机构重塑谍报战格局</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250617232005854-2/">泡沫退潮：中国大模型“六小龙”的分化与AI创业的残酷现实</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250617202000328-0/">AI制药：十年浮沉，从幻想到务实的新基建</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/articles/article-20250617202000381-5/">AI眼镜：从“百镜大战”到下一代计算平台的漫漫长路</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
