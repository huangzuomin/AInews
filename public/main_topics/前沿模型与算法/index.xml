<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>前沿模型与算法 on AI内参</title>
    <link>https://neican.huangzuomin.com/main_topics/%E5%89%8D%E6%B2%BF%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95/</link>
    <description>Recent content in 前沿模型与算法 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 21 Jun 2025 18:10:04 +0800</lastBuildDate>
    <atom:link href="https://neican.huangzuomin.com/main_topics/%E5%89%8D%E6%B2%BF%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大型语言模型的幻象：苹果争议揭示通用智能之路的挑战</title>
      <link>https://neican.huangzuomin.com/articles/article-20250621181004290-0/</link>
      <pubDate>Sat, 21 Jun 2025 18:10:04 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/article-20250621181004290-0/</guid>
      <description>苹果公司一篇质疑大型语言模型（LLM）推理能力和存在“准确率崩溃”的论文，在AI社区引发了激烈辩论，挑战了“规模化即一切”的行业信念。尽管面临来自AI专家和AI模型Claude本身的驳斥，但纽约大学教授加里·马库斯反驳了这些质疑，并获得了Salesforce和UC伯克利研究的间接支持，这些研究揭示了LLM在多轮推理和视觉理解上的脆弱性与隐私问题，促使业界重新思考AI的评估范式和神经符号结合等未来架构方向。</description>
    </item>
    <item>
      <title>稀疏激活的力量：蚂蚁Ring-lite如何重塑轻量级AI推理的格局</title>
      <link>https://neican.huangzuomin.com/articles/ring-liteai-20250621171702985-0/</link>
      <pubDate>Sat, 21 Jun 2025 17:17:02 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/ring-liteai-20250621171702985-0/</guid>
      <description>蚂蚁技术团队近日开源了轻量级MoE推理模型Ring-lite，该模型以其16.8亿总参数和仅2.75亿激活参数的精巧设计，在多项推理任务中实现了SOTA性能。其核心创新包括独创的C3PO强化学习训练方法和对多领域数据联合训练的优化，并承诺实现模型全链路的透明化开源，预示着高效、普惠与可信赖AI的新方向。</description>
    </item>
    <item>
      <title>软件范式的重塑：Andrej Karpathy解读AI时代的新代码与新操作系统</title>
      <link>https://neican.huangzuomin.com/articles/andrej-karpathyai-20250620211005691-3/</link>
      <pubDate>Fri, 20 Jun 2025 21:10:05 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/andrej-karpathyai-20250620211005691-3/</guid>
      <description>知名AI研究员Andrej Karpathy在近期演讲中提出“软件3.0”时代，将自然语言提示词视作新代码，大语言模型（LLM）比作新操作系统。他强调LLM作为计算平台的潜力，呼吁软件界面适应AI的“感知与行动”，并对AI代理的未来发展保持谨慎，主张通过人类监督和结构化协作来弥合AI的局限性。</description>
    </item>
    <item>
      <title>超级智能的路径之争：Meta研究员对OpenAI愿景的颠覆性质疑</title>
      <link>https://neican.huangzuomin.com/articles/metaopenai-20250620201004418-0/</link>
      <pubDate>Fri, 20 Jun 2025 20:10:04 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/metaopenai-20250620201004418-0/</guid>
      <description>OpenAI首席执行官Sam Altman认为构建超级智能是工程问题，但Meta AI研究员Jack Morris对此提出颠覆性质疑。Morris认为，当前依赖大语言模型（LLM）和强化学习（RL）的路径，受限于高质量训练数据的稀缺性及RL在可验证任务上的迁移能力不足，无法实现真正的通用超级智能。这场关于AI未来路径的辩论，揭示了行业在追求终极智能时面临的核心技术瓶颈和方法论分歧。</description>
    </item>
    <item>
      <title>当AI成为“外部大脑”：MIT研究揭示ChatGPT对人类认知的深层影响与“认知惯性”</title>
      <link>https://neican.huangzuomin.com/articles/aimitchatgpt-20250620201004425-1/</link>
      <pubDate>Fri, 20 Jun 2025 20:10:04 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/aimitchatgpt-20250620201004425-1/</guid>
      <description>麻省理工学院一项最新研究指出，过度使用ChatGPT等大型语言模型可能导致大脑活动水平下降，削弱记忆并引发“认知惯性”。这项结合脑电图与自然语言处理的实验发现，长期依赖AI会使大脑从主动生成信息转变为被动筛选信息，影响深度思考和创造力，提示人类需警惕AI对认知能力的潜在负面影响，并在工具使用与自主思考间寻求平衡。</description>
    </item>
    <item>
      <title>揭秘Gemini透明度迷雾：谷歌的“黑箱”决策如何挑战开发者信任与AI伦理</title>
      <link>https://neican.huangzuomin.com/articles/geminiai-20250620201004432-2/</link>
      <pubDate>Fri, 20 Jun 2025 20:10:04 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/geminiai-20250620201004432-2/</guid>
      <description>谷歌近期削减Gemini模型推理过程透明度的决定，引发了开发者社区的强烈不满，许多企业用户因无法有效调试而感到“盲目”。这一举动不仅损害了开发者对谷歌AI平台的信任，也凸显了前沿AI模型在性能与可解释性之间的内在矛盾，并对AI伦理、问责制以及谷歌在激烈AI竞赛中的市场地位构成了深远挑战。</description>
    </item>
    <item>
      <title>百万上下文与超低成本：MiniMax如何重塑大模型训练的经济学与Agent应用图景</title>
      <link>https://neican.huangzuomin.com/articles/minimaxagent-20250620191004664-2/</link>
      <pubDate>Fri, 20 Jun 2025 19:10:04 +0800</pubDate>
      <guid>https://neican.huangzuomin.com/articles/minimaxagent-20250620191004664-2/</guid>
      <description>MiniMax近日开源的MiniMax-M1模型以其百万级上下文处理能力和仅53.74万美元的强化学习训练成本，在AI领域引发震动。该模型通过创新的混合注意力架构和高效的强化学习算法（CISPO）实现性能与成本的平衡，并显著提升了AI Agent的工具调用和应用落地潜力。这一突破不仅挑战了现有大模型的高成本范式，也为AI产业的未来发展方向提供了新思路。</description>
    </item>
  </channel>
</rss>
