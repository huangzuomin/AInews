<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>算力与芯片 on AI内参</title>
    <link>http://192.168.50.247:1313/main_topics/%E7%AE%97%E5%8A%9B%E4%B8%8E%E8%8A%AF%E7%89%87/</link>
    <description>Recent content in 算力与芯片 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jun 2025 22:10:06 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/main_topics/%E7%AE%97%E5%8A%9B%E4%B8%8E%E8%8A%AF%E7%89%87/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</link>
      <pubDate>Fri, 27 Jun 2025 22:10:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。</description>
    </item>
    <item>
      <title>Meta的AI“豪赌”：扎克伯格的超万亿投入与“超智能”愿景</title>
      <link>http://192.168.50.247:1313/insights/metaai-20250627201005015-6/</link>
      <pubDate>Fri, 27 Jun 2025 20:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/metaai-20250627201005015-6/</guid>
      <description>Meta首席执行官马克·扎克伯格正大幅提升公司在AI领域的投入，预计年支出将超600亿美元，以在激烈的“超智能”竞争中抢占先机。这一战略核心在于对尖端AI模型（如Llama 4）和大规模数据中心的基础设施投资，旨在驱动其未来应用生态，同时引发了对科技巨头资源集中及AI社会影响的深层思考。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：2G显存解锁端侧AI新纪元</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</link>
      <pubDate>Fri, 27 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</guid>
      <description>谷歌最新发布的Gemma 3n模型凭借革命性的MatFormer架构和多项优化技术，成功将高性能多模态AI的显存需求降至2GB，并在大模型竞技场中刷新纪录，成为首个得分超过1300分的10B以下模型。这一突破不仅极大地降低了AI在各类端侧设备上部署的门槛，也预示着AI应用将更加普及、注重隐私且响应迅速，对未来的智能设备和AI生态产生深远影响。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</title>
      <link>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</link>
      <pubDate>Fri, 27 Jun 2025 19:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其仅需2GB内存即可运行的超高效能，重新定义了边缘AI的可能性。这款模型集成了MatFormer弹性架构、逐层嵌入机制和KV Cache共享等前沿技术，实现了在低参数量下对多模态输入的出色处理能力，并在LMArena基准测试中创下1300分的记录。Gemma 3n的发布，预示着高性能AI将更广泛地赋能智能手机、物联网设备等边缘端，加速AI的普及与民主化，深刻影响未来的计算范式。</description>
    </item>
    <item>
      <title>Meta掀起AI人才争夺战：天价挖角OpenAI，豪掷千亿押注“超级智能”</title>
      <link>http://192.168.50.247:1313/insights/metaaiopenai-20250627151004879-4/</link>
      <pubDate>Fri, 27 Jun 2025 15:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/metaaiopenai-20250627151004879-4/</guid>
      <description>Meta正通过一系列激进策略，包括从OpenAI等顶尖机构挖角核心AI研究人员，以及投入高达650亿美元建设庞大数据中心（含超130万块英伟达GPU），加速其在“超级智能”领域的布局。这一举措反映了AI前沿人才争夺的白热化，以及Meta在现有大模型（如Llama 4 Behemoth）面临挑战后，对实现超越人类智能的深远野心，预示着AI产业的竞争将更加激烈。</description>
    </item>
    <item>
      <title>多模态AI浪潮下的“减负”行动：火山引擎重塑音视频开发格局</title>
      <link>http://192.168.50.247:1313/insights/article-20250627141004384-0/</link>
      <pubDate>Fri, 27 Jun 2025 14:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250627141004384-0/</guid>
      <description>火山引擎推出多媒体智能处理平台MIPP和分布式BMF框架，旨在解决多模态AI时代音视频开发面临的成本、性能与复杂性挑战。通过帧级别调度、解耦编排与部署、以及提供丰富的原子能力，MIPP致力于为开发者“减负”，提升效率，并期望通过开源策略构建开放的生态壁垒。</description>
    </item>
    <item>
      <title>大模型基础设施的“暗涌”：工程师如何穿越复杂性与成本的迷雾</title>
      <link>http://192.168.50.247:1313/insights/article-20250626121005078-1/</link>
      <pubDate>Thu, 26 Jun 2025 12:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250626121005078-1/</guid>
      <description>大模型基础设施工程师正面临严峻挑战，包括大规模集群的稳定性问题、性能瓶颈和高昂的运营成本。他们通过模型与部署联合设计、精细化KV缓存管理、以及利用新型硬件架构如华为Cloud Matrix提升算力利用率，来优化成本和性能。同时，开源社区的协作和异构硬件的智能调度，正成为未来AI基础设施发展的关键趋势。</description>
    </item>
    <item>
      <title>AI基石：计算向数据靠拢，重塑智能时代基础设施</title>
      <link>http://192.168.50.247:1313/insights/article-20250626021004172-1/</link>
      <pubDate>Thu, 26 Jun 2025 02:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250626021004172-1/</guid>
      <description>随着人工智能对算力和数据处理提出前所未有的要求，传统“数据向计算靠拢”的模式已演变为“计算向数据靠拢”，旨在通过将处理能力与存储紧密结合，显著提升AI工作负载的效率和性能。这一范式转变正重塑IT基础设施，推动软件定义存储、高性能SSD以及云原生架构的发展，以应对GPU利用率低下和复杂数据流管理的挑战，从而加速企业级AI的广泛落地。</description>
    </item>
    <item>
      <title>国产GPU巨头沐曦冲刺IPO：一场关乎AI未来的技术与资本竞速</title>
      <link>http://192.168.50.247:1313/insights/gpuipoai-20250625181004413-2/</link>
      <pubDate>Wed, 25 Jun 2025 18:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gpuipoai-20250625181004413-2/</guid>
      <description>中国GPU独角兽沐曦集成电路已完成上市辅导，紧随摩尔线程，标志着本土AI芯片厂商正加速冲刺资本市场。沐曦凭借前AMD团队的经验、自主IP和对标英伟达的性能，正积极构建兼容主流生态的软件栈，并在大模型适配浪潮中抓住DeepSeek带来的软硬协同新机遇，以应对全球算力竞争和实现国家科技自主的战略需求。</description>
    </item>
    <item>
      <title>边缘智能的突破：小米小爱同学如何在资源受限下实现高性能大模型推理</title>
      <link>http://192.168.50.247:1313/insights/article-20250624231007315-0/</link>
      <pubDate>Tue, 24 Jun 2025 23:10:07 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624231007315-0/</guid>
      <description>小米小爱同学团队在端侧大模型部署方面取得了显著进展，通过自研推理框架、动态优化、投机推理、量化以及创新的“共享基座+LoRA”架构，成功克服了移动设备资源限制，实现了高性能、多任务并发。文章深入剖析了小米的技术策略，并展望了未来硬件与模型架构（如Linear Attention）在推动端侧AI普惠化中的关键作用。</description>
    </item>
    <item>
      <title>微软Mu：操作系统中的微型AI革命，重塑本地智能交互边界</title>
      <link>http://192.168.50.247:1313/insights/muai-20250624151004533-3/</link>
      <pubDate>Tue, 24 Jun 2025 15:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/muai-20250624151004533-3/</guid>
      <description>微软正式发布了仅3.3亿参数的设备端小型语言模型Mu，专为Windows 11的设置应用打造智能AI代理。Mu在NPU上本地运行，提供低延迟、高隐私的自然语言交互，显著简化了系统操作。这一创新不仅代表了AI从云端向边缘计算的战略性转移，也为未来操作系统中更广泛、更私密的本地AI应用奠定了基础。</description>
    </item>
    <item>
      <title>AI手机核心之争：芯片巨头如何在性能、架构与生态中角逐未来</title>
      <link>http://192.168.50.247:1313/insights/article-20250624101004329-0/</link>
      <pubDate>Tue, 24 Jun 2025 10:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624101004329-0/</guid>
      <description>2025年，手机AI芯片市场迎来白热化竞争，苹果、华为、高通、小米、联发科、三星六大巨头正围绕芯片能效、自研架构及开发生态展开全面较量。文章深入分析了各方在先进工艺、CPU/GPU/NPU自研深度以及AI开发工具链上的核心策略与挑战，指出在AI手机时代，对底层芯片技术的掌控和软硬件深度协同将是决胜的关键。</description>
    </item>
    <item>
      <title>商汤重塑：徐冰离职与AI芯片的战略剥离背后</title>
      <link>http://192.168.50.247:1313/insights/article-20250624091004643-0/</link>
      <pubDate>Tue, 24 Jun 2025 09:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624091004643-0/</guid>
      <description>商汤科技联合创始人徐冰卸任，转而负责公司分拆出去的AI芯片业务，此举是商汤在持续巨额亏损下“甩包袱”的战略调整。公司正从多元化转向聚焦生成式AI和算力服务，但AI芯片业务面临巨大烧钱压力和激烈市场竞争，而其核心生成式AI业务也深陷与头部巨头的算力与用户争夺战，商汤的未来面临严峻挑战。</description>
    </item>
    <item>
      <title>特斯拉Robotaxi终上线：一次由“巨型神经网络”驱动的豪赌</title>
      <link>http://192.168.50.247:1313/insights/robotaxi-20250623181004312-2/</link>
      <pubDate>Mon, 23 Jun 2025 18:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/robotaxi-20250623181004312-2/</guid>
      <description>特斯拉在美国奥斯汀正式启动Robotaxi试点服务，标志着其自动驾驶商业化迈出关键一步。此次上线得益于核心AI团队将系统从传统启发式代码转变为由印度裔工程师阿肖克·埃卢斯瓦米主导的“巨型神经网络”，显著提升了决策能力和算力需求。尽管面临Waymo和中国同行的激烈竞争，并仍需解决规模化挑战，特斯拉正以其惊人算力投入，加速其实现通用人工智能和改变未来经济格局的宏大愿景。</description>
    </item>
    <item>
      <title>GMI Cloud 亮相 WAIC 2025：AI算力基础设施的全球化进击与深层博弈</title>
      <link>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113258957-8/</link>
      <pubDate>Mon, 23 Jun 2025 11:32:58 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113258957-8/</guid>
      <description>GMI Cloud作为AI Native云服务商，将在WAIC 2025全面展示其AI基础设施，包括提升效率和性能的Cluster Engine与Inference Engine，以及与NVIDIA和DDN合作的AI Native Cloud服务。此次参展不仅是技术实力秀，更是GMI Cloud在AI算力全球化部署和AI应用出海战略上的深度布局，旨在通过全栈解决方案，加速企业AI落地并赋能通用人工智能的未来发展。</description>
    </item>
    <item>
      <title>GMI Cloud 亮相 WAIC 2025：AI算力基础设施的全球化进击与深层博弈</title>
      <link>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113044244-8/</link>
      <pubDate>Mon, 23 Jun 2025 11:30:44 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113044244-8/</guid>
      <description>GMI Cloud作为AI Native云服务商，将在WAIC 2025全面展示其AI基础设施，包括提升效率和性能的Cluster Engine与Inference Engine，以及与NVIDIA和DDN合作的AI Native Cloud服务。此次参展不仅是技术实力秀，更是GMI Cloud在AI算力全球化部署和AI应用出海战略上的深度布局，旨在通过全栈解决方案，加速企业AI落地并赋能通用人工智能的未来发展。</description>
    </item>
  </channel>
</rss>
