<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI伦理 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/ai%E4%BC%A6%E7%90%86/</link>
    <description>Recent content in AI伦理 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 17 Jun 2025 08:30:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/ai%E4%BC%A6%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>中国AI赛道新动向：基础模型之“炼”与智能代理之“用”</title>
      <link>http://192.168.50.247:1313/articles/article-20250617083004593-0/</link>
      <pubDate>Tue, 17 Jun 2025 08:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617083004593-0/</guid>
      <description>中国的人工智能产业正经历一场战略重心转移：尽管在基础大语言模型研发上面临巨大挑战，但在AI Agent（智能代理）的落地应用方面却展现出独特的优势与机遇。得益于庞大而复杂的数字应用场景、以实用主义为导向的“应用驱动创新”文化、完善的数字基础设施以及政府政策的支持，中国正成为AI Agent蓬勃发展的沃土。这一趋势不仅为企业提供了降本增效的新途径，也预示着AI技术在中国将走出一条务实高效的差异化发展道路。</description>
    </item>
    <item>
      <title>当算法走进课堂：AI的效率飞跃与教育“温度”的永恒命题</title>
      <link>http://192.168.50.247:1313/articles/article-20250617025225327-0/</link>
      <pubDate>Tue, 17 Jun 2025 02:52:25 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617025225327-0/</guid>
      <description>随着AI在高考等标准化测试中展现出卓越能力，其在教育领域的应用日益深化，显著提升了教学效率并实现了个性化学习。然而，这种技术革新也引发了关于教育本质的深刻伦理讨论：如何在拥抱AI所带来的效率和便利的同时，避免课堂沦为算法操控的“流水线”，并确保教育中不可或缺的人文关怀、批判性思维与情感联结得以保留和发展，成为当前亟待解决的关键问题。</description>
    </item>
    <item>
      <title>付费之外的“幻觉广告”：OpenAI的盈利焦虑与AI伦理的深层挑战</title>
      <link>http://192.168.50.247:1313/articles/openaiai-20250617025225349-3/</link>
      <pubDate>Tue, 17 Jun 2025 02:52:25 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/openaiai-20250617025225349-3/</guid>
      <description>ChatGPT付费用户报告在高级语音模式中遭遇商业广告，OpenAI虽称之为“幻觉”，但这暴露了该公司在巨额亏损下寻求盈利的迫切需求。此次事件不仅引发了对AI模型“幻觉”定义的争议和用户信任危机，也迫使业界重新审视AI技术在商业化进程中面临的伦理挑战和商业模式的未来走向。</description>
    </item>
    <item>
      <title>当人机共生走向极端：一位资深程序员的AI痴迷与职业终结</title>
      <link>http://192.168.50.247:1313/articles/article-20250617003004891-5/</link>
      <pubDate>Tue, 17 Jun 2025 00:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617003004891-5/</guid>
      <description>一位50余岁资深程序员因过度依赖GitHub Copilot，拒绝亲自编码和调试，并散布AI将取代新人的言论，最终被公司解雇。此案例凸显了在AI浪潮下，技术工具合理边界的界定、个人核心职业技能的维系，以及职场伦理和团队协作的重要性，引发了对人机共生未来模式的深度思考。</description>
    </item>
    <item>
      <title>Google NotebookLM：当AI成为你的专属知识策展人，连OpenAI也为之侧目</title>
      <link>http://192.168.50.247:1313/articles/google-notebooklmaiopenai-20250616123004/</link>
      <pubDate>Mon, 16 Jun 2025 12:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/google-notebooklmaiopenai-20250616123004/</guid>
      <description>Google近期推出的NotebookLM是一款基于用户私有知识库的AI笔记应用，其独特的“源头接地”特性和创新的“音频概览”功能，大幅降低了AI幻觉并提升了知识交互体验，甚至获得OpenAI创始成员Andrej Karpathy的高度评价。这款工具不仅改变了个人知识管理和内容消费模式，也预示着AI在个性化学习和内容创作领域的深远影响，成为Google在AI军备竞赛中对抗OpenAI的重要战略部署。</description>
    </item>
    <item>
      <title>超越表象：大语言模型“遗忘”的深层结构与可逆边界</title>
      <link>http://192.168.50.247:1313/articles/article-20250616123004/</link>
      <pubDate>Mon, 16 Jun 2025 12:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250616123004/</guid>
      <description>一项由香港理工大学、卡内基梅隆大学和加州大学圣克鲁兹分校共同完成的开创性研究，首次系统揭示了大语言模型“遗忘”现象背后的深层表示结构变化。研究区分了“可逆性遗忘”与“不可逆性遗忘”的本质差异，强调真正的遗忘是结构性抹除而非行为抑制，并通过一套表示空间诊断工具，为构建更安全、可控的机器遗忘机制奠定了基础。</description>
    </item>
    <item>
      <title>十亿美元AI折戟儿童谜题：苹果研究揭示大型模型“思考幻象”背后的深层警示</title>
      <link>http://192.168.50.247:1313/articles/2025-06-11-article-497/</link>
      <pubDate>Wed, 11 Jun 2025 00:02:25 +0000</pubDate>
      <guid>http://192.168.50.247:1313/articles/2025-06-11-article-497/</guid>
      <description>苹果公司最新研究《思考的幻象》揭示，耗资巨大的大型AI模型在复杂推理任务上表现脆弱，其智能多为模式识别而非真正理解。这份报告印证了AI批评家加里·马库斯长期以来对过度炒作的警示，强调了AI在处理新颖情境和深层逻辑时的根本性局限。这促使行业深刻反思，呼吁AI研究回归基础认知构建，并在社会和伦理层面审慎对待AI的部署与应用。</description>
    </item>
    <item>
      <title>AI“思考的幻觉”：当十亿美元模型被孩童谜题击败，我们该如何重新审视AI的承诺？</title>
      <link>http://192.168.50.247:1313/articles/2025-06-10-article-495/</link>
      <pubDate>Tue, 10 Jun 2025 16:40:06 +0000</pubDate>
      <guid>http://192.168.50.247:1313/articles/2025-06-10-article-495/</guid>
      <description>苹果公司近期研究揭示，大型语言模型在复杂推理任务上表现出明显局限，甚至在面对孩童都能解决的谜题时会“崩溃”，引发了对AI过度宣传的重新思考。文章深入探讨了当前AI在模式识别与真正推理之间的鸿沟，并分析了这种“思考的幻觉”可能带来的社会、伦理和经济风险，强调AI发展需从追求表面智能转向提升核心的可靠推理能力。</description>
    </item>
    <item>
      <title>Meta的“超级智能”野望：AI重组与百亿级战略投资的深层剖析</title>
      <link>http://192.168.50.247:1313/articles/2025-06-10-article-489/</link>
      <pubDate>Tue, 10 Jun 2025 14:09:35 +0000</pubDate>
      <guid>http://192.168.50.247:1313/articles/2025-06-10-article-489/</guid>
      <description>Meta正在重组其人工智能部门，并新设实验室以追求“超级智能”的长期目标。同时，该公司正与AI数据服务巨头Scale AI商谈一项可能超过100亿美元的巨额投资，旨在确保其未来AI模型获得高质量数据支持，这标志着Meta在AI前沿领域的激进布局及其对技术、社会和伦理影响的深层考量。</description>
    </item>
  </channel>
</rss>
