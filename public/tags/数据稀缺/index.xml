<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据稀缺 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E6%95%B0%E6%8D%AE%E7%A8%80%E7%BC%BA/</link>
    <description>Recent content in 数据稀缺 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 18 Jun 2025 20:20:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E6%95%B0%E6%8D%AE%E7%A8%80%E7%BC%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越 Transformer：具身智能能否摆脱“水土不服”的困境？</title>
      <link>http://192.168.50.247:1313/articles/-transformer-20250618202004715-0/</link>
      <pubDate>Wed, 18 Jun 2025 20:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/-transformer-20250618202004715-0/</guid>
      <description>当前，Transformer大模型在具身智能领域面临“水土不服”的挑战，主要原因在于硬件不稳定、数据稀缺以及大模型架构在能耗、泛化能力和物理世界理解上的局限。专家指出，具身智能正从模块化向端到端架构演进，并呼吁超越现有Transformer范式，探索能耗更低、更适应物理世界的新型模型架构，以实现“具身”与“智能”的真正融合。</description>
    </item>
  </channel>
</rss>
