<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>语言模型 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 语言模型 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 02 Jul 2025 11:40:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>当AI教会我们“写好”文章，我们是否正在失去深度与原创性？</title>
      <link>http://192.168.50.247:1313/insights/article-20250702114004558-1/</link>
      <pubDate>Wed, 02 Jul 2025 11:40:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250702114004558-1/</guid>
      <description>《纽约客》近期报道揭示，AI正在以“效率”为名重塑人类思维与写作方式，可能导致原创性与批判性思维的丧失。麻省理工学院和康奈尔大学的研究显示，过度依赖AI会降低大脑活动、导致思想同质化，并可能强化文化霸权。文章呼吁对AI带来的“平庸化革命”进行理性反思，警惕技术乐观主义的潜在风险。</description>
    </item>
    <item>
      <title>超越静态模型：麻省理工学院SEAL框架赋能AI自主学习新范式</title>
      <link>http://192.168.50.247:1313/insights/sealai-20250624061004196-0/</link>
      <pubDate>Tue, 24 Jun 2025 06:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/sealai-20250624061004196-0/</guid>
      <description>麻省理工学院推出的SEAL框架，让语言模型能够通过自主生成数据和自我纠正，实现持续学习和能力提升，突破了传统AI模型的静态局限。这项技术不仅能显著降低对大规模人工标注数据的依赖，提高AI的适应性和鲁棒性，也引发了关于AI可解释性、控制与伦理责任等深层社会影响的思考。</description>
    </item>
    <item>
      <title>集体智能的崛起：GRA框架如何赋能小模型“逆袭”大模型，重塑AI开发图景</title>
      <link>http://192.168.50.247:1313/insights/graai-20250617202000362-3/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/graai-20250617202000362-3/</guid>
      <description>上海人工智能实验室与中国人民大学推出的GRA框架，通过模拟学术审稿流程，使多个小型语言模型（7B级别）协同生成高质量训练数据，性能可媲美甚至超越72B大模型蒸馏的效果。这项开源技术为AI模型的开发提供了一种更经济高效、更具普惠性的新范式，有望打破当前对大规模参数模型的过度依赖，促进AI领域的民主化和可持续发展。</description>
    </item>
  </channel>
</rss>
