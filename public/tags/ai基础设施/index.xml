<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI基础设施 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/</link>
    <description>Recent content in AI基础设施 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 26 Jun 2025 12:10:05 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大模型基础设施的“暗涌”：工程师如何穿越复杂性与成本的迷雾</title>
      <link>http://192.168.50.247:1313/insights/article-20250626121005078-1/</link>
      <pubDate>Thu, 26 Jun 2025 12:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250626121005078-1/</guid>
      <description>大模型基础设施工程师正面临严峻挑战，包括大规模集群的稳定性问题、性能瓶颈和高昂的运营成本。他们通过模型与部署联合设计、精细化KV缓存管理、以及利用新型硬件架构如华为Cloud Matrix提升算力利用率，来优化成本和性能。同时，开源社区的协作和异构硬件的智能调度，正成为未来AI基础设施发展的关键趋势。</description>
    </item>
    <item>
      <title>AI基石：计算向数据靠拢，重塑智能时代基础设施</title>
      <link>http://192.168.50.247:1313/insights/article-20250626021004172-1/</link>
      <pubDate>Thu, 26 Jun 2025 02:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250626021004172-1/</guid>
      <description>随着人工智能对算力和数据处理提出前所未有的要求，传统“数据向计算靠拢”的模式已演变为“计算向数据靠拢”，旨在通过将处理能力与存储紧密结合，显著提升AI工作负载的效率和性能。这一范式转变正重塑IT基础设施，推动软件定义存储、高性能SSD以及云原生架构的发展，以应对GPU利用率低下和复杂数据流管理的挑战，从而加速企业级AI的广泛落地。</description>
    </item>
    <item>
      <title>GMI Cloud 亮相 WAIC 2025：AI算力基础设施的全球化进击与深层博弈</title>
      <link>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113258957-8/</link>
      <pubDate>Mon, 23 Jun 2025 11:32:58 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113258957-8/</guid>
      <description>GMI Cloud作为AI Native云服务商，将在WAIC 2025全面展示其AI基础设施，包括提升效率和性能的Cluster Engine与Inference Engine，以及与NVIDIA和DDN合作的AI Native Cloud服务。此次参展不仅是技术实力秀，更是GMI Cloud在AI算力全球化部署和AI应用出海战略上的深度布局，旨在通过全栈解决方案，加速企业AI落地并赋能通用人工智能的未来发展。</description>
    </item>
    <item>
      <title>GMI Cloud 亮相 WAIC 2025：AI算力基础设施的全球化进击与深层博弈</title>
      <link>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113044244-8/</link>
      <pubDate>Mon, 23 Jun 2025 11:30:44 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gmi-cloud-waic-2025ai-20250623113044244-8/</guid>
      <description>GMI Cloud作为AI Native云服务商，将在WAIC 2025全面展示其AI基础设施，包括提升效率和性能的Cluster Engine与Inference Engine，以及与NVIDIA和DDN合作的AI Native Cloud服务。此次参展不仅是技术实力秀，更是GMI Cloud在AI算力全球化部署和AI应用出海战略上的深度布局，旨在通过全栈解决方案，加速企业AI落地并赋能通用人工智能的未来发展。</description>
    </item>
    <item>
      <title>华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式</title>
      <link>http://192.168.50.247:1313/insights/aicloudmatrix384-20250619082004293-1/</link>
      <pubDate>Thu, 19 Jun 2025 08:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/aicloudmatrix384-20250619082004293-1/</guid>
      <description>华为最新发布的CloudMatrix384 AI超级节点，在DeepSeek-R1大语言模型评估中展现出超越英伟达H800 GPU的计算效率。这一突破性成果得益于CloudMatrix384创新的统一总线（UB）网络架构和昇腾910C NPU的协同作用，为构建高性能、可扩展的AI原生数据中心树立了新标杆，并预示着全球AI算力格局的潜在转变。</description>
    </item>
    <item>
      <title>AI算力浪潮下的隐形负担：美国数据中心爆发式增长的环境警示</title>
      <link>http://192.168.50.247:1313/insights/article-20250618192004390-1/</link>
      <pubDate>Wed, 18 Jun 2025 19:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250618192004390-1/</guid>
      <description>随着人工智能技术的迅猛发展，美国正经历一场史无前例的数据中心建设热潮，已建成或获批数据中心达1240座。这些支撑AI的“算力蜂巢”带来了巨大的环境足迹，其用电量预计将与波兰全国相当，年耗水量更超过五个杭州西湖，对当地电网和水资源构成严重压力。尽管科技巨头承诺绿色转型，但AI的物理基础设施扩张与可持续发展之间的矛盾日益突出，迫使社会不得不重新审视技术进步的真实代价。</description>
    </item>
    <item>
      <title>字节跳动的AI Agent豪赌：重塑数字未来的关键战役</title>
      <link>http://192.168.50.247:1313/insights/ai-agent-20250617193006124-2/</link>
      <pubDate>Tue, 17 Jun 2025 19:30:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/ai-agent-20250617193006124-2/</guid>
      <description>字节跳动正将全部赌注押向AI Agent这一新兴范式，旨在通过火山引擎在云计算市场实现“换道超车”，以应对AI时代对传统App模式的颠覆。此举不仅涉及豆包大模型的迭代与成本优化，更在于构建一套完整的AI云原生基础设施，以期在激烈的竞争和未知的挑战中，抢占下一代互联网的核心入口，实现其长期AGI愿景。</description>
    </item>
    <item>
      <title>Groq携手Hugging Face：一场重塑AI推理格局的速度革命</title>
      <link>http://192.168.50.247:1313/insights/groqhugging-faceai-20250617083004617-2/</link>
      <pubDate>Tue, 17 Jun 2025 08:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/groqhugging-faceai-20250617083004617-2/</guid>
      <description>Groq凭借其独特的LPU架构，与Hugging Face达成深度合作，成为其官方推理提供商，显著提升了开源AI模型的推理速度。此举不仅为数百万开发者带来了前所未有的高性能AI推理能力，也直接挑战了亚马逊AWS和谷歌等云服务巨头在AI基础设施领域的市场主导地位，预示着AI计算格局的深远变革。</description>
    </item>
  </channel>
</rss>
