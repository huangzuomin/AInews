<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>开源模型 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 开源模型 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 03 Jul 2025 15:40:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>智源OmniGen2：从视觉到思考，统一多模态模型如何重塑AI内容生成与产业未来</title>
      <link>http://192.168.50.247:1313/insights/omnigen2ai-20250703154004166-1/</link>
      <pubDate>Thu, 03 Jul 2025 15:40:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/omnigen2ai-20250703154004166-1/</guid>
      <description>智源研究院推出的OmniGen2以其统一的多模态图像生成能力和创新的“反思机制”引发广泛关注，其全面开源将加速AIGC领域的技术普及和产业创新。该模型不仅在技术架构上实现突破，解决数据挑战，更通过赋予AI自我修正能力，预示着通用人工智能在视觉领域的加速到来，并重塑内容创作与商业应用范式，同时对AI伦理与治理提出新要求。</description>
    </item>
    <item>
      <title>本地AI：企业驾驭数据隐私与创新的关键路径</title>
      <link>http://192.168.50.247:1313/insights/article-20250702191004634-3/</link>
      <pubDate>Wed, 02 Jul 2025 19:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250702191004634-3/</guid>
      <description>本地AI模型正成为企业在利用人工智能的同时，解决数据隐私和安全挑战的关键方案。通过在本地运行AI模型，企业可以确保敏感数据无需上传至云端，从而大幅降低泄露风险并满足严格的行业合规要求。这不仅推动了负责任的AI应用，也为医疗、金融等数据敏感行业提供了前所未有的创新机遇。</description>
    </item>
    <item>
      <title>硅谷AI人才战升级：OpenAI的紧急反击与AGI愿景的再聚焦</title>
      <link>http://192.168.50.247:1313/insights/aiopenaiagi-20250630171004471-1/</link>
      <pubDate>Mon, 30 Jun 2025 17:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/aiopenaiagi-20250630171004471-1/</guid>
      <description>OpenAI近期因Meta对其核心AI人才的激进挖角而采取了紧急应对措施，包括大幅提高薪酬、加强内部沟通和实施全员休假。这场白热化的人才争夺战凸显了AI时代顶级技术人才作为战略资源的核心地位，也促使OpenAI重申其对通用人工智能（AGI）长期愿景的聚焦，并预示其可能通过发布强大的开源模型来增强竞争力。</description>
    </item>
    <item>
      <title>Sam Altman描绘AI终极蓝图：从“生活操作系统”到具身智能的未来</title>
      <link>http://192.168.50.247:1313/insights/sam-altmanai-20250630161004921-0/</link>
      <pubDate>Mon, 30 Jun 2025 16:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/sam-altmanai-20250630161004921-0/</guid>
      <description>OpenAI首席执行官萨姆·奥特曼描绘了AI的未来蓝图，即AI将演变为无处不在的“生活操作系统”，其核心在于更强大、更经济的开源及本地部署模型，以及具备记忆功能并主动服务的“AI伴侣”。他预言未来AI将与具身智能（机器人）深度融合，甚至暗示高级订阅用户将免费获得机器人，同时强调AI在加速科学发现中的巨大潜力。</description>
    </item>
    <item>
      <title>百度文心4.5系列模型全面开源：大模型竞赛的下一战场</title>
      <link>http://192.168.50.247:1313/insights/article-20250630111004423-1/</link>
      <pubDate>Mon, 30 Jun 2025 11:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250630111004423-1/</guid>
      <description>百度于6月30日全面开源其文心大模型4.5系列，涵盖了从大型MoE模型到轻量级稠密模型等10款不同参数规模的模型，并开放了预训练权重和推理代码。此举不仅展示了百度在多模态异构MoE预训练、高效基础设施及模态特定后训练方面的技术突破，更在全球AI大模型开源竞争中迈出重要一步，旨在通过技术普惠加速AI生态发展，同时也面临着社区维护和平衡商业化等挑战。</description>
    </item>
    <item>
      <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</link>
      <pubDate>Fri, 27 Jun 2025 22:10:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：2G显存解锁端侧AI新纪元</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</link>
      <pubDate>Fri, 27 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</guid>
      <description>谷歌最新发布的Gemma 3n模型凭借革命性的MatFormer架构和多项优化技术，成功将高性能多模态AI的显存需求降至2GB，并在大模型竞技场中刷新纪录，成为首个得分超过1300分的10B以下模型。这一突破不仅极大地降低了AI在各类端侧设备上部署的门槛，也预示着AI应用将更加普及、注重隐私且响应迅速，对未来的智能设备和AI生态产生深远影响。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</title>
      <link>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</link>
      <pubDate>Fri, 27 Jun 2025 19:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其仅需2GB内存即可运行的超高效能，重新定义了边缘AI的可能性。这款模型集成了MatFormer弹性架构、逐层嵌入机制和KV Cache共享等前沿技术，实现了在低参数量下对多模态输入的出色处理能力，并在LMArena基准测试中创下1300分的记录。Gemma 3n的发布，预示着高性能AI将更广泛地赋能智能手机、物联网设备等边缘端，加速AI的普及与民主化，深刻影响未来的计算范式。</description>
    </item>
    <item>
      <title>超越符号：新型大模型如何通过代码图谱重塑软件工程的未来</title>
      <link>http://192.168.50.247:1313/insights/article-20250627171004412-0/</link>
      <pubDate>Fri, 27 Jun 2025 17:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250627171004412-0/</guid>
      <description>蚂蚁团队开源的Code Graph Model（CGM）首次使大模型能够直接理解代码图谱，无需复杂的Agent即可实现自动bug修复。该模型在SWE-Bench Lite上实现了44%的修复率，超越所有开源方案并媲美闭源模型，并通过其开源特性为软件工程自动化提供了更高效、可控和透明的路径。</description>
    </item>
    <item>
      <title>MiniMax M1的开源：在长上下文AI推理前沿的突破与权衡</title>
      <link>http://192.168.50.247:1313/insights/minimax-m1ai-20250626181004155-0/</link>
      <pubDate>Thu, 26 Jun 2025 18:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/minimax-m1ai-20250626181004155-0/</guid>
      <description>MiniMax近日开源了其首款推理模型M1，这款4560亿参数的混合注意力模型专为长上下文推理和软件任务设计，通过创新的“闪电注意力”和混合专家架构实现了百万级上下文与高效计算。尽管在多项基准测试中表现出色，尤其在长文本和软件工程领域树立了新标杆，但其在实际应用中仍面临稳定性挑战，凸显了实验室性能与真实世界鲁棒性之间的鸿沟，对未来AI模型的实用化提出了更高要求。</description>
    </item>
    <item>
      <title>有道“子曰3”：低成本AI大模型如何重塑数学教育的公平版图</title>
      <link>http://192.168.50.247:1313/insights/3ai-20250623181004301-0/</link>
      <pubDate>Mon, 23 Jun 2025 18:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/3ai-20250623181004301-0/</guid>
      <description>网易有道最新推出的“子曰3”数学大模型以极低的训练和推理成本，在消费级硬件上展现出卓越的数学推理能力，尤其在高考数学评测中表现亮眼。该模型通过开源和降低AI应用门槛，旨在促进教育公平，解决资源不均问题，并为“AI + 教育”领域及垂直模型发展树立了新范式。</description>
    </item>
    <item>
      <title>OpenAI新篇章：Sam Altman预告开源模型、GPT-5多模态跃进与智能体时代的来临</title>
      <link>http://192.168.50.247:1313/insights/openaisam-altmangpt-5-20250623113259005-16/</link>
      <pubDate>Mon, 23 Jun 2025 11:32:59 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/openaisam-altmangpt-5-20250623113259005-16/</guid>
      <description>OpenAI首席执行官Sam Altman近日宣布了公司战略的重大转变：即将发布一个功能强大的开源模型，同时预告今年夏季推出的GPT-5将实现全面的多模态能力，支持语音、图像、代码和视频等多种输入。Altman还强调2025年是“智能体之年”，预示AI将从被动工具演变为能独立执行任务的“初级员工”，并呼吁创业者抓住这一技术变革的黄金时期。</description>
    </item>
    <item>
      <title>OpenAI新篇章：Sam Altman预告开源模型、GPT-5多模态跃进与智能体时代的来临</title>
      <link>http://192.168.50.247:1313/insights/openaisam-altmangpt-5-20250623113044290-16/</link>
      <pubDate>Mon, 23 Jun 2025 11:30:44 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/openaisam-altmangpt-5-20250623113044290-16/</guid>
      <description>OpenAI首席执行官Sam Altman近日宣布了公司战略的重大转变：即将发布一个功能强大的开源模型，同时预告今年夏季推出的GPT-5将实现全面的多模态能力，支持语音、图像、代码和视频等多种输入。Altman还强调2025年是“智能体之年”，预示AI将从被动工具演变为能独立执行任务的“初级员工”，并呼吁创业者抓住这一技术变革的黄金时期。</description>
    </item>
    <item>
      <title>稀疏激活的力量：蚂蚁Ring-lite如何重塑轻量级AI推理的格局</title>
      <link>http://192.168.50.247:1313/insights/ring-liteai-20250621171702985-0/</link>
      <pubDate>Sat, 21 Jun 2025 17:17:02 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/ring-liteai-20250621171702985-0/</guid>
      <description>蚂蚁技术团队近日开源了轻量级MoE推理模型Ring-lite，该模型以其16.8亿总参数和仅2.75亿激活参数的精巧设计，在多项推理任务中实现了SOTA性能。其核心创新包括独创的C3PO强化学习训练方法和对多领域数据联合训练的优化，并承诺实现模型全链路的透明化开源，预示着高效、普惠与可信赖AI的新方向。</description>
    </item>
    <item>
      <title>Mistral Small 3.2：高效能模型的战略升级与欧洲AI主权的崛起</title>
      <link>http://192.168.50.247:1313/insights/mistral-small-32ai-20250621071004217-0/</link>
      <pubDate>Sat, 21 Jun 2025 07:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/mistral-small-32ai-20250621071004217-0/</guid>
      <description>法国AI初创公司Mistral AI将其开源小型模型Mistral Small从3.1升级至3.2，此次迭代着重于提升性能和效率，而非扩大参数规模，展现了其在“小而精”模型路线上的坚持。凭借240亿参数即可媲美大型模型的强大能力，以及对欧盟AI法规的严格遵循，Mistral不仅在开放模型市场占据优势，更在全球AI主权竞争中扮演着关键角色，为企业提供了高效且合规的AI解决方案。</description>
    </item>
    <item>
      <title>百万上下文与超低成本：MiniMax如何重塑大模型训练的经济学与Agent应用图景</title>
      <link>http://192.168.50.247:1313/insights/minimaxagent-20250620191004664-2/</link>
      <pubDate>Fri, 20 Jun 2025 19:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/minimaxagent-20250620191004664-2/</guid>
      <description>MiniMax近日开源的MiniMax-M1模型以其百万级上下文处理能力和仅53.74万美元的强化学习训练成本，在AI领域引发震动。该模型通过创新的混合注意力架构和高效的强化学习算法（CISPO）实现性能与成本的平衡，并显著提升了AI Agent的工具调用和应用落地潜力。这一突破不仅挑战了现有大模型的高成本范式，也为AI产业的未来发展方向提供了新思路。</description>
    </item>
    <item>
      <title>MiniMax的AI成本革命：53万美元如何塑造下一代智能体未来</title>
      <link>http://192.168.50.247:1313/insights/minimaxai53-20250620092004466-0/</link>
      <pubDate>Fri, 20 Jun 2025 09:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/minimaxai53-20250620092004466-0/</guid>
      <description>MiniMax通过独创的Lightning Attention混合架构和CISPO强化学习算法，将顶级AI模型的强化训练成本大幅降低至53.74万美元，实现了百万级上下文处理能力和卓越的Agent工具调用表现。这一技术突破不仅显著降低了AI研发门槛，更为智能体技术的广泛应用和AI市场的未来增长注入了强大信心。</description>
    </item>
    <item>
      <title>MiniMax M1：解构中国AI“六小虎”的首个开源推理模型，重塑长上下文交互的边界</title>
      <link>http://192.168.50.247:1313/insights/minimax-m1ai-20250617202000424-10/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/minimax-m1ai-20250617202000424-10/</guid>
      <description>MiniMax开源了其首个大规模混合架构推理模型M1，以4560亿参数、MoE架构和独特的“闪电注意力”机制，在长上下文处理和Agent工具使用方面展现出卓越性能，并大幅降低了训练成本。M1的开放标志着中国AI公司在高效、超长上下文推理技术上的重要突破，预示着未来AI在复杂任务协作中的广阔应用前景。</description>
    </item>
  </channel>
</rss>
