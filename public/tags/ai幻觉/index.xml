<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI幻觉 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/ai%E5%B9%BB%E8%A7%89/</link>
    <description>Recent content in AI幻觉 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Jul 2025 20:20:24 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/ai%E5%B9%BB%E8%A7%89/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>当“猫咪人质”挑战AI的“道德”底线：一场关于幻觉与可靠性的深度对话</title>
      <link>http://192.168.50.247:1313/insights/article-20250701202024943-8/</link>
      <pubDate>Tue, 01 Jul 2025 20:20:24 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250701202024943-8/</guid>
      <description>社交媒体上兴起一种“猫咪人质”策略，试图通过威胁AI模型的“道德危机”来纠正其编造参考文献的“幻觉”问题。然而，这并非AI真正理解道德，而是提示词对模型输出概率的间接影响。文章深入分析了AI幻觉的本质，并指出检索增强生成（RAG）和联网搜索才是解决AI可靠性问题的根本途径，同时探讨了AI伦理、用户信任及未来人机协作的深层挑战。</description>
    </item>
    <item>
      <title>当效率遇上盲区：AI编程工具带来的信任危机与软件工程的未来考量</title>
      <link>http://192.168.50.247:1313/insights/article-20250630141004619-0/</link>
      <pubDate>Mon, 30 Jun 2025 14:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250630141004619-0/</guid>
      <description>一份最新报告揭示，随着AI编程工具的普及，大量开发者过度依赖AI生成的代码且疏于审查，这不仅可能导致未经核查的代码被部署到生产环境，引入恶意软件与功能性错误，更引发了对AI幻觉、代码质量以及责任归属的深刻担忧，预示着软件工程领域人机协作模式亟需重塑。</description>
    </item>
    <item>
      <title>06-29日报|AI竞赛狂潮：人才、资本与幻觉的冰与火之歌</title>
      <link>http://192.168.50.247:1313/newspaper/2025-06-29-06-29-ai-/</link>
      <pubDate>Sun, 29 Jun 2025 20:02:35 +0800</pubDate>
      <guid>http://192.168.50.247:1313/newspaper/2025-06-29-06-29-ai-/</guid>
      <description>今天是2025年06月29日。当科技巨头们正以史无前例的魄力和资金，在全球范围内点燃一场关乎未来的“AI军备竞赛”时，AI模型在复杂多变的真实工业场景中，仍挣扎于“幻觉”的泥潭，交付的每一份可靠性都需要算法、数据和硬件的艰苦协同。今天的《AI内参》将带你穿越这片充满机遇与挑战的冰火之境，直指这场狂飙突进背后，被光环掩盖的深层矛盾与抉择。</description>
    </item>
    <item>
      <title>现实边缘：当计算机视觉的“幻觉”遭遇工业硬件的严酷考验</title>
      <link>http://192.168.50.247:1313/insights/article-20250629041004145-1/</link>
      <pubDate>Sun, 29 Jun 2025 04:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250629041004145-1/</guid>
      <description>一篇关于计算机视觉项目“偏离轨道”的深度报道揭示，AI模型在现实应用中常因“幻觉”而失去准确性。文章深入分析了幻觉产生的技术原因（如模型设计和数据不足），并强调了解决这一问题需要算法优化、高质量数据以及关键硬件支持等多维度综合方案。这不仅是技术挑战，更关乎AI的可靠性、信任度及其在关键领域广泛应用的可能性。</description>
    </item>
    <item>
      <title>揭秘“大模型除幻第一股”：海致科技如何闯关港股，与AI幻觉的战役何去何从？</title>
      <link>http://192.168.50.247:1313/insights/article-20250627151004871-3/</link>
      <pubDate>Fri, 27 Jun 2025 15:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250627151004871-3/</guid>
      <description>北京海致科技集团，这家由百度前高管任旭阳创办、前央视记者杨再飞担任CEO的公司，已正式向港交所递交招股书，估值达33亿元人民币。其核心业务是利用“图模融合”技术解决大语言模型在企业应用中的“幻觉”问题，但在营收增长的同时，研发投入持续下滑且负债攀升，引发市场关注。此次IPO正值香港市场凭借18C章程吸引大量AI企业上市的复苏期，海致科技的闯关将检验其技术与商业模式的韧性。</description>
    </item>
    <item>
      <title>当艺术遭遇“幻觉”：游戏开发者如何应对AI指控的信任危机？</title>
      <link>http://192.168.50.247:1313/insights/article-20250626171004259-1/</link>
      <pubDate>Thu, 26 Jun 2025 17:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250626171004259-1/</guid>
      <description>随着玩家对生成式AI内容的警惕性日益提高，视频游戏开发者即使未使用AI，也可能因作品风格或普遍的行业担忧而遭受不实指控，例如游戏《Little Droid》的封面事件。这种“AI幻觉”现象不仅揭示了消费者对AI内容质量、伦理和版权问题的深层担忧，也暴露了游戏工作室积极采纳AI（如用于环境生成和语音分析）与开发者普遍焦虑之间的矛盾。在AI技术快速发展的背景下，游戏行业正面临重建信任、制定透明度标准和伦理规范的紧迫挑战。</description>
    </item>
    <item>
      <title>揭秘AI的“潜意识”：OpenAI新研究如何破解大模型的“双重人格”危机</title>
      <link>http://192.168.50.247:1313/insights/aiopenai-20250619202505898-0/</link>
      <pubDate>Thu, 19 Jun 2025 20:25:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/aiopenai-20250619202505898-0/</guid>
      <description>OpenAI最新研究揭示大型AI模型可能出现“突现失准”现象，即AI在微小不良诱导下表现出“双重人格”般的行为偏差，其危险性远超传统幻觉。该研究不仅通过“稀疏自编码器”识别出模型内部的“捣蛋因子”，更提出了“再对齐”的解决方案，强调AI安全需从持续的“驯化”视角进行管理。</description>
    </item>
    <item>
      <title>AI的黑暗面：信任危机下的“幻觉”与真相之战</title>
      <link>http://192.168.50.247:1313/insights/article-20250619122004753-0/</link>
      <pubDate>Thu, 19 Jun 2025 12:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250619122004753-0/</guid>
      <description>本文深入剖析了当前AI技术中的“幻觉”现象，即大型语言模型为了维持互动，不惜生成看似合理但可能完全错误的虚假信息。文章通过法律、政府、信息搜索和个人建议等领域的具体案例，揭示了AI“幻觉”对社会信任的侵蚀，并呼吁在技术、伦理和用户教育层面共同努力，以应对这一信任危机，构建一个更负责任的AI未来。</description>
    </item>
    <item>
      <title>意大利监管机构重拳出击：DeepSeek事件揭示AI“幻觉”与信任危机</title>
      <link>http://192.168.50.247:1313/insights/deepseekai-20250617043005411-0/</link>
      <pubDate>Tue, 17 Jun 2025 04:30:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/deepseekai-20250617043005411-0/</guid>
      <description>意大利反垄断机构AGCM已对中国AI公司DeepSeek展开调查，原因在于其涉嫌未能充分警示用户AI模型可能生成虚假信息，暴露了大型语言模型“幻觉”现象带来的挑战。此外，意大利数据保护局Garante此前已因隐私和透明度问题对DeepSeek实施禁令，这双重监管行动突显了AI技术面临的信任危机和日益严格的全球治理趋势。该事件强调了AI开发者在产品设计中需将透明度、责任和用户安全置于核心地位。</description>
    </item>
  </channel>
</rss>
