<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>网络安全 on AI内参</title>
    <link>http://localhost:65292/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/</link>
    <description>Recent content in 网络安全 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 17 Jun 2025 23:20:05 +0800</lastBuildDate>
    <atom:link href="http://localhost:65292/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Agent的致命软肋：Django缔造者警示“三重威胁”下的数据安全危机</title>
      <link>http://localhost:65292/articles/ai-agentdjango-20250617232005863-3/</link>
      <pubDate>Tue, 17 Jun 2025 23:20:05 +0800</pubDate>
      <guid>http://localhost:65292/articles/ai-agentdjango-20250617232005863-3/</guid>
      <description>Django Web框架的联合创建者Simon Willison针对AI Agent的安全风险发出了严厉警告。他指出，当AI Agent同时具备访问私人数据、暴露于不可信内容和进行外部通信的能力时，将构成一个“致命三重威胁”，极易导致数据被窃取。Willison强调，LLM固有的指令遵循特性使其容易受到“提示注入”攻击，而目前的技术防护措施尚不能提供100%的可靠保障，这要求用户和开发者对AI Agent的使用和设计保持高度警惕。</description>
    </item>
    <item>
      <title>当AI学会“喵喵叫”：提示词攻击揭示数字人直播深层安全困境</title>
      <link>http://localhost:65292/articles/article-20250617232005846-1/</link>
      <pubDate>Tue, 17 Jun 2025 23:20:05 +0800</pubDate>
      <guid>http://localhost:65292/articles/article-20250617232005846-1/</guid>
      <description>数字人直播中发生的“喵喵叫”事件，揭示了大型语言模型普遍存在的“提示词攻击”漏洞，即恶意指令可穿透AI安全护栏。这不仅暴露出AI系统在智能与可控之间难以平衡的困境，更对新兴的AI商业应用带来了潜在的经济与信任风险，凸显了构建有效AI安全策略的紧迫性。</description>
    </item>
  </channel>
</rss>
