<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>小模型 on AI内参</title>
    <link>http://localhost:51049/tags/%E5%B0%8F%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 小模型 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 20 Jun 2025 16:10:04 +0800</lastBuildDate>
    <atom:link href="http://localhost:51049/tags/%E5%B0%8F%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大模型幻觉之殇与协同之光：智能投顾如何精准破局</title>
      <link>http://localhost:51049/articles/article-20250620161004296-1/</link>
      <pubDate>Fri, 20 Jun 2025 16:10:04 +0800</pubDate>
      <guid>http://localhost:51049/articles/article-20250620161004296-1/</guid>
      <description>随着大型语言模型（LLMs）在金融领域的应用日益深入，其固有的“幻觉”问题和在高合规性要求下的局限性变得尤为突出。北银金科在AICon北京大会上提出的“大小模型协同”架构，通过结合通用大模型的理解能力与传统小模型的精准计算，提供了一种有效解决幻觉风险、提升专业服务深度的新方案，为智能投顾乃至更广泛的高风险行业AI应用指明了方向。</description>
    </item>
    <item>
      <title>集体智能的崛起：GRA框架如何赋能小模型“逆袭”大模型，重塑AI开发图景</title>
      <link>http://localhost:51049/articles/graai-20250617202000362-3/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://localhost:51049/articles/graai-20250617202000362-3/</guid>
      <description>上海人工智能实验室与中国人民大学推出的GRA框架，通过模拟学术审稿流程，使多个小型语言模型（7B级别）协同生成高质量训练数据，性能可媲美甚至超越72B大模型蒸馏的效果。这项开源技术为AI模型的开发提供了一种更经济高效、更具普惠性的新范式，有望打破当前对大规模参数模型的过度依赖，促进AI领域的民主化和可持续发展。</description>
    </item>
    <item>
      <title>游戏之智：小模型如何通过像素世界解锁通用推理能力</title>
      <link>http://localhost:51049/articles/article-20250617193006116-1/</link>
      <pubDate>Tue, 17 Jun 2025 19:30:06 +0800</pubDate>
      <guid>http://localhost:51049/articles/article-20250617193006116-1/</guid>
      <description>一项最新研究揭示，通过让仅70亿参数的多模态模型玩简单的街机游戏，如《贪吃蛇》，可以培养出强大的跨领域推理能力，使其在数学和几何任务上超越GPT-4o等顶级模型。这项名为“视觉游戏学习”（ViGaL）的范式，通过游戏训练促进了通用认知能力（如空间理解和规划）的涌现，并挑战了传统AI训练对大规模特定领域数据的依赖，为未来AI发展开辟了高效且可扩展的新路径。</description>
    </item>
  </channel>
</rss>
