<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM局限 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/llm%E5%B1%80%E9%99%90/</link>
    <description>Recent content in LLM局限 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 04 Jul 2025 15:10:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/llm%E5%B1%80%E9%99%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越符号：杨立昆新研究揭示LLM认知鸿沟，预示AGI之路范式巨变</title>
      <link>http://192.168.50.247:1313/insights/llmagi-20250704151004340-3/</link>
      <pubDate>Fri, 04 Jul 2025 15:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/llmagi-20250704151004340-3/</guid>
      <description>杨立昆的最新研究量化揭示了LLM与人类认知策略的根本差异：LLM擅长统计压缩，而人类侧重适应性理解，预示着单纯扩大模型规模无法实现通用人工智能。文章深入探讨了强化学习、大型概念模型和世界模型等多元化新路径，指出AI发展将从单一的预训练范式转向多模态、物理世界锚定与架构创新相结合，以期弥合认知鸿沟，迈向更具理解力的通用智能。</description>
    </item>
  </channel>
</rss>
