<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>边缘计算 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/</link>
    <description>Recent content in 边缘计算 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jun 2025 22:10:06 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</link>
      <pubDate>Fri, 27 Jun 2025 22:10:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：2G显存解锁端侧AI新纪元</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</link>
      <pubDate>Fri, 27 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</guid>
      <description>谷歌最新发布的Gemma 3n模型凭借革命性的MatFormer架构和多项优化技术，成功将高性能多模态AI的显存需求降至2GB，并在大模型竞技场中刷新纪录，成为首个得分超过1300分的10B以下模型。这一突破不仅极大地降低了AI在各类端侧设备上部署的门槛，也预示着AI应用将更加普及、注重隐私且响应迅速，对未来的智能设备和AI生态产生深远影响。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</title>
      <link>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</link>
      <pubDate>Fri, 27 Jun 2025 19:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其仅需2GB内存即可运行的超高效能，重新定义了边缘AI的可能性。这款模型集成了MatFormer弹性架构、逐层嵌入机制和KV Cache共享等前沿技术，实现了在低参数量下对多模态输入的出色处理能力，并在LMArena基准测试中创下1300分的记录。Gemma 3n的发布，预示着高性能AI将更广泛地赋能智能手机、物联网设备等边缘端，加速AI的普及与民主化，深刻影响未来的计算范式。</description>
    </item>
    <item>
      <title>边缘智能的突破：小米小爱同学如何在资源受限下实现高性能大模型推理</title>
      <link>http://192.168.50.247:1313/insights/article-20250624231007315-0/</link>
      <pubDate>Tue, 24 Jun 2025 23:10:07 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624231007315-0/</guid>
      <description>小米小爱同学团队在端侧大模型部署方面取得了显著进展，通过自研推理框架、动态优化、投机推理、量化以及创新的“共享基座+LoRA”架构，成功克服了移动设备资源限制，实现了高性能、多任务并发。文章深入剖析了小米的技术策略，并展望了未来硬件与模型架构（如Linear Attention）在推动端侧AI普惠化中的关键作用。</description>
    </item>
    <item>
      <title>微软Mu：操作系统中的微型AI革命，重塑本地智能交互边界</title>
      <link>http://192.168.50.247:1313/insights/muai-20250624151004533-3/</link>
      <pubDate>Tue, 24 Jun 2025 15:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/muai-20250624151004533-3/</guid>
      <description>微软正式发布了仅3.3亿参数的设备端小型语言模型Mu，专为Windows 11的设置应用打造智能AI代理。Mu在NPU上本地运行，提供低延迟、高隐私的自然语言交互，显著简化了系统操作。这一创新不仅代表了AI从云端向边缘计算的战略性转移，也为未来操作系统中更广泛、更私密的本地AI应用奠定了基础。</description>
    </item>
    <item>
      <title>黑芝麻智能的战略棋局：低功耗芯片如何加速具身智能浪潮</title>
      <link>http://192.168.50.247:1313/insights/article-20250620111004334-2/</link>
      <pubDate>Fri, 20 Jun 2025 11:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250620111004334-2/</guid>
      <description>黑芝麻智能拟收购一家本土低功耗AI芯片企业，旨在完善其车规级计算芯片产品线，从高性能芯片延伸至满足边缘计算的低功耗需求。此举不仅有助于其在智能汽车市场提供更全面的解决方案，更关键的是，它标志着黑芝麻智能正加速布局具身智能领域，将机器人视为公司未来新的增长引擎，实现从车端到具身AI的战略性进化。</description>
    </item>
  </channel>
</rss>
