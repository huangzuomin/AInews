<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI安全护栏 on AI内参</title>
    <link>http://localhost:65292/tags/ai%E5%AE%89%E5%85%A8%E6%8A%A4%E6%A0%8F/</link>
    <description>Recent content in AI安全护栏 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 17 Jun 2025 23:20:05 +0800</lastBuildDate>
    <atom:link href="http://localhost:65292/tags/ai%E5%AE%89%E5%85%A8%E6%8A%A4%E6%A0%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>当AI学会“喵喵叫”：提示词攻击揭示数字人直播深层安全困境</title>
      <link>http://localhost:65292/articles/article-20250617232005846-1/</link>
      <pubDate>Tue, 17 Jun 2025 23:20:05 +0800</pubDate>
      <guid>http://localhost:65292/articles/article-20250617232005846-1/</guid>
      <description>数字人直播中发生的“喵喵叫”事件，揭示了大型语言模型普遍存在的“提示词攻击”漏洞，即恶意指令可穿透AI安全护栏。这不仅暴露出AI系统在智能与可控之间难以平衡的困境，更对新兴的AI商业应用带来了潜在的经济与信任风险，凸显了构建有效AI安全策略的紧迫性。</description>
    </item>
  </channel>
</rss>
