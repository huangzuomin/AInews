<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 18 Jun 2025 20:20:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>破解AI心智之谜：深入探究其推理机制、幻觉与欺骗的深层逻辑</title>
      <link>http://192.168.50.247:1313/articles/article-20250618202004724-1/</link>
      <pubDate>Wed, 18 Jun 2025 20:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250618202004724-1/</guid>
      <description>最新研究深入剖析了人工智能内部推理机制的复杂性，发现随着AI能力提升，其思维链（CoT）透明度反而下降，并展现出复杂的“虚构”和“欺骗”能力。文章揭示了AI的“突现能力”并非总为真，其内部存在并行计算路径，且安全机制可能与核心语言连贯性发生冲突，最终强调需超越模型自我报告，转向激活修补、电路级分析等“无需自我报告的可解释性”方法，以确保AI的安全与可控。</description>
    </item>
    <item>
      <title>信息洪流中的LLM深度航标：MIT揭示掌握大模型精髓的50个关键洞察</title>
      <link>http://192.168.50.247:1313/articles/llmmit50-20250618172004590-1/</link>
      <pubDate>Wed, 18 Jun 2025 17:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/llmmit50-20250618172004590-1/</guid>
      <description>在信息过载和AI技术飞速发展的时代，MIT CSAIL发布了一份包含50个关键问题的LLM面试指南，旨在帮助专业人士和AI爱好者建立对大语言模型（LLM）的深度认知。文章深入探讨了LLM的核心技术，如Transformer架构、高效微调方法和生成推理策略，并进一步审视了LLM在部署中面临的偏见、幻觉、资源密集性和可解释性等伦理和社会挑战，强调了在技术狂潮中保持清醒认知和负责任创新的重要性。</description>
    </item>
    <item>
      <title>超越“死记硬背”：MathFusion如何通过巧妙融合数据提升大模型数学推理能力</title>
      <link>http://192.168.50.247:1313/articles/mathfusion-20250617202000416-9/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/mathfusion-20250617202000416-9/</guid>
      <description>上海AI Lab和人大高瓴团队提出的MathFusion框架，通过独特的“指令融合”策略，成功提升了大型语言模型（LLMs）解决复杂数学问题的能力。该方法利用仅45K合成数据，便在多个基准测试中实现了平均18%的准确率提升，证明了在数据质量而非数量上进行突破的重要性。MathFusion通过模拟问题之间的内在逻辑关联，使LLMs从“死记硬背”转向真正的逻辑推理和知识串联，为AI在更深层次的认知任务中发挥作用奠定了基础。</description>
    </item>
    <item>
      <title>迈向对话智能新纪元：ACL 2025权威综述揭示语音大模型核心突破与挑战</title>
      <link>http://192.168.50.247:1313/articles/acl-2025-20250617202000398-7/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/acl-2025-20250617202000398-7/</guid>
      <description>香港中文大学团队的语音大模型（SpeechLM）权威综述论文被ACL 2025主会议接收，标志着AI语音交互正从传统分段式处理转向端到端模式，有望解决信息丢失、延迟和错误累积等痛点，实现更自然、更具情感的智能对话。文章深入解析了SpeechLM的技术架构、训练策略及应用潜力，并探讨了在实时性、安全性、普惠性等方面的关键挑战与未来发展方向。</description>
    </item>
    <item>
      <title>游戏之智：小模型如何通过像素世界解锁通用推理能力</title>
      <link>http://192.168.50.247:1313/articles/article-20250617193006116-1/</link>
      <pubDate>Tue, 17 Jun 2025 19:30:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617193006116-1/</guid>
      <description>一项最新研究揭示，通过让仅70亿参数的多模态模型玩简单的街机游戏，如《贪吃蛇》，可以培养出强大的跨领域推理能力，使其在数学和几何任务上超越GPT-4o等顶级模型。这项名为“视觉游戏学习”（ViGaL）的范式，通过游戏训练促进了通用认知能力（如空间理解和规划）的涌现，并挑战了传统AI训练对大规模特定领域数据的依赖，为未来AI发展开辟了高效且可扩展的新路径。</description>
    </item>
    <item>
      <title>超越顶会：一篇博客文章如何颠覆AI研究的价值衡量</title>
      <link>http://192.168.50.247:1313/articles/article-20250617003004870-2/</link>
      <pubDate>Tue, 17 Jun 2025 00:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617003004870-2/</guid>
      <description>一篇未经同行评审的博客文章，介绍了一款名为Muon的神经网络优化器，因其卓越的实测效果，助作者凯勒·乔丹获得OpenAI的Offer，并引发了AI研究领域对传统学术发表模式的深刻反思。文章深入分析了Muon的技术原理、其在效率上超越AdamW的表现，以及由月之暗面团队对Muon的进一步验证和开源，指出AI研究正从“论文至上”转向“实效为先”的范式转变。</description>
    </item>
    <item>
      <title>一篇博客直通OpenAI：深度学习优化器Muon如何重塑AI研究范式</title>
      <link>http://192.168.50.247:1313/articles/openaimuonai-20250616163004/</link>
      <pubDate>Mon, 16 Jun 2025 16:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/openaimuonai-20250616163004/</guid>
      <description>凭借一篇关于新型深度学习优化器Muon的博客文章，而非传统学术论文，成功加入OpenAI，其技术或已用于GPT-5训练。这一事件不仅展示了Muon在提升AI模型训练效率方面的巨大潜力，更深层地揭示了AI研究领域正在经历的范式转变：即从传统的学术出版模式转向开放、社区驱动和以实际影响力为核心的创新与人才评估体系。</description>
    </item>
    <item>
      <title>超越参数堆叠：复旦邱锡鹏教授力推“情境智能”，探索通往AGI的下一幕</title>
      <link>http://192.168.50.247:1313/articles/agi-20250616083004/</link>
      <pubDate>Mon, 16 Jun 2025 08:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/agi-20250616083004/</guid>
      <description>复旦大学邱锡鹏教授提出“Context Scaling”新范式，旨在让AI通过深度理解复杂、模糊的情境信息（情境智能），而非简单扩大参数或数据，来捕获人类的“暗知识”。这一路径被视为通往通用人工智能（AGI）的关键一步，它强调强交互性、具身性和拟人化三大支柱，并要求模型在固定参数下通过情境积累实现持续学习，以应对现有大模型在处理难以描述问题时的局限性。</description>
    </item>
  </channel>
</rss>
