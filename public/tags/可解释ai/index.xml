<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>可解释AI on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E5%8F%AF%E8%A7%A3%E9%87%8Aai/</link>
    <description>Recent content in 可解释AI on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 20 Jun 2025 20:10:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E5%8F%AF%E8%A7%A3%E9%87%8Aai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>揭秘Gemini透明度迷雾：谷歌的“黑箱”决策如何挑战开发者信任与AI伦理</title>
      <link>http://192.168.50.247:1313/articles/geminiai-20250620201004432-2/</link>
      <pubDate>Fri, 20 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/geminiai-20250620201004432-2/</guid>
      <description>谷歌近期削减Gemini模型推理过程透明度的决定，引发了开发者社区的强烈不满，许多企业用户因无法有效调试而感到“盲目”。这一举动不仅损害了开发者对谷歌AI平台的信任，也凸显了前沿AI模型在性能与可解释性之间的内在矛盾，并对AI伦理、问责制以及谷歌在激烈AI竞赛中的市场地位构成了深远挑战。</description>
    </item>
    <item>
      <title>大语言模型的数学悖论：奥数级证明揭示的深层推理鸿沟</title>
      <link>http://192.168.50.247:1313/articles/article-20250619162004499-1/</link>
      <pubDate>Thu, 19 Jun 2025 16:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250619162004499-1/</guid>
      <description>一项由斯坦福大学、UC伯克利和MIT合作的开创性研究揭示，顶尖大语言模型在解决奥数级不等式证明问题时，尽管常能得出正确答案，但其内部逻辑推理过程却充满漏洞。研究团队通过创建IneqMath数据集和LLM-as-Judge评估系统，量化了这种“可信度错觉”，并指出模型规模的增大或延长思考时间并不能有效提升其逻辑严谨性，但自我反思和引入外部定理线索等策略显示出改善潜能，为AI的可靠性与信任问题带来了深远启示。</description>
    </item>
    <item>
      <title>Anthropic的可解释AI：解构大模型“黑箱”，重塑企业级AI策略的信任基石</title>
      <link>http://192.168.50.247:1313/articles/anthropicaiai-20250618072004246-0/</link>
      <pubDate>Wed, 18 Jun 2025 07:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/anthropicaiai-20250618072004246-0/</guid>
      <description>Anthropic正通过其“AI显微镜”深耕可解释人工智能，旨在揭示大型语言模型内部的决策机制，这不仅是理解AI“黑箱”的关键，更是驱动企业级LLM战略从单纯追求效率向建立信任转型的核心。这项研究不仅能显著提升商业效率，更对AI的安全性、可靠性与伦理治理产生深远影响，为AI的广泛应用奠定透明与可控的基石。</description>
    </item>
  </channel>
</rss>
