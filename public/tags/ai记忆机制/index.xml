<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI记忆机制 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/ai%E8%AE%B0%E5%BF%86%E6%9C%BA%E5%88%B6/</link>
    <description>Recent content in AI记忆机制 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 10 Jul 2025 10:10:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/ai%E8%AE%B0%E5%BF%86%E6%9C%BA%E5%88%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越算力：AI“熟能生巧”开启大模型推理效率与智能涌现新范式</title>
      <link>http://192.168.50.247:1313/insights/article-20250710101004597-0/</link>
      <pubDate>Thu, 10 Jul 2025 10:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250710101004597-0/</guid>
      <description>Emory大学的SpeedupLLM框架通过动态资源分配和记忆机制，让大模型实现“熟能生巧”，大幅降低高达56%的推理成本并提升准确率，开启了AI效能优化超越纯算力堆叠的新范式。这一突破将显著提升LLM的商业化效率，加速企业级AI应用普及，并引发关于AI智能本质与可持续发展的深层思考，预示着AI将从“算法机器”迈向“经验学习者”。</description>
    </item>
  </channel>
</rss>
