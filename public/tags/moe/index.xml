<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MoE on AI内参</title>
    <link>http://localhost:51049/tags/moe/</link>
    <description>Recent content in MoE on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 20 Jun 2025 13:10:04 +0800</lastBuildDate>
    <atom:link href="http://localhost:51049/tags/moe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MiniMax的夏季攻势：技术竞速、商业化突围与资本化迷途</title>
      <link>http://localhost:51049/articles/minimax-20250620131004465-0/</link>
      <pubDate>Fri, 20 Jun 2025 13:10:04 +0800</pubDate>
      <guid>http://localhost:51049/articles/minimax-20250620131004465-0/</guid>
      <description>MiniMax正在通过一系列技术发布（如高性能M1模型和通用Agent产品）和产品线多元化（视频生成Hailuo 02），积极应对激烈的AI竞争，并尝试通过新产品订阅和拓展海外市场来解决营收单一的问题。同时，伴随其赴港IPO的传闻，该公司正面临将技术实力转化为商业可持续性，并在严峻的资本市场中获得认可的双重挑战，这预示着其步入一个关键的战略转折期。</description>
    </item>
    <item>
      <title>MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界</title>
      <link>http://localhost:51049/articles/minimax-m1ai-20250618082004316-0/</link>
      <pubDate>Wed, 18 Jun 2025 08:20:04 +0800</pubDate>
      <guid>http://localhost:51049/articles/minimax-m1ai-20250618082004316-0/</guid>
      <description>MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。</description>
    </item>
  </channel>
</rss>
