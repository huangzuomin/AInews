<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>强化学习 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 强化学习 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 21 Jun 2025 17:17:02 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>稀疏激活的力量：蚂蚁Ring-lite如何重塑轻量级AI推理的格局</title>
      <link>http://192.168.50.247:1313/articles/ring-liteai-20250621171702985-0/</link>
      <pubDate>Sat, 21 Jun 2025 17:17:02 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/ring-liteai-20250621171702985-0/</guid>
      <description>蚂蚁技术团队近日开源了轻量级MoE推理模型Ring-lite，该模型以其16.8亿总参数和仅2.75亿激活参数的精巧设计，在多项推理任务中实现了SOTA性能。其核心创新包括独创的C3PO强化学习训练方法和对多领域数据联合训练的优化，并承诺实现模型全链路的透明化开源，预示着高效、普惠与可信赖AI的新方向。</description>
    </item>
    <item>
      <title>超级智能的路径之争：Meta研究员对OpenAI愿景的颠覆性质疑</title>
      <link>http://192.168.50.247:1313/articles/metaopenai-20250620201004418-0/</link>
      <pubDate>Fri, 20 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/metaopenai-20250620201004418-0/</guid>
      <description>OpenAI首席执行官Sam Altman认为构建超级智能是工程问题，但Meta AI研究员Jack Morris对此提出颠覆性质疑。Morris认为，当前依赖大语言模型（LLM）和强化学习（RL）的路径，受限于高质量训练数据的稀缺性及RL在可验证任务上的迁移能力不足，无法实现真正的通用超级智能。这场关于AI未来路径的辩论，揭示了行业在追求终极智能时面临的核心技术瓶颈和方法论分歧。</description>
    </item>
    <item>
      <title>百万上下文与超低成本：MiniMax如何重塑大模型训练的经济学与Agent应用图景</title>
      <link>http://192.168.50.247:1313/articles/minimaxagent-20250620191004664-2/</link>
      <pubDate>Fri, 20 Jun 2025 19:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/minimaxagent-20250620191004664-2/</guid>
      <description>MiniMax近日开源的MiniMax-M1模型以其百万级上下文处理能力和仅53.74万美元的强化学习训练成本，在AI领域引发震动。该模型通过创新的混合注意力架构和高效的强化学习算法（CISPO）实现性能与成本的平衡，并显著提升了AI Agent的工具调用和应用落地潜力。这一突破不仅挑战了现有大模型的高成本范式，也为AI产业的未来发展方向提供了新思路。</description>
    </item>
    <item>
      <title>开源AI编程模型的里程碑：DeepCoder如何挑战大厂，重塑代码生成格局</title>
      <link>http://192.168.50.247:1313/articles/aideepcoder-20250620131004480-1/</link>
      <pubDate>Fri, 20 Jun 2025 13:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/aideepcoder-20250620131004480-1/</guid>
      <description>Agentica和Together AI联合开源的DeepCoder-14B-Preview模型，在编码基准测试中超越了OpenAI的o1模型并与o3-mini性能相当。这款140亿参数的模型通过创新的强化学习训练方法克服了数据和计算瓶颈，并致力于通过完全共享训练细节来民主化LLM的RL训练。这一进展标志着开源AI编程领域的重要里程碑，预示着AI模型开发将迈向更开放、更高效的新阶段。</description>
    </item>
    <item>
      <title>MiniMax的AI成本革命：53万美元如何塑造下一代智能体未来</title>
      <link>http://192.168.50.247:1313/articles/minimaxai53-20250620092004466-0/</link>
      <pubDate>Fri, 20 Jun 2025 09:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/minimaxai53-20250620092004466-0/</guid>
      <description>MiniMax通过独创的Lightning Attention混合架构和CISPO强化学习算法，将顶级AI模型的强化训练成本大幅降低至53.74万美元，实现了百万级上下文处理能力和卓越的Agent工具调用表现。这一技术突破不仅显著降低了AI研发门槛，更为智能体技术的广泛应用和AI市场的未来增长注入了强大信心。</description>
    </item>
    <item>
      <title>MiniMax M1的非共识之路：中国大模型公司如何重塑AI推理的边界</title>
      <link>http://192.168.50.247:1313/articles/minimax-m1ai-20250618082004316-0/</link>
      <pubDate>Wed, 18 Jun 2025 08:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/minimax-m1ai-20250618082004316-0/</guid>
      <description>MiniMax近日发布了其自研的MiniMax-M1推理模型，这款模型创新性地融合了MoE架构和混合注意力机制，并引入了新型强化学习算法CISPO，显著提升了长上下文理解和智能体工具使用能力，同时大幅降低了训练成本。M1的推出不仅展现了MiniMax在基础模型技术上的深厚实力，也再次强调了其作为一家“模型驱动”AI公司的核心战略定位。</description>
    </item>
    <item>
      <title>MiniMax M1：解构中国AI“六小虎”的首个开源推理模型，重塑长上下文交互的边界</title>
      <link>http://192.168.50.247:1313/articles/minimax-m1ai-20250617202000424-10/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/minimax-m1ai-20250617202000424-10/</guid>
      <description>MiniMax开源了其首个大规模混合架构推理模型M1，以4560亿参数、MoE架构和独特的“闪电注意力”机制，在长上下文处理和Agent工具使用方面展现出卓越性能，并大幅降低了训练成本。M1的开放标志着中国AI公司在高效、超长上下文推理技术上的重要突破，预示着未来AI在复杂任务协作中的广阔应用前景。</description>
    </item>
    <item>
      <title>游戏之智：小模型如何通过像素世界解锁通用推理能力</title>
      <link>http://192.168.50.247:1313/articles/article-20250617193006116-1/</link>
      <pubDate>Tue, 17 Jun 2025 19:30:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/article-20250617193006116-1/</guid>
      <description>一项最新研究揭示，通过让仅70亿参数的多模态模型玩简单的街机游戏，如《贪吃蛇》，可以培养出强大的跨领域推理能力，使其在数学和几何任务上超越GPT-4o等顶级模型。这项名为“视觉游戏学习”（ViGaL）的范式，通过游戏训练促进了通用认知能力（如空间理解和规划）的涌现，并挑战了传统AI训练对大规模特定领域数据的依赖，为未来AI发展开辟了高效且可扩展的新路径。</description>
    </item>
    <item>
      <title>AI的未来之路：Richard Sutton预言“经验时代”的到来</title>
      <link>http://192.168.50.247:1313/articles/airichard-sutton-20250617003004877-3/</link>
      <pubDate>Tue, 17 Jun 2025 00:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/articles/airichard-sutton-20250617003004877-3/</guid>
      <description>图灵奖得主Richard S. Sutton在北京智源大会上提出，人工智能正从依赖人类数据的时代走向“经验时代”。他认为现有大模型已受困于高质量人类数据枯竭的瓶颈，未来智能体必须通过与环境的实时交互来获取第一手经验。Sutton还强调了去中心化合作在AI治理中的重要性，反对基于恐惧的中心化控制，呼吁建立多元目标共存的韧性生态系统。</description>
    </item>
  </channel>
</rss>
