<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI治理 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/ai%E6%B2%BB%E7%90%86/</link>
    <description>Recent content in AI治理 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jun 2025 05:10:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/ai%E6%B2%BB%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>企业级智能体AI：穿越部署迷雾，解锁增长潜能的关键战略</title>
      <link>http://192.168.50.247:1313/insights/article-20250627051004410-0/</link>
      <pubDate>Fri, 27 Jun 2025 05:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250627051004410-0/</guid>
      <description>企业在部署智能体AI时面临普遍的用户信任挑战和“广泛部署但缺乏实际P&amp;amp;L影响”的悖论。行业领袖强调，成功的关键在于建立强大的自治理框架以提升客户信任和竞争优势，同时通过健壮的方法论加速创新并优化运营效率。最终，智能体AI的价值实现不仅依赖于技术突破，更在于其伦理治理、信任构建以及与人类工作的深度融合。</description>
    </item>
    <item>
      <title>安德鲁·吴的“沙盒优先”蓝图：平衡企业AI创新的速度与安全</title>
      <link>http://192.168.50.247:1313/insights/article-20250625051004336-0/</link>
      <pubDate>Wed, 25 Jun 2025 05:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250625051004336-0/</guid>
      <description>安德鲁·吴提出“沙盒优先”策略，旨在通过受控环境下的安全实验加速企业AI创新，强调在不牺牲速度的前提下，确保AI的可观察性和安全护栏。文章深入探讨了该方法如何平衡敏捷性与风险管理，及其在企业AI转型中的核心作用，并延伸至AI伦理与治理的深层考量，指出其对于负责任AI落地的关键意义。</description>
    </item>
    <item>
      <title>预警：AGI浪潮将至，全球经济体系何去何从？</title>
      <link>http://192.168.50.247:1313/insights/agi-20250624101004347-3/</link>
      <pubDate>Tue, 24 Jun 2025 10:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/agi-20250624101004347-3/</guid>
      <description>弗吉尼亚大学经济学教授安东·科里内克预警，通用人工智能（AGI）可能在2-5年内实现，届时若现有经济体系未能彻底变革，全球经济恐将面临崩溃。他呼吁各国政府和企业重新思考收入分配（如全民基本收入）、教育模式和AI治理，以应对由AI引发的劳动力市场冲击和社会不稳定风险，强调现在是采取激进应对措施的关键时刻。</description>
    </item>
    <item>
      <title>微软与OpenAI股权博弈：AI未来格局的深层拉锯</title>
      <link>http://192.168.50.247:1313/insights/openaiai-20250623131004207-0/</link>
      <pubDate>Mon, 23 Jun 2025 13:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/openaiai-20250623131004207-0/</guid>
      <description>微软与OpenAI的股权谈判陷入僵局，主要围绕微软在OpenAI重组后盈利部门的持股比例，可能导致双方130亿美元的合作破裂。这场博弈不仅关乎两家科技巨头的财务利益，更将重塑全球AI产业的权力格局与发展方向，尤其是在OpenAI作为“公共利益公司”的使命与商业化需求之间寻找平衡。</description>
    </item>
    <item>
      <title>高考志愿，大厂AI的隐形战役：流量、数据与未来治理的权衡</title>
      <link>http://192.168.50.247:1313/insights/article-20250619102004644-4/</link>
      <pubDate>Thu, 19 Jun 2025 10:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250619102004644-4/</guid>
      <description>在高考志愿填报季，互联网大厂纷纷推出免费AI工具，试图通过抢占流量、积累教育数据和验证大模型能力来实现隐形收益。尽管这些AI工具提供了便利，但在算法透明度、数据准确性和个性化服务方面仍面临挑战，难以完全取代人工专家。文章同时指出，这一现象不仅是技术应用，更折射出AI治理的深层伦理考量，即如何在技术发展与社会责任间取得平衡。</description>
    </item>
    <item>
      <title>揭开黑箱：大模型可解释性竞赛，一场关乎AI未来的智力马拉松</title>
      <link>http://192.168.50.247:1313/insights/article-20250617202000340-1/</link>
      <pubDate>Tue, 17 Jun 2025 20:20:00 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250617202000340-1/</guid>
      <description>随着大型语言模型能力日益增强，其“黑箱”本质构成了AI发展的重要瓶颈。为确保AI安全、负责任地落地，对模型可解释性的深入探索已刻不容缓。当前研究正积极利用自动化解释、特征可视化、思维链监控和机制可解释性等前沿技术，试图揭示模型内部复杂的决策逻辑，但仍面临技术瓶颈和认知局限。这场理解与创造并行的竞赛，将决定人工智能的未来走向，并呼吁行业加大投入与审慎监管。</description>
    </item>
    <item>
      <title>AI的未来之路：Richard Sutton预言“经验时代”的到来</title>
      <link>http://192.168.50.247:1313/insights/airichard-sutton-20250617003004877-3/</link>
      <pubDate>Tue, 17 Jun 2025 00:30:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/airichard-sutton-20250617003004877-3/</guid>
      <description>图灵奖得主Richard S. Sutton在北京智源大会上提出，人工智能正从依赖人类数据的时代走向“经验时代”。他认为现有大模型已受困于高质量人类数据枯竭的瓶颈，未来智能体必须通过与环境的实时交互来获取第一手经验。Sutton还强调了去中心化合作在AI治理中的重要性，反对基于恐惧的中心化控制，呼吁建立多元目标共存的韧性生态系统。</description>
    </item>
  </channel>
</rss>
