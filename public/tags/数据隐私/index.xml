<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据隐私 on AI内参</title>
    <link>http://localhost:65292/tags/%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81/</link>
    <description>Recent content in 数据隐私 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 17 Jun 2025 23:20:05 +0800</lastBuildDate>
    <atom:link href="http://localhost:65292/tags/%E6%95%B0%E6%8D%AE%E9%9A%90%E7%A7%81/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Agent的致命软肋：Django缔造者警示“三重威胁”下的数据安全危机</title>
      <link>http://localhost:65292/articles/ai-agentdjango-20250617232005863-3/</link>
      <pubDate>Tue, 17 Jun 2025 23:20:05 +0800</pubDate>
      <guid>http://localhost:65292/articles/ai-agentdjango-20250617232005863-3/</guid>
      <description>Django Web框架的联合创建者Simon Willison针对AI Agent的安全风险发出了严厉警告。他指出，当AI Agent同时具备访问私人数据、暴露于不可信内容和进行外部通信的能力时，将构成一个“致命三重威胁”，极易导致数据被窃取。Willison强调，LLM固有的指令遵循特性使其容易受到“提示注入”攻击，而目前的技术防护措施尚不能提供100%的可靠保障，这要求用户和开发者对AI Agent的使用和设计保持高度警惕。</description>
    </item>
    <item>
      <title>AI浪潮深处：从高考志愿到浏览器核心，一场流量与认知的高维之战</title>
      <link>http://localhost:65292/articles/article-20250617193006138-4/</link>
      <pubDate>Tue, 17 Jun 2025 19:30:06 +0800</pubDate>
      <guid>http://localhost:65292/articles/article-20250617193006138-4/</guid>
      <description>中国科技巨头腾讯和阿里巴巴正将AI能力深度整合进其浏览器产品，以高考志愿填报为切入点，抢夺AI时代的下一代核心流量入口。这场竞争不仅改变了用户获取信息的方式和传统广告商业模式，也促使行业思考大模型性能瓶颈下的应用创新方向，同时凸显了AI安全与伦理治理的迫切性。</description>
    </item>
    <item>
      <title>AI浪潮深处：从高考志愿到浏览器核心，一场流量与认知的高维之战</title>
      <link>http://localhost:65292/articles/article-20250617190043145-13/</link>
      <pubDate>Tue, 17 Jun 2025 19:00:43 +0800</pubDate>
      <guid>http://localhost:65292/articles/article-20250617190043145-13/</guid>
      <description>中国科技巨头腾讯和阿里巴巴正将AI能力深度整合进其浏览器产品，以高考志愿填报为切入点，抢夺AI时代的下一代核心流量入口。这场竞争不仅改变了用户获取信息的方式和传统广告商业模式，也促使行业思考大模型性能瓶颈下的应用创新方向，同时凸显了AI安全与伦理治理的迫切性。</description>
    </item>
    <item>
      <title>意大利监管机构重拳出击：DeepSeek事件揭示AI“幻觉”与信任危机</title>
      <link>http://localhost:65292/articles/deepseekai-20250617043005411-0/</link>
      <pubDate>Tue, 17 Jun 2025 04:30:05 +0800</pubDate>
      <guid>http://localhost:65292/articles/deepseekai-20250617043005411-0/</guid>
      <description>意大利反垄断机构AGCM已对中国AI公司DeepSeek展开调查，原因在于其涉嫌未能充分警示用户AI模型可能生成虚假信息，暴露了大型语言模型“幻觉”现象带来的挑战。此外，意大利数据保护局Garante此前已因隐私和透明度问题对DeepSeek实施禁令，这双重监管行动突显了AI技术面临的信任危机和日益严格的全球治理趋势。该事件强调了AI开发者在产品设计中需将透明度、责任和用户安全置于核心地位。</description>
    </item>
    <item>
      <title>超越表象：大语言模型“遗忘”的深层结构与可逆边界</title>
      <link>http://localhost:65292/articles/article-20250616123004/</link>
      <pubDate>Mon, 16 Jun 2025 12:30:04 +0800</pubDate>
      <guid>http://localhost:65292/articles/article-20250616123004/</guid>
      <description>一项由香港理工大学、卡内基梅隆大学和加州大学圣克鲁兹分校共同完成的开创性研究，首次系统揭示了大语言模型“遗忘”现象背后的深层表示结构变化。研究区分了“可逆性遗忘”与“不可逆性遗忘”的本质差异，强调真正的遗忘是结构性抹除而非行为抑制，并通过一套表示空间诊断工具，为构建更安全、可控的机器遗忘机制奠定了基础。</description>
    </item>
  </channel>
</rss>
