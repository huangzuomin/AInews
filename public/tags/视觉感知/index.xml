<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>视觉感知 on AI内参</title>
    <link>http://localhost:1315/tags/%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/</link>
    <description>Recent content in 视觉感知 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 26 Jun 2025 08:10:04 +0800</lastBuildDate>
    <atom:link href="http://localhost:1315/tags/%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越表面智能：多模态AI“幻觉悖论”揭示的感知与推理深层张力</title>
      <link>http://localhost:1315/insights/article-20250626081004120-1/</link>
      <pubDate>Thu, 26 Jun 2025 08:10:04 +0800</pubDate>
      <guid>http://localhost:1315/insights/article-20250626081004120-1/</guid>
      <description>一项最新研究揭示了多模态推理模型在追求深度推理时，反而更容易产生“幻觉”的悖论。该研究指出，随着推理链条的加长，模型对视觉输入的关注度下降，转而过度依赖语言先验知识，导致生成内容与图像脱节。为解决此问题，研究团队提出了RH-AUC评估指标和RH-Bench数据集，以衡量模型在推理与感知间的平衡，并为未来模型的稳健性训练提供了宝贵启示。</description>
    </item>
    <item>
      <title>弥合“想”与“做”的鸿沟：UC伯克利LeVERB框架赋能人形机器人自主决策</title>
      <link>http://localhost:1315/insights/ucleverb-20250625171004494-0/</link>
      <pubDate>Wed, 25 Jun 2025 17:10:04 +0800</pubDate>
      <guid>http://localhost:1315/insights/ucleverb-20250625171004494-0/</guid>
      <description>UC伯克利与卡内基梅隆大学的团队推出了LeVERB框架，首次成功连接了人形机器人的视觉感知与物理运动，使其能根据语言指令和环境变化，零样本地完成复杂的全身动作。该框架通过分层系统和创新的仿真基准，显著提升了宇树G1机器人的任务成功率，为具身智能的自主决策能力带来了突破性进展，并有望推动未来机器人应用。</description>
    </item>
    <item>
      <title>具身智能浪潮下的港股叩门者：乐动机器人IPO揭示的视觉感知技术与市场竞逐</title>
      <link>http://localhost:1315/insights/ipo-20250616123004/</link>
      <pubDate>Mon, 16 Jun 2025 12:30:04 +0800</pubDate>
      <guid>http://localhost:1315/insights/ipo-20250616123004/</guid>
      <description>由阿里巴巴CEO吴泳铭及华为前高管投资的乐动机器人，近期正谋求在香港上市，估值超40亿港元。这家以视觉感知技术为核心的机器人公司，主要提供传感器和算法模组，并推出了割草机器人作为具身智能应用。其IPO不仅反映了中国在机器人核心技术领域的深耕，也预示着具身智能赛道资本化进程的加速。</description>
    </item>
  </channel>
</rss>
