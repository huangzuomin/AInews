<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>提示工程 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/</link>
    <description>Recent content in 提示工程 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 02 Jul 2025 18:40:04 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越客套：AI时代人机沟通的深层逻辑与效率考量</title>
      <link>http://192.168.50.247:1313/insights/article-20250702184004482-1/</link>
      <pubDate>Wed, 02 Jul 2025 18:40:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250702184004482-1/</guid>
      <description>本文深入探讨了对AI说“谢谢”这一行为的无效性，指出AI缺乏情感理解，仅通过模式识别处理语言。文章分析了人类拟人化AI的心理倾向及其对效率的潜在影响，并强调了在人机交互中，清晰、结构化和信息量丰富的指令远比社交礼貌更重要，这标志着我们与人工智能沟通范式的深刻转变。</description>
    </item>
    <item>
      <title>当“猫咪人质”挑战AI的“道德”底线：一场关于幻觉与可靠性的深度对话</title>
      <link>http://192.168.50.247:1313/insights/article-20250701202024943-8/</link>
      <pubDate>Tue, 01 Jul 2025 20:20:24 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250701202024943-8/</guid>
      <description>社交媒体上兴起一种“猫咪人质”策略，试图通过威胁AI模型的“道德危机”来纠正其编造参考文献的“幻觉”问题。然而，这并非AI真正理解道德，而是提示词对模型输出概率的间接影响。文章深入分析了AI幻觉的本质，并指出检索增强生成（RAG）和联网搜索才是解决AI可靠性问题的根本途径，同时探讨了AI伦理、用户信任及未来人机协作的深层挑战。</description>
    </item>
  </channel>
</rss>
