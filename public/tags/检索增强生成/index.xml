<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>检索增强生成 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/</link>
    <description>Recent content in 检索增强生成 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Jul 2025 20:20:24 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>当“猫咪人质”挑战AI的“道德”底线：一场关于幻觉与可靠性的深度对话</title>
      <link>http://192.168.50.247:1313/insights/article-20250701202024943-8/</link>
      <pubDate>Tue, 01 Jul 2025 20:20:24 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250701202024943-8/</guid>
      <description>社交媒体上兴起一种“猫咪人质”策略，试图通过威胁AI模型的“道德危机”来纠正其编造参考文献的“幻觉”问题。然而，这并非AI真正理解道德，而是提示词对模型输出概率的间接影响。文章深入分析了AI幻觉的本质，并指出检索增强生成（RAG）和联网搜索才是解决AI可靠性问题的根本途径，同时探讨了AI伦理、用户信任及未来人机协作的深层挑战。</description>
    </item>
  </channel>
</rss>
