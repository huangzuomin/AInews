<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>内存优化 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/</link>
    <description>Recent content in 内存优化 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jun 2025 22:10:06 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</link>
      <pubDate>Fri, 27 Jun 2025 22:10:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</title>
      <link>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</link>
      <pubDate>Fri, 27 Jun 2025 19:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其仅需2GB内存即可运行的超高效能，重新定义了边缘AI的可能性。这款模型集成了MatFormer弹性架构、逐层嵌入机制和KV Cache共享等前沿技术，实现了在低参数量下对多模态输入的出色处理能力，并在LMArena基准测试中创下1300分的记录。Gemma 3n的发布，预示着高性能AI将更广泛地赋能智能手机、物联网设备等边缘端，加速AI的普及与民主化，深刻影响未来的计算范式。</description>
    </item>
    <item>
      <title>化繁为简：ZPressor如何破解3D高斯泼溅的“多视图之困”</title>
      <link>http://192.168.50.247:1313/insights/zpressor3d-20250618112004717-2/</link>
      <pubDate>Wed, 18 Jun 2025 11:20:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/zpressor3d-20250618112004717-2/</guid>
      <description>浙江大学研究人员提出ZPressor模块，通过引入信息瓶颈原理，彻底解决了3D高斯泼溅（3DGS）在处理密集多视图输入时的性能瓶颈。ZPressor能够将可输入视图量提升至500个，推理速度提高3倍，并显著降低80%的内存占用，预示着其在AR/VR和更广泛的AI领域中的深远应用潜力。</description>
    </item>
  </channel>
</rss>
