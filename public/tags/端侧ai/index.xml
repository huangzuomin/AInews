<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>端侧AI on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E7%AB%AF%E4%BE%A7ai/</link>
    <description>Recent content in 端侧AI on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 28 Jun 2025 20:20:14 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E7%AB%AF%E4%BE%A7ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>06-28日报|AI狂潮：当智能脱缰，我们如何掌舵未来？</title>
      <link>http://192.168.50.247:1313/newspaper/2025-06-28-06-28-ai-/</link>
      <pubDate>Sat, 28 Jun 2025 20:20:14 +0800</pubDate>
      <guid>http://192.168.50.247:1313/newspaper/2025-06-28-06-28-ai-/</guid>
      <description>今天是2025年06月28日。当AI的狂潮以前所未有的速度席卷而来，我们正站在一个十字路口：智能的边界被一次次打破，从能“照镜子”学习情感的机器人，到能在2GB内存中运行的多模态模型，再到人人可创造的AI应用平台，技术进步的步伐令人目眩。然而，在这波狂飙突进的浪潮中，我们也不得不面对其背后隐匿的深层挑战——失控的自主智能体、真假难辨的内容、以及模糊的人机伦理界限。</description>
    </item>
    <item>
      <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</link>
      <pubDate>Fri, 27 Jun 2025 22:10:06 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：2G显存解锁端侧AI新纪元</title>
      <link>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</link>
      <pubDate>Fri, 27 Jun 2025 20:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3n2gai-20250627201004999-4/</guid>
      <description>谷歌最新发布的Gemma 3n模型凭借革命性的MatFormer架构和多项优化技术，成功将高性能多模态AI的显存需求降至2GB，并在大模型竞技场中刷新纪录，成为首个得分超过1300分的10B以下模型。这一突破不仅极大地降低了AI在各类端侧设备上部署的门槛，也预示着AI应用将更加普及、注重隐私且响应迅速，对未来的智能设备和AI生态产生深远影响。</description>
    </item>
    <item>
      <title>谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</title>
      <link>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</link>
      <pubDate>Fri, 27 Jun 2025 19:10:05 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemma-3nai2gb-20250627191005495-3/</guid>
      <description>谷歌最新发布的Gemma 3n模型，以其仅需2GB内存即可运行的超高效能，重新定义了边缘AI的可能性。这款模型集成了MatFormer弹性架构、逐层嵌入机制和KV Cache共享等前沿技术，实现了在低参数量下对多模态输入的出色处理能力，并在LMArena基准测试中创下1300分的记录。Gemma 3n的发布，预示着高性能AI将更广泛地赋能智能手机、物联网设备等边缘端，加速AI的普及与民主化，深刻影响未来的计算范式。</description>
    </item>
    <item>
      <title>谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景</title>
      <link>http://192.168.50.247:1313/insights/vla-20250627091004314-5/</link>
      <pubDate>Fri, 27 Jun 2025 09:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/vla-20250627091004314-5/</guid>
      <description>谷歌DeepMind发布了其首个可完全在机器人本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的重大转变。该模型实现了低延迟、高效学习和跨形态泛化能力，并通过开放微调功能和SDK，旨在构建一个开放的机器人“安卓”生态系统，从而推动具身智能在隐私敏感和无网络环境中的应用。尽管其落地仍面临硬件碎片化、数据成本高昂以及在复杂真实世界中保持鲁棒性等挑战，但此次发布为机器人走向更广泛的实际应用奠定了关键基础。</description>
    </item>
    <item>
      <title>谷歌的具身智能新策略：Gemini Robotics On-Device与“机器人安卓”生态的黎明</title>
      <link>http://192.168.50.247:1313/insights/gemini-robotics-on-device-20250625121004319-2/</link>
      <pubDate>Wed, 25 Jun 2025 12:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/gemini-robotics-on-device-20250625121004319-2/</guid>
      <description>谷歌最新发布的Gemini Robotics On-Device模型，是一款优化后的端侧视觉语言动作（VLA）模型，它能在本地机器人设备上运行，只需50-100次演示即可学会新任务，极大提升了机器人执行复杂灵巧操作的效率和泛化能力。此举被誉为机器人领域的“安卓”时刻，预示着硬件与AI“大脑”分离的产业新生态正在形成，并将加速具身智能的广泛应用和商业落地。</description>
    </item>
    <item>
      <title>边缘智能的突破：小米小爱同学如何在资源受限下实现高性能大模型推理</title>
      <link>http://192.168.50.247:1313/insights/article-20250624231007315-0/</link>
      <pubDate>Tue, 24 Jun 2025 23:10:07 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624231007315-0/</guid>
      <description>小米小爱同学团队在端侧大模型部署方面取得了显著进展，通过自研推理框架、动态优化、投机推理、量化以及创新的“共享基座+LoRA”架构，成功克服了移动设备资源限制，实现了高性能、多任务并发。文章深入剖析了小米的技术策略，并展望了未来硬件与模型架构（如Linear Attention）在推动端侧AI普惠化中的关键作用。</description>
    </item>
    <item>
      <title>AI手机核心之争：芯片巨头如何在性能、架构与生态中角逐未来</title>
      <link>http://192.168.50.247:1313/insights/article-20250624101004329-0/</link>
      <pubDate>Tue, 24 Jun 2025 10:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250624101004329-0/</guid>
      <description>2025年，手机AI芯片市场迎来白热化竞争，苹果、华为、高通、小米、联发科、三星六大巨头正围绕芯片能效、自研架构及开发生态展开全面较量。文章深入分析了各方在先进工艺、CPU/GPU/NPU自研深度以及AI开发工具链上的核心策略与挑战，指出在AI手机时代，对底层芯片技术的掌控和软硬件深度协同将是决胜的关键。</description>
    </item>
  </channel>
</rss>
