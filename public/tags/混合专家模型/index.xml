<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>混合专家模型 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in 混合专家模型 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Jul 2025 20:20:25 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>中国大模型“下半场”：Kimi与Minimax如何重塑心智，争夺下一个DeepSeek？</title>
      <link>http://192.168.50.247:1313/insights/kimiminimaxdeepseek-20250701202025025-17/</link>
      <pubDate>Tue, 01 Jul 2025 20:20:25 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/kimiminimaxdeepseek-20250701202025025-17/</guid>
      <description>中国大模型市场正经历新一轮洗牌，DeepSeek的崛起重塑了竞争格局。Kimi与Minimax作为昔日“六小龙”的代表，近期通过发布Kimi-Researcher深度研究Agent和Minimax-M1推理模型，试图在技术深度和产品应用上实现突破，争夺“下一个DeepSeek”的市场心智。它们在长文本、MoE架构和Agent应用上的差异化策略，预示着AI下半场竞争已从参数比拼转向对垂直场景的渗透和用户认知的占领，而团队的技术前瞻性成为核心竞争力。</description>
    </item>
    <item>
      <title>MiniMax M1的开源：在长上下文AI推理前沿的突破与权衡</title>
      <link>http://192.168.50.247:1313/insights/minimax-m1ai-20250626181004155-0/</link>
      <pubDate>Thu, 26 Jun 2025 18:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/minimax-m1ai-20250626181004155-0/</guid>
      <description>MiniMax近日开源了其首款推理模型M1，这款4560亿参数的混合注意力模型专为长上下文推理和软件任务设计，通过创新的“闪电注意力”和混合专家架构实现了百万级上下文与高效计算。尽管在多项基准测试中表现出色，尤其在长文本和软件工程领域树立了新标杆，但其在实际应用中仍面临稳定性挑战，凸显了实验室性能与真实世界鲁棒性之间的鸿沟，对未来AI模型的实用化提出了更高要求。</description>
    </item>
  </channel>
</rss>
