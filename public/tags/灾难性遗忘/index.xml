<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>灾难性遗忘 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98/</link>
    <description>Recent content in 灾难性遗忘 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 02 Jul 2025 13:34:03 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>游戏教父John Carmack：为何大型语言模型并非游戏智能的未来</title>
      <link>http://192.168.50.247:1313/insights/john-carmack-20250702133403546-3/</link>
      <pubDate>Wed, 02 Jul 2025 13:34:03 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/john-carmack-20250702133403546-3/</guid>
      <description>游戏界传奇人物约翰·卡马克指出，大型语言模型（LLM）并非游戏或通用人工智能的未来，因其“无所不知却又无所学”的预训练模式难以适应高效的交互式学习。他正通过在Atari平台上的具身智能和强化学习研究，解决AI在数据效率、灾难性遗忘和物理世界交互等方面的核心挑战，旨在推动AI向更接近人类的智能迈进。</description>
    </item>
  </channel>
</rss>
