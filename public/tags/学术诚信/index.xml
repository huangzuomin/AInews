<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>学术诚信 on AI内参</title>
    <link>http://192.168.50.247:1313/tags/%E5%AD%A6%E6%9C%AF%E8%AF%9A%E4%BF%A1/</link>
    <description>Recent content in 学术诚信 on AI内参</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 08 Jul 2025 19:27:25 +0800</lastBuildDate>
    <atom:link href="http://192.168.50.247:1313/tags/%E5%AD%A6%E6%9C%AF%E8%AF%9A%E4%BF%A1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>07-08日报|AI，闯入禁区：当机器直抵生命、思想与创造的终极边界</title>
      <link>http://192.168.50.247:1313/newspaper/2025-07-08-07-08-ai-/</link>
      <pubDate>Tue, 08 Jul 2025 19:27:25 +0800</pubDate>
      <guid>http://192.168.50.247:1313/newspaper/2025-07-08-07-08-ai-/</guid>
      <description>今天是2025年07月08日。AI的浪潮，已不再局限于效率工具的范畴，它正以一种前所未有的深度和广度，向人类的生命本源、知识高地乃至创造力的核心发起冲击。我们正站在一个十字路口：AI带来的奇迹令人振奋，但它在改写规则的同时，也悄然触及了那些我们曾以为“人”才独有的领域，拷问着我们的身份、责任与未来的边界。</description>
    </item>
    <item>
      <title>AI撰写论文的“幽灵指纹”：重塑科研诚信与知识的未来边界</title>
      <link>http://192.168.50.247:1313/insights/article-20250708174004675-0/</link>
      <pubDate>Tue, 08 Jul 2025 17:40:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250708174004675-0/</guid>
      <description>最新研究揭示了AI在学术论文中留下的独特“语言指纹”，部分期刊AI摘要使用率高达40%，这不仅暴露了科研领域对AI工具的滥用和潜在的学术不端行为，也引发了关于学术诚信、知识原创性和作者责任的深层伦理与哲学探讨，预示着未来科学出版需要更严格的治理框架和对人类贡献的重新定义。</description>
    </item>
    <item>
      <title>AI渗透学术写作：超越风格的“数字指纹”与知识生产的未来范式</title>
      <link>http://192.168.50.247:1313/insights/article-20250705111004294-3/</link>
      <pubDate>Sat, 05 Jul 2025 11:10:04 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250705111004294-3/</guid>
      <description>最新《自然》研究揭示高达14%的生物医学论文摘要可能由AI代写，其独特的风格词汇成为“数字指纹”。这不仅引发了对学术诚信、人机共生边界的深层思考，更推动着学术界在披露标准、作者定义和AI素养方面进行范式重构，以应对未来知识生产的伦理与效率挑战。</description>
    </item>
    <item>
      <title>当AI检测遭遇人类创作：教育信任危机下的学术诚信重构</title>
      <link>http://192.168.50.247:1313/insights/article-20250623113258940-5/</link>
      <pubDate>Mon, 23 Jun 2025 11:32:58 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250623113258940-5/</guid>
      <description>AI检测工具在教育领域普遍应用，却频频误判人类创作，将无辜学生推向“虚假阳性”的信任困境。学生们不得不采取录屏等极端方式自证清白，导致普遍的焦虑和师生信任关系的侵蚀。文章分析了AI检测的技术局限及社会影响，呼吁教育界超越技术对抗，转而重塑以过程、对话和负责任的AI使用为核心的学术诚信新范式。</description>
    </item>
    <item>
      <title>当AI检测遭遇人类创作：教育信任危机下的学术诚信重构</title>
      <link>http://192.168.50.247:1313/insights/article-20250623113044227-5/</link>
      <pubDate>Mon, 23 Jun 2025 11:30:44 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250623113044227-5/</guid>
      <description>AI检测工具在教育领域普遍应用，却频频误判人类创作，将无辜学生推向“虚假阳性”的信任困境。学生们不得不采取录屏等极端方式自证清白，导致普遍的焦虑和师生信任关系的侵蚀。文章分析了AI检测的技术局限及社会影响，呼吁教育界超越技术对抗，转而重塑以过程、对话和负责任的AI使用为核心的学术诚信新范式。</description>
    </item>
    <item>
      <title>当算法侵蚀学术：AI与公共数据如何助长一场“垃圾论文”海啸</title>
      <link>http://192.168.50.247:1313/insights/article-20250617025225335-1/</link>
      <pubDate>Tue, 17 Jun 2025 02:52:25 +0800</pubDate>
      <guid>http://192.168.50.247:1313/insights/article-20250617025225335-1/</guid>
      <description>随着AI工具的普及和公共数据集的滥用，学术界正经历一场前所未有的“垃圾论文”爆发，仅一个数据集一年就产出近8000篇论文，引发了对学术诚信和科学质量的严重担忧。这一现象不仅暴露出AI技术被论文工厂利用的风险，更深层地揭示了当前“以量取胜”的科研评价体系与开放获取期刊商业模式所导致的结构性扭曲，亟需从技术检测、期刊审查和激励机制改革等多维度进行应对，以维护科学的本质与价值。</description>
    </item>
  </channel>
</rss>
