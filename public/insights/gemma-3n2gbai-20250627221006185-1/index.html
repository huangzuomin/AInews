<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。">
    <meta name="generator" content="Hugo 0.147.8">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/insights/gemma-3n2gbai-20250627221006185-1/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局">
  <meta property="og:description" content="谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="insights">
    <meta property="article:published_time" content="2025-06-27T22:10:06+08:00">
    <meta property="article:modified_time" content="2025-06-27T22:10:06+08:00">
    <meta property="article:tag" content="Gemma 3n">
    <meta property="article:tag" content="端侧AI">
    <meta property="article:tag" content="大模型">
    <meta property="article:tag" content="人工智能">
    <meta property="article:tag" content="MatFormer">
    <meta property="article:tag" content="边缘计算">

  <meta itemprop="name" content="超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局">
  <meta itemprop="description" content="谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。">
  <meta itemprop="datePublished" content="2025-06-27T22:10:06+08:00">
  <meta itemprop="dateModified" content="2025-06-27T22:10:06+08:00">
  <meta itemprop="wordCount" content="71">
  <meta itemprop="keywords" content="Gemma 3n,端侧AI,大模型,人工智能,MatFormer,边缘计算,开源模型,内存优化,多模态AI,Google">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局">
  <meta name="twitter:description" content="谷歌最新发布的Gemma 3n模型，以其在最低2GB内存设备上运行多模态能力的突破，震惊了AI社区。这款开源模型采用创新的MatFormer架构和逐层嵌入技术，显著提升了端侧AI的效率和性能，在LMArena基准测试中得分超过1300，超越众多更大模型。Gemma 3n的发布预示着高性能AI向边缘设备普及的新趋势，将深刻影响离线智能应用的发展和AI的普惠化进程。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/newsimages/selected_image_YYYY-06-Jun%2027,%202025_22-01-35-375.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        <img src="/logo/logo.png" class="w100 mw5-ns" alt="AI内参" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/insights/" title="">
              洞察
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/newspaper/" title="">
              日报
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/explore/" title="">
              主题探索
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        <span style="color: #999;">2025-06-27 22:10</span>
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">超越极限：谷歌Gemma 3n如何以2GB内存颠覆端侧AI模型格局</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>谷歌Gemma 3n的正式发布，标志着端侧AI模型在内存效率与性能上达到了前所未有的高度。凭借创新的MatFormer架构和逐层嵌入技术，该模型能在最低2GB内存设备上运行，同时在LMArena基准测试中创下1300分的碾压性记录，预示着AI普惠化的新篇章。</p></blockquote>
<p>在人工智能领域，追求模型性能与资源效率的平衡始终是核心挑战。当行业巨头们竞相推出参数量动辄千亿的大模型，并引发对算力与能耗担忧之际，谷歌却选择了一条看似“反其道而行之”的路径——将强大的智能下沉至最受限的边缘设备。当地时间6月26日，谷歌正式发布了Gemma 3n完整版，这款模型不仅能够直接在本地硬件上运行，更以其在<strong>仅2GB内存</strong>下跑通并实现多模态能力的突破，在全球AI社区引发了震动。它不仅是第一个在参数规模低于10B（具体指E4B模型）的前提下，LMArena测评得分突破1300的模型，更以这一成绩超越了包括Llama 4 Maverick 17B、GPT 4.1-nano和Phi-4在内的一系列知名模型，证明了“小而精”也能迸发出惊人的力量。</p>
<p>Gemma系列是谷歌推出的开源大模型，与更注重性能和商业化的Gemini专有模型不同，Gemma面向开发者开放下载和修改，旨在构建一个更广泛的开源生态。此次发布的Gemma 3n，天生支持图像、音频、视频等多模态输入及文本输出，其核心亮点在于极致的运行效率。</p>
<h3 id="技术原理解析小尺寸大智慧">技术原理解析：小尺寸，大智慧</h3>
<p>Gemma 3n之所以能在如此受限的硬件环境中展现卓越性能，并非简单的模型小型化，而是得益于一系列深思熟虑的架构创新和优化策略。</p>
<p>谷歌特别指出，其高效能的核心在于全新的<strong>MatFormer</strong>（Matryoshka Transformer）架构，这是一种为弹性推理而设计的嵌套式Transformer。如同俄罗斯套娃般，一个较大的模型内部嵌套着一个功能完整但尺寸较小的子模型。这种设计将“套娃式表示学习”的理念从嵌入层扩展到整个Transformer架构的各个组件，从而大幅提升了模型在不同资源环境下的灵活性与适应性。在训练4B有效参数（E4B）模型时，系统会同时优化一个2B有效参数（E2B）子模型。这种双层优化带来了两大关键能力：</p>
<ul>
<li><strong>预提取模型，开箱即用</strong>：开发者可以根据应用场景灵活选择E4B主模型以获得更强性能，或直接使用预提取的E2B子模型。E2B在保证准确率的前提下，实现了高达2倍的推理速度，特别适用于边缘设备或算力受限的场景。</li>
<li><strong>Mix-n-Match定制模型</strong>：通过灵活调整每层前馈网络的隐藏维度（例如从8192调整到16384）并选择性跳过部分层，开发者可以在E2B与E4B之间自由定制模型大小，以适应不同的硬件资源限制。</li>
</ul>
<p>MatFormer架构还为未来的“弹性推理”奠定了基础，尽管尚未正式上线，但其设计理念已初具雏形：单个部署的E4B模型，未来将能够根据当前任务类型和设备负载，在运行时动态切换E4B与E2B的推理路径，实时优化性能与内存占用。</p>
<p>除了MatFormer，<strong>Per-Layer Embeddings (PLE)</strong> 机制也是提升内存效率的关键。这种专为端侧部署设计的创新机制，允许将很大一部分参数（即分布在各层的嵌入参数）在CPU上高效加载和计算。这意味着，尽管E2B和E4B模型的总参数数量分别为5B和8B，但只有核心Transformer权重（E2B约为2B，E4B约为4B）需要存储在通常更为受限的加速器内存（VRAM）中，从而显著降低了设备的硬件门槛。</p>
<p>在处理长序列输入（如音频、视频流）方面，Gemma 3n引入了<strong>KV Cache Sharing</strong>机制。该机制优化了模型的Prefill阶段，使中间层中来自局部与全局注意力机制的中间层Key与Value可以直接共享给所有上层结构，相较于Gemma 3 4B，Prefill性能提升高达2倍，尤其适用于流式响应场景，加速了长文本推理中“首个Token”的生成速度。</p>
<p>Gemma 3n还推出了全新的高效<strong>视觉编码器MobileNet-V5-300M</strong>，以提升边缘设备上的多模态任务表现。MobileNet-V5支持多种分辨率，并在Google Pixel设备上可实现每秒最高60帧的实时处理速度。同时，基于Universal Speech Model（USM）的先进<strong>音频编码器</strong>的搭载，使Gemma 3n能够对每160毫秒的语音生成一个token，解锁了端侧的语音识别与语音翻译功能，并在多种语言间表现出色。</p>
<h3 id="端侧部署与生态影响普惠ai的潜力与现实">端侧部署与生态影响：普惠AI的潜力与现实</h3>
<p>Gemma 3n的发布，不仅是一项技术突破，更是对AI应用边界的一次拓展。它不仅在技术层面降低了高性能AI模型的运行门槛，也在生态层面激发了开发者的巨大热情。</p>
<p>Django Web联合创建者Simon Willison对此高度评价，他表示Gemma 3n是“见过的任何模型中首发最全面的”，并指出谷歌与AMD、Hugging Face、NVIDIA、Ollama等几十家生态伙伴的紧密合作，使得开发者可以有多种方式尝试和部署该模型<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。Willison在Mac笔记本电脑上运行不同版本的Gemma 3n时发现，尽管模型在图像生成方面存在量化差异（7.5GB和15GB模型之间有显著视觉差异），且Ollama版本尚不支持图像或音频输入，但mlx-vlm版本已可支持<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。同时，他也指出模型在图片描述方面仍有改进空间，例如将他生成的图片误认为化学图。</p>
<p>不过，开发者pilooch则赞叹Gemma 3n的兼容性和训练效率：“我将其接入视觉语言模型微调脚本后，程序顺利启动（使用 HF Transformer 代码）。在单GPU运行LoRa微调时，E4B模型在批量大小为1的情况下仅占用18GB VRAM，而Gemma-4B需要21GB。DeepMind推出的Gemma3系列真不错，稳居开源视觉语言模型榜首。”<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> 另一位开发者则表示，在AI Studio中试用E4B的效果“非常好，比8B型号的预期要好得多”，并考虑将其安装在VPS上，以替代昂贵的API服务。</p>
<p>尽管Gemma 3n展现出强大的潜力，社区中对小模型的实际用处仍存在不同看法。有开发者直言不讳地表示：“我做过很多实验，任何小于27B的模型基本上都用不了，除非当玩具用。对于小模型，我只能说它们有时能给出不错的答案，但这还不够。”这种观点反映了部分专业用户对模型性能“天花板”的追求。然而，也有网友提供了小模型的实用案例：“我发现微型模型（&lt;5B参数）的最佳用例是作为没有WiFi时的参考工具。我在飞机上写代码时，一直在MacBook Air上使用Qwen来代替谷歌搜索，它在询问有关语法和文档的基本问题时非常有效。”<sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p>这一讨论恰恰揭示了Gemma 3n这类端侧模型的真正价值：它们并非旨在全面替代云端大模型，而是在特定场景下，为用户提供<strong>离线、实时、低延迟且注重隐私</strong>的智能服务。这对于那些数据敏感、网络受限或需要即时响应的应用而言，具有颠覆性的意义。想象一下，您的手机、智能穿戴设备或家用机器人能够无需联网，即可理解并处理复杂的语音指令、分析本地图像和视频流，甚至进行简单的编程辅助——Gemma 3n正在让这些设想变为现实。</p>
<p>谷歌Gemma 3n的发布，是AI发展史上一个重要的里程碑。它不仅挑战了人们对“大模型”的固有认知，更通过精妙的架构设计，将高性能AI的门槛降至前所未有的低点。这无疑将加速AI在智能手机、物联网设备、汽车等各类边缘硬件上的普及，推动人工智能从云端中心化走向端侧普惠化。Gemma 3n的问世，不仅仅是技术参数上的突破，更是对未来AI形态的一次深刻预演，它预示着一个更加智能、更少依赖云端、更贴近用户生活的“边缘智能时代”的到来。</p>
<h2 id="引用">引用</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://simonwillison.net/2025/Jun/26/gemma-3n/">Gemma 3n</a>·Simon Willison’s Blog·Simon Willison（2025/6/26）·检索日期2025/6/27&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://m.36kr.com/p/3354532205261447">2G 内存跑Gemma 3n完整版，全球首个10B内模型杀疯LMArena - 36氪</a>·36氪·褚杏娟（2025/6/27）·检索日期2025/6/27&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/gemma-3n/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Gemma 3n</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E7%AB%AF%E4%BE%A7ai/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">端侧AI</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">大模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">人工智能</a>
   </li>
  
   <li class="list di">
     <a href="/tags/matformer/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">MatFormer</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">边缘计算</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">开源模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">内存优化</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81ai/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">多模态AI</a>
   </li>
  
   <li class="list di">
     <a href="/tags/google/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Google</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/insights/gemma-3nai2gb-20250627191005495-3/">谷歌Gemma 3n：将高性能多模态AI带入2GB内存时代的里程碑</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/gemma-3n2gai-20250627201004999-4/">谷歌Gemma 3n：2G显存解锁端侧AI新纪元</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250626201004526-0/">智能演进：AI高考的跃迁与隐匿的认知鸿沟</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250627171004412-0/">超越符号：新型大模型如何通过代码图谱重塑软件工程的未来</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/metascale-aiai-20250627091004258-0/">元宇宙巨头入局，数据基石动摇：Meta收购Scale AI如何搅动AI信任与供应链？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/kimiai-20250625171004517-3/">Kimi能否穿越“月之暗面”：AI创业浪潮中的战略迷思与重塑之路</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004566-9/">“上新潮”来袭：AI眼镜如何重塑人机交互与产业格局？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624231007315-0/">边缘智能的突破：小米小爱同学如何在资源受限下实现高性能大模型推理</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624161004445-2/">AI浪潮下的权力、资本与转型：从巨头布局到人才争夺</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openai-o3-pro-20250624131004401-0/">OpenAI o3-pro：可靠性之诺与用户体验的现实鸿沟</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/3ai-20250623181004301-0/">有道“子曰3”：低成本AI大模型如何重塑数学教育的公平版图</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openaisam-altmangpt-5-20250623113259005-16/">OpenAI新篇章：Sam Altman预告开源模型、GPT-5多模态跃进与智能体时代的来临</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/anthropic-20250623113258945-6/">当智能体寻求“自保”：Anthropic研究揭示大模型“错位”行为的深层隐忧</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openaisam-altmangpt-5-20250623113044290-16/">OpenAI新篇章：Sam Altman预告开源模型、GPT-5多模态跃进与智能体时代的来临</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/anthropic-20250623113044233-6/">当智能体寻求“自保”：Anthropic研究揭示大模型“错位”行为的深层隐忧</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
