<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="谷歌DeepMind发布了其首个可完全在机器人本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的重大转变。该模型实现了低延迟、高效学习和跨形态泛化能力，并通过开放微调功能和SDK，旨在构建一个开放的机器人“安卓”生态系统，从而推动具身智能在隐私敏感和无网络环境中的应用。尽管其落地仍面临硬件碎片化、数据成本高昂以及在复杂真实世界中保持鲁棒性等挑战，但此次发布为机器人走向更广泛的实际应用奠定了关键基础。">
    <meta name="generator" content="Hugo 0.147.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/insights/vla-20250627091004314-5/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/insights/vla-20250627091004314-5/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景">
  <meta property="og:description" content="谷歌DeepMind发布了其首个可完全在机器人本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的重大转变。该模型实现了低延迟、高效学习和跨形态泛化能力，并通过开放微调功能和SDK，旨在构建一个开放的机器人“安卓”生态系统，从而推动具身智能在隐私敏感和无网络环境中的应用。尽管其落地仍面临硬件碎片化、数据成本高昂以及在复杂真实世界中保持鲁棒性等挑战，但此次发布为机器人走向更广泛的实际应用奠定了关键基础。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="insights">
    <meta property="article:published_time" content="2025-06-27T09:10:04+08:00">
    <meta property="article:modified_time" content="2025-06-27T09:10:04+08:00">
    <meta property="article:tag" content="谷歌DeepMind">
    <meta property="article:tag" content="Gemini Robotics On-Device">
    <meta property="article:tag" content="具身智能">
    <meta property="article:tag" content="VLA模型">
    <meta property="article:tag" content="本地部署">
    <meta property="article:tag" content="机器人操作系统">

  <meta itemprop="name" content="谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景">
  <meta itemprop="description" content="谷歌DeepMind发布了其首个可完全在机器人本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的重大转变。该模型实现了低延迟、高效学习和跨形态泛化能力，并通过开放微调功能和SDK，旨在构建一个开放的机器人“安卓”生态系统，从而推动具身智能在隐私敏感和无网络环境中的应用。尽管其落地仍面临硬件碎片化、数据成本高昂以及在复杂真实世界中保持鲁棒性等挑战，但此次发布为机器人走向更广泛的实际应用奠定了关键基础。">
  <meta itemprop="datePublished" content="2025-06-27T09:10:04+08:00">
  <meta itemprop="dateModified" content="2025-06-27T09:10:04+08:00">
  <meta itemprop="wordCount" content="42">
  <meta itemprop="keywords" content="谷歌DeepMind,Gemini Robotics On-Device,具身智能,VLA模型,本地部署,机器人操作系统,AI模型,端侧AI">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景">
  <meta name="twitter:description" content="谷歌DeepMind发布了其首个可完全在机器人本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的重大转变。该模型实现了低延迟、高效学习和跨形态泛化能力，并通过开放微调功能和SDK，旨在构建一个开放的机器人“安卓”生态系统，从而推动具身智能在隐私敏感和无网络环境中的应用。尽管其落地仍面临硬件碎片化、数据成本高昂以及在复杂真实世界中保持鲁棒性等挑战，但此次发布为机器人走向更广泛的实际应用奠定了关键基础。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/images/default%20%281%29.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        <img src="/logo/logo.png" class="w100 mw5-ns" alt="AI内参" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/insights/" title="">
              洞察
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/newspaper/" title="">
              日报
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/explore/" title="">
              主题探索
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        <span style="color: #999;">2025-06-27 09:10</span>
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">谷歌推出本地VLA模型：具身智能迈向“端侧时代”与机器人“安卓”生态的愿景</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>谷歌DeepMind发布的首个完全本地部署的视觉-语言-动作（VLA）模型Gemini Robotics On-Device，标志着具身智能从云端依赖向本地自主运行的关键转折。这一突破不仅极大地提升了机器人响应速度和隐私安全性，更被视为构建开放、标准化的机器人“安卓”生态系统的基础，尽管其落地仍面临硬件碎片化和复杂环境适应性的严峻挑战。</p></blockquote>
<p>在人工智能领域，每一次核心计算范式的转移，都预示着一个新时代的到来。继大型语言模型（LLMs）从云端走向边缘设备之后，具身智能——将AI赋予物理形态，使其能在真实世界中感知、理解并行动——也正经历着一场深刻的“端侧革命”。近日，Google DeepMind发布的首个可完全在机器人本地部署的<strong>视觉-语言-动作模型（Visual-Language-Action, VLA）——Gemini Robotics On-Device</strong>，正是这场变革中的一个里程碑事件，其深层含义远不止于技术演示，更指向了机器人领域长期愿景中的“安卓系统”化<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h3 id="技术原理解析从云端到本地的飞跃">技术原理解析：从云端到本地的飞跃</h3>
<p>长期以来，具身智能的部署面临着两大核心瓶颈：对云计算资源的重度依赖和模型自身的体积庞大。机器人需要通过网络将视觉、听觉等传感器数据传输至云端进行复杂推理，再将决策传回执行。这种架构不仅受限于网络带宽和延迟，也使得机器人在网络不稳定或无网络环境下几乎无法独立作业。同时，通用AI模型巨大的参数量，也难以在机器人有限的本地计算资源上高效运行。</p>
<p>Gemini Robotics On-Device的出现，正是为了破解这些限制。这款模型能够<strong>在算力受限的机器人设备上直接运行</strong>，无需持续联网。这意味着，机器人现在可以在工厂车间、家庭环境乃至野外等任何没有稳定网络连接的场景中，独立完成复杂的任务。其核心优势在于：</p>
<ul>
<li><strong>本地运行能力</strong>：摆脱了对云端算力的束缚，极大地降低了延迟，提升了实时响应速度，这对于需要即时决策和高精度执行的机器人应用至关重要。</li>
<li><strong>高效学习与泛化</strong>：DeepMind研究人员指出，该模型只需<strong>50-100次演示</strong>即可学习新技能，相比传统机器人训练动辄成百上千次的迭代，效率得到了质的提升<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这种“少量演示学习”的能力，极大地降低了机器人部署和任务拓展的门槛。</li>
<li><strong>跨机器人形态泛化</strong>：尽管模型可能针对特定机器人训练，但它能够<strong>泛化到不同的机器人形态</strong>，例如在演示中，模型在双臂Franka机器人上成功执行了折叠衣服、工业组装等精巧任务，并能处理此前未见过的物体和场景<sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这种通用性是构建广泛机器人生态系统的基石。</li>
<li><strong>开放生态的构建</strong>：谷歌首次开放了VLA模型的微调功能，并推出了Gemini Robotics SDK。这使得工程师和机器人公司可以基于自身数据对模型进行定制化训练和评估，从而优化特定任务和硬件平台的表现。这种开放策略，与安卓系统在智能手机领域所做的如出一辙，旨在构建一个<strong>开放、通用且易于开发的机器人平台</strong><sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</li>
</ul>
<p>本质上，VLA模型赋予机器人从多模态信息（视觉、语言）中理解任务并转化为实际行动的能力。此前的VLA模型若要实现复杂操作，往往需依赖强大的云端推理和决策。此次本地部署的突破，如同为机器人装上了“离线大脑”，让具身智能真正“走入真实环境”<sup id="fnref4:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h3 id="行业影响与未来图景端侧时代与安卓愿景">行业影响与未来图景：“端侧时代”与“安卓”愿景</h3>
<p>谷歌此次发布，预示着具身智能领域正在迈入一个崭新的“端侧时代”。如同大语言模型从云端走向手机、平板，本地VLA模型的出现，使得机器人具备了前所未有的自主性。</p>
<p>一位具身智能领域专家强调：</p>
<blockquote>
<p>“以往受限于带宽和算力，很多机器人AI只能做示范。这次谷歌的进展，意味着通用模型可以真正运行在硬件终端上，未来不依赖联网也能做复杂操作。”<sup id="fnref5:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p></blockquote>
<p>这种本地化能力，对于机器人走向家庭、医疗、教育等敏感场景具有决定性意义。它能够有效解决数据隐私、实时反应、安全稳定性等核心挑战。试想，一个在家庭中服务的机器人，其操作无需依赖外部网络，不仅能确保用户数据的本地化处理，也能在紧急情况下迅速响应，而不会受制于网络连接的波动。</p>
<p>更深远的影响在于，谷歌正在试图为机器人领域提供一个类似于“安卓”的操作系统级平台。目前，机器人硬件的多样性——不同的本体结构、自由度、传感器配置——使得统一的软件架构难以实现<sup id="fnref6:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。这导致了每个机器人都需要独立的软件开发和适配，极大地阻碍了行业发展和规模化应用。</p>
<p>正如一位关注机器人领域的投资人所言：</p>
<blockquote>
<p>“一旦硬件标准趋于统一，正如智能手机生态中USB接口、键盘、屏幕等通用组件所形成的规范一样，将大大推动算法的标准化与本地部署的实现。”<sup id="fnref7:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p></blockquote>
<p>谷歌的“机器人安卓生态”愿景，正是希望通过开放模型和开发工具，鼓励开发者和硬件厂商围绕其VLA模型构建应用，从而推动硬件接口和软件标准的逐渐统一。这有望加速具身智能的普及，催生更多创新应用，并降低开发成本。</p>
<h3 id="挑战与前瞻性思考通向通用机器人之路的崎岖">挑战与前瞻性思考：通向通用机器人之路的崎岖</h3>
<p>尽管Gemini Robotics On-Device带来了振奋人心的突破，但具身智能真正实现大规模落地，依然面临诸多不容小觑的挑战。</p>
<p>首先是<strong>硬件的碎片化和适配性问题</strong>。尽管模型具备跨形态泛化能力，但市场上形形色色的机器人硬件意味着即使是强大的通用模型，也需针对每种具体硬件进行细致的适配和调优。每一次新的硬件平台，都可能需要额外的工程投入，这在短期内仍是阻碍快速普及的关键因素<sup id="fnref8:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<p>其次是<strong>数据收集和标注的成本</strong>。要让机器人在海量、多样化的实际应用场景中真正落地，高质量的数据集是不可或缺的。特别是在需要专业操作知识和设备的工业或特定服务场景，数据收集和标注的成本可能异常高昂。如何高效、经济地获取足够多样性和真实世界复杂性的数据，将是决定模型鲁棒性和通用性的关键。</p>
<p>更重要的是，机器人需要在<strong>极其复杂、动态且不可预测的真实世界环境中保持鲁棒性</strong>。光照变化、物体遮挡、非结构化杂乱环境，以及人机交互中的细微差异，都将对模型的实时感知和决策能力提出严苛考验<sup id="fnref9:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。确保机器人在各种实际场景中都能保持高水平的稳定性、安全性和可靠性，是未来具身智能发展必须持续攻克的难题。本地部署固然解决了速度和隐私问题，但模型本身对复杂环境的理解和应对能力，仍需通过持续的研究和海量真实数据训练来提升。</p>
<p>总而言之，谷歌Gemini Robotics On-Device的发布，无疑为具身智能的未来打开了新的窗口，将“离线大脑”的愿景推向现实。它不仅仅是技术层面的一个新模型，更是对整个机器人产业生态的一次重塑尝试。然而，从实验室的演示到普罗大众的日常应用，具身智能的道路依然漫长而充满挑战，需要技术创新、产业协作和伦理治理的共同推进。这场“端侧革命”的真正影响，将在未来几年逐渐显现。</p>
<h2 id="引用">引用</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>谷歌发布本地VLA模型，机器人界的“安卓系统”要来了？·36氪·武静静 (2025/6/27)·检索日期2025/6/27&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref5:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref6:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref7:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref8:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref9:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/%E8%B0%B7%E6%AD%8Cdeepmind/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">谷歌DeepMind</a>
   </li>
  
   <li class="list di">
     <a href="/tags/gemini-robotics-on-device/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Gemini Robotics On-Device</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">具身智能</a>
   </li>
  
   <li class="list di">
     <a href="/tags/vla%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">VLA模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">本地部署</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">机器人操作系统</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E7%AB%AF%E4%BE%A7ai/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">端侧AI</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/insights/gemini-robotics-on-device-20250625121004319-2/">谷歌的具身智能新策略：Gemini Robotics On-Device与“机器人安卓”生态的黎明</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/deepmindgemini-20250625121004313-1/">谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/deepmindalphagenomeai-20250627091004322-6/">DeepMind的AlphaGenome：AI破译基因组“天书”的统一之钥</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openaiai-20250626131004994-1/">OpenAI首款神秘硬件：超越屏幕的AI具身计算新范式</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/casbot-20250626121005072-0/">北京人形机器人新星灵宝CASBOT：高速融资背后的人形智能落地之路</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/casbot-20250626101004254-0/">灵宝CASBOT获近亿元融资：人形机器人如何深耕工业与矿产，重塑具身智能商业化路径</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625211007538-0/">人形机器人：从宏大愿景到务实求生，产业加速驶入“精打细算”新阶段</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/newspaper/2025-06-25-06-25-ai-/">06-25日报|AI“具身入世”：智能体破界而来，重塑生命、工作与权力的未来格局</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/ucleverb-20250625171004494-0/">弥合“想”与“做”的鸿沟：UC伯克利LeVERB框架赋能人形机器人自主决策</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625161004880-1/">小米AI眼镜：具身智能的下一步，抑或数字伦理的新挑战？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/aichatgpt-20250625151004761-0/">具身智能：中国「身体力行」的AI如何探索「ChatGPT时刻」</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004566-9/">“上新潮”来袭：AI眼镜如何重塑人机交互与产业格局？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004505-0/">摆脱“花瓶”困境：银河通用如何在具身智能的“无人区”中深耕实用价值</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624231007315-0/">边缘智能的突破：小米小爱同学如何在资源受限下实现高性能大模型推理</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624191004335-0/">特斯拉机器人出租车引发监管关注：自动驾驶的现实与伦理拷问</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
