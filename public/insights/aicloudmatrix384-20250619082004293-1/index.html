<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式 | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="华为最新发布的CloudMatrix384 AI超级节点，在DeepSeek-R1大语言模型评估中展现出超越英伟达H800 GPU的计算效率。这一突破性成果得益于CloudMatrix384创新的统一总线（UB）网络架构和昇腾910C NPU的协同作用，为构建高性能、可扩展的AI原生数据中心树立了新标杆，并预示着全球AI算力格局的潜在转变。">
    <meta name="generator" content="Hugo 0.147.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/insights/aicloudmatrix384-20250619082004293-1/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/insights/aicloudmatrix384-20250619082004293-1/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式">
  <meta property="og:description" content="华为最新发布的CloudMatrix384 AI超级节点，在DeepSeek-R1大语言模型评估中展现出超越英伟达H800 GPU的计算效率。这一突破性成果得益于CloudMatrix384创新的统一总线（UB）网络架构和昇腾910C NPU的协同作用，为构建高性能、可扩展的AI原生数据中心树立了新标杆，并预示着全球AI算力格局的潜在转变。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="insights">
    <meta property="article:published_time" content="2025-06-19T08:20:04+08:00">
    <meta property="article:modified_time" content="2025-06-19T08:20:04+08:00">
    <meta property="article:tag" content="华为">
    <meta property="article:tag" content="AI算力">
    <meta property="article:tag" content="昇腾910C">
    <meta property="article:tag" content="CloudMatrix384">
    <meta property="article:tag" content="大语言模型">
    <meta property="article:tag" content="英伟达">

  <meta itemprop="name" content="华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式">
  <meta itemprop="description" content="华为最新发布的CloudMatrix384 AI超级节点，在DeepSeek-R1大语言模型评估中展现出超越英伟达H800 GPU的计算效率。这一突破性成果得益于CloudMatrix384创新的统一总线（UB）网络架构和昇腾910C NPU的协同作用，为构建高性能、可扩展的AI原生数据中心树立了新标杆，并预示着全球AI算力格局的潜在转变。">
  <meta itemprop="datePublished" content="2025-06-19T08:20:04+08:00">
  <meta itemprop="dateModified" content="2025-06-19T08:20:04+08:00">
  <meta itemprop="wordCount" content="44">
  <meta itemprop="keywords" content="华为,AI算力,昇腾910C,CloudMatrix384,大语言模型,英伟达,AI基础设施,并行计算">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式">
  <meta name="twitter:description" content="华为最新发布的CloudMatrix384 AI超级节点，在DeepSeek-R1大语言模型评估中展现出超越英伟达H800 GPU的计算效率。这一突破性成果得益于CloudMatrix384创新的统一总线（UB）网络架构和昇腾910C NPU的协同作用，为构建高性能、可扩展的AI原生数据中心树立了新标杆，并预示着全球AI算力格局的潜在转变。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/images/default%20%287%29.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        <img src="/logo/logo.png" class="w100 mw5-ns" alt="AI内参" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/insights/" title="">
              洞察
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/newspaper/" title="">
              日报
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/explore/" title="">
              主题探索
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        <span style="color: #999;">2025-06-19 08:20</span>
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">华为突破AI基础设施瓶颈：CloudMatrix384如何重塑超大规模计算范式</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>华为最新发布的CloudMatrix384 AI超级节点及其昇腾910C NPU在运行DeepSeek-R1大语言模型时，展示出超越英伟达H800 GPU的计算效率，其核心在于创新的统一总线（UB）网络架构，为构建下一代AI原生数据中心提供了高性能、可扩展的解决方案，并预示着AI算力竞争格局的新变化。</p></blockquote>
<p>在人工智能浪潮席卷全球的当下，算力已成为国家乃至企业竞争力的核心。长期以来，英伟达凭借其CUDA生态系统和领先的GPU技术，几乎垄断了高端AI芯片市场。然而，这一格局正被一股来自东方的力量——华为——悄然挑战。最近，华为联合硅基流动发布的一篇论文揭示了其AI超级节点CloudMatrix384在实际大语言模型（LLM）推理任务中，<strong>效率超越英伟达H800 GPU的惊人表现</strong>，这不仅是对其技术实力的强有力证明，也为全球AI基础设施的发展指明了新的方向 <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h3 id="华为的互联即力量策略cloudmatrix384的架构创新">华为的“互联即力量”策略：CloudMatrix384的架构创新</h3>
<p>当前，大型AI模型，特别是混合专家（MoE）模型，对计算、内存和通信提出了前所未有的要求。传统的AI数据中心架构，往往受限于孤立的计算单元、有限的内存带宽以及高昂的芯片间通信开销。华为的CloudMatrix架构，正是为解决这些深层痛点而生。</p>
<p>CloudMatrix的核心理念在于**“互联即力量”**，它彻底重新构想了AI数据中心基础设施。其愿景是拆除传统的分层设计，实现CPU、NPU、内存、网络接口卡（NIC）等所有异构系统组件的完全点对点分解和池化，并通过一个统一的、超高性能网络互联 <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。</p>
<p>这种架构的首次生产级落地便是CloudMatrix384超级节点。它集成了惊人的<strong>384颗昇腾910C NPU和192个鲲鹏CPU</strong>。最引人注目的技术亮点是其采用了<strong>超高带宽、低延迟的统一总线（UB）网络</strong>。与传统通过CPU中介或RDMA网络进行通信不同，UB网络实现了所有NPU和CPU之间的直接、高性能通信，从而将节点间通信性能提升至接近节点内水平。</p>
<p>具体来看，CloudMatrix384的UB网络设计为无阻塞网络，在L2交换层没有带宽超额订阅。每个昇腾910C NPU提供高达392GB/s的单向UB带宽，而每个鲲鹏CPU插槽提供约160GB/s的单向UB带宽。这种极致的互联能力，对于通信密集型任务至关重要，例如大规模MoE模型的专家并行（Expert Parallelism）和分布式键值（KV）缓存访问。</p>
<p>昇腾910C NPU本身也采用了先进的双die封装技术，每个封装集成了两个计算die，共享128GB封装内存，并通过高带宽交叉die结构连接。其单颗芯片可提供约376 TFLOPS的BF16/FP16密集吞吐量，这为高效率计算奠定了硬件基础。</p>
<p>软件层面，华为构建了名为**神经网络计算架构（CANN）**的全面软件生态系统，类似于英伟达的CUDA。CANN作为中间件，将高级AI框架（如PyTorch）与昇腾NPU底层硬件高效集成，通过将计算图转换为优化的硬件可执行指令，简化了开发并最大化了性能。配合华为云的MatrixResource、MatrixLink等基础设施软件，CloudMatrix384的部署和资源编排得以实现无缝衔接 <sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<h3 id="性能突破与市场格局超越英伟达的背后">性能突破与市场格局：超越英伟达的背后</h3>
<p>华为的CloudMatrix-Infer服务解决方案，旨在充分利用CloudMatrix384的强大能力，特别是针对DeepSeek-R1这样的大规模MoE模型。通过一系列核心创新，CloudMatrix-Infer取得了显著的性能提升。</p>
<p>其中最关键的创新包括：</p>
<ul>
<li><strong>点对点服务架构</strong>：将预填充、解码和缓存分解到独立可扩展的资源池中，并通过UB网络实现对缓存数据的高带宽、统一访问，从而减少数据局部性限制并提高缓存效率。</li>
<li><strong>大规模专家并行（LEP）策略</strong>：利用UB网络实现高效的token调度和专家输出组合，支持极高的EP度数（如EP320），使每个NPU芯片仅托管一名专家，显著降低了解码延迟。</li>
<li><strong>硬件感知优化</strong>：包括高度优化的算子、基于微批处理的流水线和INT8量化，以提高执行效率和资源利用率。</li>
</ul>
<p>在对DeepSeek-R1模型的广泛评估中，CloudMatrix-Infer的计算效率确实令人瞩目。它在预填充阶段为每颗NPU提供了<strong>6688 tokens/s的吞吐量</strong>，在解码期间为每颗NPU提供了<strong>1943 tokens/s的吞吐量</strong>，同时保持每个输出token低于50ms的低延迟 <sup id="fnref2:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。换算成计算效率，预填充阶段达到<strong>4.45 tokens/s/TFLOPS</strong>，解码阶段达到<strong>1.29 tokens/s/TFLOPS</strong>。这些数据不仅验证了华为的架构设计，更重要的是，<strong>它超越了NVIDIA H100上的SGLang和H800上的DeepSeek等领先框架的公布效率</strong> <sup id="fnref3:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<p>这一成就也印证了英伟达CEO黄仁勋早前的判断：尽管美国芯片技术可能领先华为一代，但人工智能是一个并行问题。如果单台计算机的性能不足够强，那就用更多的计算机。黄仁勋的言论间接肯定了华为通过大规模并行和高效互联来弥补个体芯片差距的策略。华为的这一进展，无疑增强了其在中国乃至更广阔市场满足大模型需求的能力，对英伟达在AI算力市场的长期主导地位构成了实质性挑战。</p>
<h3 id="ai基础设施的未来技术融合与产业影响">AI基础设施的未来：技术融合与产业影响</h3>
<p>CloudMatrix384的成功不仅仅是单一产品性能的提升，它更代表着AI基础设施设计理念的一次范式转变。随着模型规模的爆炸式增长，尤其是MoE架构的普及和上下文长度的不断扩展，传统的数据中心架构瓶士愈发明显。华为通过其点对点、完全互联、超高带宽的UB网络，为未来的AI数据中心基础设施树立了新标杆。</p>
<p>从更广阔的视角来看，这种“互联先行”的架构策略，预示着AI计算将越来越依赖于<strong>分布式系统的整体优化，而非仅仅是单点芯片性能的提升</strong>。这意味着未来的竞争将不仅仅是芯片硬件的算力比拼，更是系统级设计、网络拓扑、软件栈协同优化能力的全面较量。</p>
<p>CloudMatrix384的未来增强方向也描绘了一幅令人兴奋的蓝图：整合和统一VPC和RDMA网络平面以实现更简化的互连，扩展到更大的超级节点配置，以及追求更深入的CPU资源分解和池化。这些方向都指向了AI数据中心基础设施的更高灵活性、效率和可扩展性。</p>
<p>华为在AI算力领域的这一突破，不仅提升了其自身在全球科技舞台上的竞争力，也为其他国家和地区发展自主可控的AI基础设施提供了宝贵的经验。在当前地缘政治背景下，这不仅是技术上的胜利，更是战略上的主动出击，可能重塑全球AI生态系统的力量平衡。AI技术的发展，从来不只是纯粹的技术演进，它总是与经济、社会乃至国际关系紧密交织。华为CloudMatrix384的案例，正是这一复杂现实的最新注脚。</p>
<h2 id="references">References</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>智东西（2025/6/18）。<a href="https://m.36kr.com/p/3341960690612743">黄仁勋夸爆的华为AI超节点，技术秘籍披露，昇腾910C跑DeepSeek，效率超英伟达</a>。36氪。检索日期2025/6/19。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>李水青（2025/6/18）。<a href="https://news.qq.com/rain/a/20250618A08SEA00">黄仁勋夸爆的华为AI超节点，技术秘籍披露！昇腾910C跑DeepSeek</a>。腾讯新闻。检索日期2025/6/19。&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/%E5%8D%8E%E4%B8%BA/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">华为</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E7%AE%97%E5%8A%9B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI算力</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%98%87%E8%85%BE910c/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">昇腾910C</a>
   </li>
  
   <li class="list di">
     <a href="/tags/cloudmatrix384/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">CloudMatrix384</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">大语言模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E8%8B%B1%E4%BC%9F%E8%BE%BE/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">英伟达</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI基础设施</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">并行计算</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/insights/article-20250619042004381-0/">AI编排层：驾驭提示词之乱，构建智能企业新秩序</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openaigpt-45-apiai-20250618202004742-3/">OpenAI策略调整：GPT-4.5 API退役背后的成本、稳定与AI生态两难</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250618192004390-1/">AI算力浪潮下的隐形负担：美国数据中心爆发式增长的环境警示</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/llmmit50-20250618172004590-1/">信息洪流中的LLM深度航标：MIT揭示掌握大模型精髓的50个关键洞察</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/gemini-25ai-20250618122004604-5/">揭秘Gemini 2.5家族：从轻量级“神经操作系统”到AI“智能体恐慌”的深层洞察</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/anthropicaiai-20250618072004246-0/">Anthropic的可解释AI：解构大模型“黑箱”，重塑企业级AI策略的信任基石</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250618002005001-0/">任正非的“无心之言”：华为长局中的中国AI芯未来</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250617232005846-1/">当AI学会“喵喵叫”：提示词攻击揭示数字人直播深层安全困境</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/chatgpt-20250617202000390-6/">大语言模型如何被一场古老棋局“考倒”：ChatGPT与“理解”的边界</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/mathfusion-20250617202000416-9/">超越“死记硬背”：MathFusion如何通过巧妙融合数据提升大模型数学推理能力</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250617193006108-0/">“思考的幻象”还是评估的盲点？AI推理能力辩论的深层反思</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/ai-agent-20250617193006124-2/">字节跳动的AI Agent豪赌：重塑数字未来的关键战役</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250617190043087-6/">超越“思考的幻觉”：一场关乎大模型推理本质与评估范式的深度辩论</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/groqhugging-faceai-20250617083004617-2/">Groq携手Hugging Face：一场重塑AI推理格局的速度革命</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250617025225342-2/">昆仑万维的AI豪赌：在“烧钱”中追逐巨头梦的代价与前路</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
