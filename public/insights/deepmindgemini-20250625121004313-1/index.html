<!DOCTYPE html>
<html lang="zh-cn">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？ | AI内参</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="谷歌DeepMind推出了Gemini Robotics On-Device，这是其首个可直接在机器人上本地运行的视觉-语言-动作（VLA）模型，大幅降低了延迟并提高了在无网络环境下的鲁棒性。该模型展现了强大的任务泛化能力和跨机器人平台适应性，只需少量演示即可快速适应新任务，预示着具身智能迈向更加自主和普及的关键阶段，但也带来了对安全性、伦理和商业模式的新思考。">
    <meta name="generator" content="Hugo 0.147.8">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    <meta name="author" content="温故智新AIGC实验室">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/css/custom.css">
  

  
    <link rel="stylesheet" href="/css/article-enhancements.css">
  


    


    
      

    

    

    
      <link rel="canonical" href="http://192.168.50.247:1313/insights/deepmindgemini-20250625121004313-1/">
    

    <meta property="og:url" content="http://192.168.50.247:1313/insights/deepmindgemini-20250625121004313-1/">
  <meta property="og:site_name" content="AI内参">
  <meta property="og:title" content="谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？">
  <meta property="og:description" content="谷歌DeepMind推出了Gemini Robotics On-Device，这是其首个可直接在机器人上本地运行的视觉-语言-动作（VLA）模型，大幅降低了延迟并提高了在无网络环境下的鲁棒性。该模型展现了强大的任务泛化能力和跨机器人平台适应性，只需少量演示即可快速适应新任务，预示着具身智能迈向更加自主和普及的关键阶段，但也带来了对安全性、伦理和商业模式的新思考。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="insights">
    <meta property="article:published_time" content="2025-06-25T12:10:04+08:00">
    <meta property="article:modified_time" content="2025-06-25T12:10:04+08:00">
    <meta property="article:tag" content="具身智能">
    <meta property="article:tag" content="机器人AI">
    <meta property="article:tag" content="Gemini Robotics On-Device">
    <meta property="article:tag" content="本地运行">
    <meta property="article:tag" content="VLA模型">
    <meta property="article:tag" content="DeepMind">

  <meta itemprop="name" content="谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？">
  <meta itemprop="description" content="谷歌DeepMind推出了Gemini Robotics On-Device，这是其首个可直接在机器人上本地运行的视觉-语言-动作（VLA）模型，大幅降低了延迟并提高了在无网络环境下的鲁棒性。该模型展现了强大的任务泛化能力和跨机器人平台适应性，只需少量演示即可快速适应新任务，预示着具身智能迈向更加自主和普及的关键阶段，但也带来了对安全性、伦理和商业模式的新思考。">
  <meta itemprop="datePublished" content="2025-06-25T12:10:04+08:00">
  <meta itemprop="dateModified" content="2025-06-25T12:10:04+08:00">
  <meta itemprop="wordCount" content="58">
  <meta itemprop="keywords" content="具身智能,机器人AI,Gemini Robotics On-Device,本地运行,VLA模型,DeepMind,AI泛化能力,AI伦理">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？">
  <meta name="twitter:description" content="谷歌DeepMind推出了Gemini Robotics On-Device，这是其首个可直接在机器人上本地运行的视觉-语言-动作（VLA）模型，大幅降低了延迟并提高了在无网络环境下的鲁棒性。该模型展现了强大的任务泛化能力和跨机器人平台适应性，只需少量演示即可快速适应新任务，预示着具身智能迈向更加自主和普及的关键阶段，但也带来了对安全性、伦理和商业模式的新思考。">

	
  </head><body class="ma0 avenir bg-near-white development">

    
  
  

  
  
  
  <header class="cover bg-center" style="background-image: url('http://192.168.50.247:1313/newsimages/selected_image_YYYY-06-Jun%2025,%202025_12-01-04-971.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        <img src="/logo/logo.png" class="w100 mw5-ns" alt="AI内参" />
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/insights/" title="">
              洞察
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/newspaper/" title="">
              日报
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/explore/" title="">
              主题探索
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref helvetica tracked">
        <span style="color: #999;">2025-06-25 12:10</span>
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">谷歌DeepMind推出具身Gemini本地版：机器人自主时代的里程碑？</h1>
      
      <p class="tracked"><strong>温故智新AIGC实验室</strong>
      </p>
      
      
    </header>
    <div class="article-content nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>谷歌DeepMind发布了Gemini Robotics On-Device，首次将多模态具身智能模型直接部署到机器人上，无需互联网连接即可实现低延迟操作和强大的任务泛化能力，标志着具身智能迈向自主、普及的关键一步。</p></blockquote>
<p>具身智能（embodied AI）的愿景，在于赋予机器人理解、推理并主动在物理世界中行动的能力。长期以来，实现这一目标面临着巨大的计算挑战，尤其是在边缘设备上实时运行复杂AI模型的需求。然而，谷歌DeepMind的最新发布——<strong>Gemini Robotics On-Device</strong>——正试图改变这一格局，它将强大的视觉-语言-动作（VLA）模型直接带到机器人本体上，无需持续的云端连接，从而打开了机器人自主性和适应能力的新篇章。</p>
<h3 id="具身智能的本地化突破">具身智能的本地化突破</h3>
<p>Gemini Robotics On-Device是谷歌DeepMind针对机器人领域推出的Gemini家族新成员，其核心创新在于实现了<strong>本地化部署</strong>。这意味着该模型能够直接在机器人硬件上运行，摆脱了对稳定互联网连接的依赖。在传统架构中，机器人的决策往往需要将感知数据上传至云端进行处理，再将指令下发，这不仅引入了显著的<strong>延迟</strong>，也限制了机器人在网络不稳定或无连接环境中的应用。而本地运行则彻底解决了这些问题，确保了操作的即时性和鲁棒性<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<p>这款模型基于多模态推理能力强大的Gemini 2.0，针对最大限度减少计算资源需求进行了优化，特别适合快速进行灵巧操作实验。DeepMind的实验结果显示，即使在本地运行模式下，Gemini Robotics On-Device在视觉、语义和行为泛化能力方面也展现出显著优势。它在广泛的测试场景中能够遵循自然语言指令，执行诸如拉开袋子拉链或折叠衣服等高度灵巧的任务。与之前最佳的本地端机器人模型相比，Gemini Robotics On-Device在标准泛化任务，尤其是在更具挑战性的“分布外（out-of-distribution）”任务和复杂的多步骤指令方面，表现出明显优越的性能，这为其在现实世界中的广泛应用奠定了基础。</p>
<h3 id="灵活性与泛化能力的延伸">灵活性与泛化能力的延伸</h3>
<p>本地化运行固然重要，但模型的<strong>通用灵活性</strong>和<strong>任务泛化能力</strong>才是决定其应用前景的关键。Gemini Robotics On-Device是DeepMind推出的首个可供微调的VLA模型，这意味着开发者无需从零开始训练，只需通过少量演示（通常为50到100个）即可让模型快速适应新任务。这种“小样本学习”能力极大地降低了机器人部署的门槛和成本，使得机器人能够更迅速地适应特定环境和需求。</p>
<p>DeepMind在七项不同难度的灵巧操作任务上验证了模型的适应性，包括拉开午餐盒拉链、画卡片和倒沙拉酱等。更令人印象深刻的是其<strong>跨具身泛化</strong>能力。该模型最初在ALOHA机器人上进行训练，但实验证明，它可以进一步微调并成功应用于其他完全不同形态的机器人，如双臂Franky FR3机器人和Apptronik的Apollo人形机器人。在Franky机器人上，它能处理未见过的物体并执行复杂的工业皮带装配任务；在Apollo人形机器人上，它也能良好适应，遵循自然语言指令对不同物体进行通用操作。这种跨平台适应性，预示着未来具身AI模型可能实现“一次训练，多处部署”，极大地加速了机器人技术的商业化进程。</p>
<p>为了进一步赋能开发者，谷歌还将发布<strong>Gemini Robotics SDK</strong>。通过该SDK，开发者可以在DeepMind的MuJoCo物理模拟器中测试和评估模型表现，并高效地将其适应到新领域。值得一提的是，与该SDK相关的<strong>MuJoCo Playground</strong>项目，刚刚荣获了机器人科学与系统会议（RSS 2025）的杰出演示论文奖，这进一步印证了其在机器人仿真领域的领先地位。</p>
<h3 id="更广阔的产业图景与考量">更广阔的产业图景与考量</h3>
<p>Gemini Robotics On-Device的发布，不仅仅是技术上的突破，更是在描绘一个更加自主化、普及化的机器人时代。当机器人不再受制于网络连接，它们将能够进入更广泛、更复杂的环境，例如偏远地区的农业、灾难救援、家庭服务，甚至深空探索。这不仅能提升工作效率，也能在一定程度上弥补劳动力短缺问题。</p>
<p>然而，随之而来的深层影响和伦理考量也值得关注。当AI模型在本地拥有高度自主决策能力时，如何确保其行为的<strong>安全性、可控性和透明度</strong>变得尤为关键。本地化处理虽然可能在数据隐私方面提供一定优势（数据无需上传云端），但同时，机器人“离线”自主运行时的行为边界、责任归属以及面对不可预测情况时的应急机制，都需要行业和监管机构共同深思并建立健全的规范。</p>
<p>值得注意的是，在发布Gemini Robotics On-Device的同时，谷歌DeepMind也在调整其更广泛的AI模型策略。例如，免费用户可用的Gemini Flash模型额度有所下调，而Imagen 4和Imagen 4 Ultra等图像生成模型也已在谷歌AI Studio和Gemini API中推出<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。这种调整反映了谷歌在AI商业化道路上的审慎考量：一方面持续推动前沿技术创新以保持领先地位，另一方面也在探索如何平衡免费试用与付费服务，将尖端AI能力转化为可持续的商业价值。</p>
<p>Gemini Robotics On-Device的问世，无疑是具身智能领域的一次重要飞跃。它让机器人离真正的“智能自主体”更近了一步，但这条道路依然漫长，充满技术挑战、伦理考量以及社会适应的复杂性。如何确保这些强大的本地化AI系统能够安全、普惠地服务于人类社会，将是未来几年我们必须面对的核心议题。</p>
<h2 id="引用">引用</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>刚刚，首个能在机器人上本地运行的具身Gemini来了·36氪·Panda (2025/6/25)·检索日期2025/6/25&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Gemini Robotics On-Device brings AI to local robotic devices·DeepMind· (2025/6/25)·检索日期2025/6/25&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<ul class="pa0">
  
   <li class="list di">
     <a href="/tags/%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">具身智能</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BAai/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">机器人AI</a>
   </li>
  
   <li class="list di">
     <a href="/tags/gemini-robotics-on-device/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Gemini Robotics On-Device</a>
   </li>
  
   <li class="list di">
     <a href="/tags/%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">本地运行</a>
   </li>
  
   <li class="list di">
     <a href="/tags/vla%E6%A8%A1%E5%9E%8B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">VLA模型</a>
   </li>
  
   <li class="list di">
     <a href="/tags/deepmind/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">DeepMind</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI泛化能力</a>
   </li>
  
   <li class="list di">
     <a href="/tags/ai%E4%BC%A6%E7%90%86/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">AI伦理</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3" style="color: #666;">相关阅读</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/insights/gemini-robotics-on-device-20250625121004319-2/">谷歌的具身智能新策略：Gemini Robotics On-Device与“机器人安卓”生态的黎明</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250620181004362-0/">人形机器人的“玩具”困境：从聚光灯到真实应用的漫漫长路</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250619132004443-2/">人形机器人闯入消费市场：不止是价格战，更是具身智能的未来预演</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/chatehr-20250625101004434-0/">对话病历：斯坦福ChatEHR如何重塑医疗数据交互与挑战</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004518-2/">AI商业化：一场创新投入的持久战与伦理重塑</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004566-9/">“上新潮”来袭：AI眼镜如何重塑人机交互与产业格局？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250625091004505-0/">摆脱“花瓶”困境：银河通用如何在具身智能的“无人区”中深耕实用价值</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624191004335-0/">特斯拉机器人出租车引发监管关注：自动驾驶的现实与伦理拷问</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/harvey-ai50ai-20250624181004234-1/">Harvey AI估值飙升至50亿美元：法务AI如何重塑专业服务未来？</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624161004445-2/">AI浪潮下的权力、资本与转型：从巨头布局到人才争夺</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/alphawriteai-20250624151004557-6/">AlphaWrite：进化算法如何迭代重塑AI叙事边界</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/article-20250624151004510-0/">具身智能：中国制造业价值攀升的“国运级”新引擎</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/openai-o3-pro-20250624131004401-0/">OpenAI o3-pro：可靠性之诺与用户体验的现实鸿沟</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/midjourneyai-20250624101004341-2/">好莱坞巨头吹响号角：迪士尼与环球影业起诉Midjourney，重塑AI版权格局</a>
        </li>
	    
	     <li  class="mb2">
          <a href="/insights/sealai-20250624061004196-0/">超越静态模型：麻省理工学院SEAL框架赋能AI自主学习新范式</a>
        </li>
	    
    </ul>
</div>



<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links mt3">
  <p class="f5 b mb3" style="color: #666;">AI写作声明</p>
  <div class="f6 lh-copy" style="color: #777;">
    <p>本文由AI系统全流程生成，涵盖选题、资料整合与撰写。文章发布后由人工编辑进行核查。文末附有详细的[引用信息索引]，供您查证溯源。</p>
  </div>
</div></aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://192.168.50.247:1313/" >
    &copy;  AI内参 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

    <script src="/js/relative-time.js"></script>
  </body>
</html>
